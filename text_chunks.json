["1 \n ISyE DDA  \u2013 Agenda for 0 4/04/23 Lecture (Lec. 22) \nI) Resampling and Ensemble Methods  \n(a) Resampling:  Bootstrap and Jackknife  (presented)  \n(b) Ensemble Methods: Bagging, Stacking, (presented)  \nBoosting, Random Fores t (today \u2019s focus)  \nII) Mode", "resented)  \nBoosting, Random Fores t (today \u2019s focus)  \nII) Model Assessments  \nIII) In-Class Exam -2 Topics  \nIV) Past In -Class Exam -2 Problems  \n------------------------------------------------------------------------------------  \nDetailed Lectures:  ", "-----------------------------------------  \nDetailed Lectures:   \nI) Ensemble Methods: Boosting, Random Forest  \n 2 \n  \n \n3 \n  \n4 \n Boosting Weight Examples:     Err (1-Err)/Err Alpha_m = Log[(1-Err)/Err] Exp(Alpha_m)   Model-Quality         weight-factor ", "(1-Err)/Err] Exp(Alpha_m)   Model-Quality         weight-factor       0.8 0.25 -0.602059991 0.547682253   Not a good model    0.5 1 0 1       0.4 1.5 0.176091259 1.192546884   Good model                  \nAn Algorithm for Random Forest (Tree Constructions)", "            \nAn Algorithm for Random Forest (Tree Constructions):  \n \nAn Example \u2013 Comparison Between Bagging, Random \nForest and Boosting Procedures:  \n5 \n  \n----------------------------------------------------------------------------------  \nII) Model As", "-------------------------------------------------  \nII) Model Assessment:  \nReference: Hastie, T., Tibshirani, R., and Friedman, J. (2017), \nThe Elements of Statis tical Learning , Springer, New York. \nNote that this book is a typical textbook used in data", "ew York. \nNote that this book is a typical textbook used in data \nmining or/and machine learning classes.  Downloadable \npdf file: https://web.stanford.edu/~hastie/ElemStatLearn/printings/ESLII_print12.pdf  \n \n6 \n  \n7 \n  \n8 \n  \n \n \n9 \n III) In-Class Exam -", "I_print12.pdf  \n \n6 \n  \n7 \n  \n8 \n  \n \n \n9 \n III) In-Class Exam -2 Subjects \u2013 focus on \u201chigh level\u201d concepts  \n \n1. Decision Models (30%)  \n \ni) Decision in An Uncertain Environment (Constrained -\nOptimization Model Formulation)  \nii) Game -Theoretic Models", "d -\nOptimization Model Formulation)  \nii) Game -Theoretic Models  \n \n2. Advanced Data Modeling (70%)  \ni) Classification (LDA/QDA, SVM)  \nii) Nonparametric Regression  \niii) Cluster Analysis (K -Means, Multivariate Gaussian \nMixtures)  \niv) Dimension Reduc", "K -Means, Multivariate Gaussian \nMixtures)  \niv) Dimension Reduction (PCA, PLS, MDS, SOM)  \nv) Variable -Selections (Stepwise, All -Subsets, Ridge \nRegression, Lasso)  \nvi) Resampling and Ensemble Methods (Bootstrap \nSampling; Cross -Validation, Boosting, ", "mble Methods (Bootstrap \nSampling; Cross -Validation, Boosting, Random Forest)  \n------------------------------------------------------------------------------------  \nIV) Past In -Class Exam -2 Problems:  \nA) Essay questions:  [50 points in total]  10 \n 1", "-2 Problems:  \nA) Essay questions:  [50 points in total]  10 \n 11. Briefly describe boosting\u2019s three key properties discussed in \nlectures.   [9 points ; 3 points each ] \nAnswers:  \n(1) \u201cTrust high -quality model  more\u201d by assigning a larger value \nto \u03b1m i", " high -quality model  more\u201d by assigning a larger value \nto \u03b1m in the weighted average based (final) prediction model.  \n(2) \u201cLearn from mistakes \u201d by updating  weights wi to mis-\nclassifi ed cases.  \n(3) \u201cUse weighted  data-modeling or -analysis\u201d procedur", "cases.  \n(3) \u201cUse weighted  data-modeling or -analysis\u201d procedure to \nconstruct G2, G3, \u2026, Gm models in the boosting process.  \n \n12. Briefly describe Principal Component Analysis\u2019 (PCA) three key \nproperties.   [10 points]  \nAnswers:  \n(1) All Principal C", " key \nproperties.   [10 points]  \nAnswers:  \n(1) All Principal Components (PCs) are mutually orthogonal to \neach other.   [3 points]  \n(2) All PCs are linearly weighted sum of the o riginal X -variables.   \n[3 points]  \n(3) The variances (\u03c32i for i = 1, 2,", "-variables.   \n[3 points]  \n(3) The variances (\u03c32i for i = 1, 2, \u2026, p) captured by the first, \nsecond, third, \u2026, p-th PCs are in the descending order, i.e., \n\u03c321 \u2265  \u03c322 \u2265 \u2026 \u2265 \u03c32p.  [4 points]  11 \n  \n13. For understanding the physical meaning of the Multi ", " 11 \n  \n13. For understanding the physical meaning of the Multi -\nDimensional Scaling (MDS) procedure described below (taken \nfrom Lecture -Notes #18), answer questions below.  \n \n(1) What is the physical meaning of dik ?  [3 points]  \n(2) What is the phys", "the physical meaning of dik ?  [3 points]  \n(2) What is the physical meaning of cik = || Zi \u2013 Zk || ?  [3 points]  \n(3) What is the physical meaning that MDS seeks values Z1, Z2, \u2026, \nZN to minimize the above stress function ? [5 points]  \n \nAnswers:  \n(1) ", "imize the above stress function ? [5 points]  \n \nAnswers:  \n(1) dik is the distance between two data points in the (original) X -\nvariable scale. For example, consider a n L 2-norm  with p (=eg= \n30) dimensional data xi. The distance metric  \n  dik = sqrt{", "g= \n30) dimensional data xi. The distance metric  \n  dik = sqrt{ (xi1 \u2013 xk1)2 + (xi2 \u2013 xk2)2 + \u2026 + (xi1p \u2013 xkp)2 } \nmeasure the similarity  between two X -variable locations, Xi and \nXk. \n12 \n (2) Similarly, cik = || Zi \u2013 Zk || measures the similarity of t", " (2) Similarly, cik = || Zi \u2013 Zk || measures the similarity of two Z -\nvariable locations Zi and Zk, \nwhere in the Z -transformed scale, the Z -data variable has a much \nlower dimension q =eg= 7 (to 10). Again, cik = || Zi \u2013 Zk || can \nbe defined as the L ", " 7 (to 10). Again, cik = || Zi \u2013 Zk || can \nbe defined as the L 2-norm similar to the one defined for the X -\nvariables.  \n(3) The stress function shown above aims to find the Z -variables \nthat minimize the difference between X -variable distance \nmetric ", "at minimize the difference between X -variable distance \nmetric and Z -variable distance metric such that these two sets \nof distance metrics are as \u201cclose\u201d (defined in the square -error -\nloss format) as possible in describing the similarities in the data", "s format) as possible in describing the similarities in the data \nlocations  (at p- and q-dim scales, respectively).  \n \n14. Define profit \u03a0(x1, x2; Y)  as a function for two decision \nvariables x1 and x2 and one random variable Y describing \neconomic outl", "es x1 and x2 and one random variable Y describing \neconomic outlook for business . \n(a) Use the notations taught in the lectures to define a mixture -\ndistribution model  for investors\u2019  outlook of economic \ncondition Y in two directions , getting worse  a", "ok of economic \ncondition Y in two directions , getting worse  and getting \nbetter .  [6 points]  13 \n (b) What is the typical optimization model used in the risk -neutral \nsolution? [ 4 points]  \n(c) Formulate the Probability -constraint -based Optimizati", "s]  \n(c) Formulate the Probability -constraint -based Optimization \n(PCO) Model , [5 points] and provide  detailed interpretation  \nfocusing on the \u201cgetting -worse\u201d economic outlook  \nsituation  [5 points]  \nAnswer : \n(a) Denoted by Y 1 as the random varia", "n  [5 points]  \nAnswer : \n(a) Denoted by Y 1 as the random variable for describing a \n\u201cgetting -better\u201d economic outlook. Its distribution function \n(cdf) is G 1(y1). Similarly, denoted by Y 2 as the random \nvariable for describing \u201c getting -worse \u201d econo", " as the random \nvariable for describing \u201c getting -worse \u201d economic outlook. Its \ndistribution function (cdf) is G2(y2). Define an indicator \nrandom variable D = 1 if it is a better -outlook; 0, if it is a \nworse -outlook. Pr(D = 1) = p. Fur thermore, assu", "0, if it is a \nworse -outlook. Pr(D = 1) = p. Fur thermore, assume that D, Y 1 \nand Y 2 are mutually independent.  Then, the random variable \nfor any economic outlook condition Y  is a mixture of these \ntwo random variables as Y = D*  Y1 + (1 \u2013 D)* Y2. Its", " of these \ntwo random variables as Y = D*  Y1 + (1 \u2013 D)* Y2. Its \ndistribution can be derived as G(y) = p* G1(y) + (1 \u2013 \np)*G 2(y). \n 14 \n (b) The risk -neutral solution  finds the optimal values of decision \nvariables  x1, x2 , to maximize E G[ \u03a0(x1, x2; ", "ues of decision \nvariables  x1, x2 , to maximize E G[ \u03a0(x1, x2; Y)  ], where the \nexpectation is taken with respect to (w.r.t.) the G(y) \ndistribution for the general economic outlook  random \nvariable Y . \nGrading Remarks: 2 pts assigned to the expectatio", "\nvariable Y . \nGrading Remarks: 2 pts assigned to the expectation -\nobjective -function, and 2 pts assigned to the distribution \nG(y).  \n \n(c)  \n(i)The PCO model will find the optimal values of decision \nvariables  x1, x2 , to maximize E G[ \u03a0(x1, x2; Y)  ]", "f decision \nvariables  x1, x2 , to maximize E G[ \u03a0(x1, x2; Y)  ] subject \nto Pr[ \u03a0(x1, x2; Y ) \u2264 20% | in the \u201cgetting -worse\u201d \neconomic outlook  situation  ] \u2264 5%.  \n(ii) The physical explanation of the constraint is that the re is a \nvery small  chanc e ", "tion of the constraint is that the re is a \nvery small  chanc e (using 5% as an upper bound) for \nseeing the profit \u03a0(x1, x2; Y ) being lower than a value \n(using 20% as an example here), which is like the low -\nacceptable -value for business (money making", "h is like the low -\nacceptable -value for business (money making) \nperformance. The probability there  is evaluated against \nthe distribution G2(y2) for the \u201cgetting -worse\u201d economic \noutlook situations.  15 \n -------------------------------------- -------", "situations.  15 \n -------------------------------------- ---------------------------------------------  \nB) True and False Questions  (5 points for each question and \nthere is no partial credit).  \n(True,  False )  1.  In K -means method a data -point coul", "t).  \n(True,  False )  1.  In K -means method a data -point could be in \nseveral clusters with different probabilities (sum to \none).  \nAnswer: False. There is no probability or distribution \nassump tion for the K -means method.  \n(True,  False )  2.  AIC ", "assump tion for the K -means method.  \n(True,  False )  2.  AIC metric could be used in the Stepwise \nRegression.  \nAnswer: False. AIC is used in the all -subsets regression. \nStepwise regression is based on the partial -F-tests.  \n (True,  False )  3. In ", "ion is based on the partial -F-tests.  \n (True,  False )  3. In the four ensemble m ethods (bagging, \nstacking, boosting and random -forest) taught in the \nlectures for regression predictions bagging  is the \nonly procedure uses equal -weights in the avera", "bagging  is the \nonly procedure uses equal -weights in the average of \npredictions from m = 1000 (eg) individual models \nfitted to re -sampled -data.  \nAnswer: False. Random -forest also uses equal weights to \naverage predictions.  16 \n (True ,  False)  4.", "equal weights to \naverage predictions.  16 \n (True ,  False)  4.  Whether Y -data is normally or multinominal \ndistributed, the results of PCA are the same.  \nAnswer: True. PCA is an unsupervised learning method dealing \nwith only X -data, where Y -data an", "sed learning method dealing \nwith only X -data, where Y -data and its distribution \nare not involved . \n(True,  False )  5.  AIC -, BIC - and PRESS -based all -subsets \nregression procedures are applicable to non -normal \ndata and non -linear models. Simil", "re applicable to non -normal \ndata and non -linear models. Similarly, the stepwise \nregression procedures have the same prop erties.  \nAnswer: False. Stepwise regression depends on the normal \ndistribution and linear model assumptions such that \nthe partia", "\ndistribution and linear model assumptions such that \nthe partial -F-test has an F -distribution.  \n(True,  False )  6.  In the boosting procedure the weights for the \nmis-classified samples from the previous model are \nalways more than the weights for the", "rom the previous model are \nalways more than the weights for the non -mis-\nclassified samples.  \nAnswer: False. In boosting the weights for the mis -classified \nsamples are more than the w eights for correctly \nclassified samples \u2013 this comparison is only ", "hts for correctly \nclassified samples \u2013 this comparison is only valid \nfor a set of samples , i.e., comparison within a set of 17 \n samples, but not between two sets of samples or \nsamples in different models. This is the property in \nboosting\u2019s algorithm ", "different models. This is the property in \nboosting\u2019s algorithm Step -2(c). Thus, the sample -\nweight can be more or less than the weights given \nby the previous model.  \n(True ,  False)  7. When the X -data-columns are organized in \ndifferent sequences (e", "hen the X -data-columns are organized in \ndifferent sequences (e.g., X1, X3, X4 versus X4, \nX3, X1), it is possible that forward -selection \nprodu ces distinct models (even that alpha -to-enter is \nset at the same value, e.g., 15%).  \nAnswer: True. The par", "r is \nset at the same value, e.g., 15%).  \nAnswer: True. The partial -F-test in the forward -selections takes \nthe first (and then, the subsequent) variable(s) from \nthe X -data-columns given by the user. Different \nseque nces could produce distinct models", "by the user. Different \nseque nces could produce distinct models.  \n(True ,  False)  8. One of the key differences in the LDA - and \nlogistic -classification is that LDA assumes the \ndistribution of X -variables (as a multivariate \nnormal).  \nAnswer: True.", "ion of X -variables (as a multivariate \nnormal).  \nAnswer: True. Logistic -classification treats X -variabl es as given \nconstants, but LDA assumes them to have a 18 \n multivariate normal distribution (given a class of \nY). \n(True,  False )  9.  The weight", "ribution (given a class of \nY). \n(True,  False )  9.  The weights for each one of the m = 1000 \nstacking -models and boosting -models are found \nbased on certain optimization objectives . \nAnswer: False. It is true for the stacking method, but not true for", "wer: False. It is true for the stacking method, but not true for \nthe boosting method, where the model -weight is \nassigned as a given function of \u201cErr (= error rate)\u201d, \nwhere no optimization objective function is used to \nderive the weights.  \n (True,  Fa", "objective function is used to \nderive the weights.  \n (True,  False )  10.  Even that the covariance between X and Y \nstays the same, PLS -results could change depending \non the distribution assumption of Y -data, e.g., log -\nnormal versus Weibull or Gamma", "ssumption of Y -data, e.g., log -\nnormal versus Weibull or Gamma.  \nAnswer: False. PLS only works with the covariance between  X \nand Y. The distribution (e.g., pdf) information is not \ninvolved.  \n(True,  False )  11.  The SVM -classification will minimiz", "ed.  \n(True,  False )  11.  The SVM -classification will minimize the \nmis-classification counts.  19 \n Answer: False. The SVM maximizes the margin of support -\nvectors  in different classes.  \n(True ,  False)   12.  In all variable -selection procedures t", " \n(True ,  False)   12.  In all variable -selection procedures taught in \nthe lectures stepwise -regression is the only \nsequential procedure, i.e., the model selected in the \nlatter stage will depend on the model(s) selected in \nthe earlier stage(s).  \nAn", "l depend on the model(s) selected in \nthe earlier stage(s).  \nAnswer: True. The partial -F-test used in the stepwise regression \nis a sequential procedure. All other variable -\nselection procedures work with each possible model \nindependently.  \n----------", "dures work with each possible model \nindependently.  \n------------------------------------------------------------------------------------  \n \n(True ,  False)  1.  Cluster analysis works with explanatory \nvariables (i.e., X -data). Thus, it is an unsupervi", "explanatory \nvariables (i.e., X -data). Thus, it is an unsupervised \nlearning procedure.  \n(True,  False )  2.  In the Game -Theoretic problem presented in \nlectures, for a Retailer Stackelberg Decision Model, \none should work on Retailer\u2019s Reaction Functi", "g Decision Model, \none should work on Retailer\u2019s Reaction Function 20 \n first before solving Manufacturers\u2019 optimal decision \nmodels . \nAnswer: False. In a Retailer Stackelberg Decision Model, \nthe retailer is the leader and has more bargaining \npower. The", " \nthe retailer is the leader and has more bargaining \npower. Therefore, one should first work on the \nmanufacturer's optimal decision model before the \nretailer\u2019s reaction function. This is because the \nretailer has more power and has knowledge of how \na m", "cause the \nretailer has more power and has knowledge of how \na manufacturer would react to different quantities. \nSo, the retailer can condition on the information \nabout the manufacturer's wholesale price and \nservice when making their own decision to set", "olesale price and \nservice when making their own decision to set retail \nprice a nd order quantity.  \n(True,  False )  3. A statistics -based classification procedure  such \nas QDA will always be more accurate  than a \ncomputing/optimization  procedure suc", " be more accurate  than a \ncomputing/optimization  procedure such as SVM .  \nAnswer: False. When all assumptions needed in a statistics -\nbased classification  procedure are satisfied, the \nstatistical classification can be more accurate. \nHowever, when a ", "atistical classification can be more accurate. \nHowever, when a certain assumption is not \nsatisfied, its accuracy is not guaranteed. SVM will 21 \n do a better job in handling data with potential \noutliers compared to most statistic al classifications.  \n(", "ial \noutliers compared to most statistic al classifications.  \n(True ,  False)  4.  The PCA procedure constructs p number of \nPrincipal Components (PCs), where p (=eg= 10) is \nthe number of X -variables. Each PCs is a linearly \nweighted sum of the X -varia", "-variables. Each PCs is a linearly \nweighted sum of the X -variables.  \n(True,  False )  5.  For optimizing objecti ve functions involving \nuncertain components (i.e., random variables), one \nalways takes expected values for random \ncomponents to simplify ", "always takes expected values for random \ncomponents to simplify the stochastic optimization \nproblem into a deterministic optimization  problem.  \nAnswer: False. There are many alternative options in \nhandling optimization with uncertainty. Lecture \nnotes ", "ions in \nhandling optimization with uncertainty. Lecture \nnotes presented a few constrained optimization \nprocedures to limit potential impact of uncertainty.  \n(True ,  False )  6.  In spline fitting, when the tuning parameter \u03bb \nis larger, the fit ted re", " fitting, when the tuning parameter \u03bb \nis larger, the fit ted regression function will be \nsmoother.  \nAnswer: True. One can consider the \u201cextreme\u201d case that when \u03bb \nis equal to zero, the spline fit will go through all 22 \n data points to minimize the sum ", "ne fit will go through all 22 \n data points to minimize the sum -of-squares of \nprediction -errors, i.e., the fitted regression will be \nthe least smooth. Thus, when the tuning parameter \u03bb \nis larger, the fitted regression function will be \nsmoother.  \n(Tr", " larger, the fitted regression function will be \nsmoother.  \n(True ,  False )  7.  Stepwise and all -subsets regressions are \nsuitable for p < n problems, where p = #x-variables \nand n = sample size. They are not suitable for \nhandling \u201clarge p and small n", "e size. They are not suitable for \nhandling \u201clarge p and small n\u201d problems.  \n(True ,  False )  8.  In clustering analysis with a Gaussian Mixture \nModel  (GMM) , it is possible that some data point s \nhave non -zero probabilities for being in a few \ndiffe", " point s \nhave non -zero probabilities for being in a few \ndifferent clusters.  \nAnswer: True.  The above characteristic is the key feature that \ndistinguishes GMM -clustering with other clustering \nmethods.  \n(True,   False )  9.  LDA and QDA are the only", "ering \nmethods.  \n(True,   False )  9.  LDA and QDA are the only two Bayesian \nclassification procedures discussed in lectures.  \nAnswer : False . Bayes classifier is another Bayesian \nclassification procedure presented in lectures.  23 \n (True,   False ) ", "ication procedure presented in lectures.  23 \n (True,   False )  10.  All ensemble methods taught in lectures use \nbootstrapping methods to generate many data sets \nfor fitting various data models. Then, the final \nmodel is an assembly (e.g., average) of t", "dels. Then, the final \nmodel is an assembly (e.g., average) of these data \nmodels.  \nAnswer: False. Boosting is not. Boosting works with one data \nset, the original data set.   It assigns different \nweights in successive iterations. In each iteration, a \nn", "erent \nweights in successive iterations. In each iteration, a \nnew data model is constru cted. The final model is a \n(weighted) average of these models.  \n \n 1 \n ISyE DDA  \u2013 Agenda for 0 3/30/23 Lecture (Lec. 21) \nI) Semester Project \u2013 PPT and Final Report", "23 Lecture (Lec. 21) \nI) Semester Project \u2013 PPT and Final Report Guidelines  \nII) Resampling and Ensemble Methods  \n(a) Resampling:  Bootstrap and Jackknife  (presented)  \n(b) Ensemble Methods: Bagging, Stacking, Boosting, Random \nFores t \nIII) Model Asses", ": Bagging, Stacking, Boosting, Random \nFores t \nIII) Model Assessments  \nIV) In-Class Exam -2 Topics  \nV) Past In-Class Exam -2 Problems  \n------------------------------------------------------------------------------------  \nDetailed Lectures:   \nI) Guide", "-------------------------------  \nDetailed Lectures:   \nI) Guide lines for Preparing PPT s and Final Reports  \nSuggestions for PPT -Designs  \nPPT will serve as a \u201cskeleton\u201d for the Final Report  \nAccording to our syllabus, 3% of credits are allocated to \nP", "t  \nAccording to our syllabus, 3% of credits are allocated to \nPresentation -PPT Designs.  Even that we do not have live (or \nremote) presentations for your semester -projects, students need \nto design their presentation -PPTs. Every team is supposed to \nh", "to design their presentation -PPTs. Every team is supposed to \nhave 15 minutes for presenting their project experience. Suppose \nthat there are five mai n sections  in the  project studies (e.g., \nIntroduction  and Problem  Definition, LoM for Problem 2 \n ", "g., \nIntroduction  and Problem  Definition, LoM for Problem 2 \n Background , Decision Modeling , Data Modeling and Data \nSource  and Conclusion/Future Work). Then, each section will \nhave about 3 minutes. If one slide takes 20 - 30 seconds to \npresent, the", "t 3 minutes. If one slide takes 20 - 30 seconds to \npresent, there shall be about 6-8 pages per section. Totally, there \nmight be 30-40 pages for the entire PPT.   Of course, certain \nsections might need more  pages than other sections do. If \nstudents hav", " might need more  pages than other sections do. If \nstudents have anything to discuss or ask me, please use e mail me \nat < JCLU@isye.gatech.edu  >. Please remember to put \" 4034 :\" \nin your subject -line. \n \nSuggestions for Section Contents in the Final R", "ubject -line. \n \nSuggestions for Section Contents in the Final Report  \nLet us use bullets to suggest section contents. Each bullet could \nbe developed into one or two paragraphs.  The total number of \npages (without counting Appendix that includes more in", "umber of \npages (without counting Appendix that includes more in -depth \ndetails) could be 30 -40 pages.   \n Please remember to include a page of project title , brief  \ntable -of-contents  and student names . Every page should be \nnumbered.  \nSection 1 \u2013 ", "d student names . Every page should be \nnumbered.  \nSection 1 \u2013 Introduction  \n[1] Briefly describe  (and motivate)  your problem scope . 3 \n [2] State the goal(s)  of your semester -project . \n[3] A brief \u201creview\u201d of the problem background; LoM studies \ns", " \n[3] A brief \u201creview\u201d of the problem background; LoM studies \nshould  be referred in the main text, but included in appendix . \n[4] Briefly provide an overview of problem solving  ideas  and \ntheir rational;  A brief roadmap   \nmight be useful . Specific ", "\ntheir rational;  A brief roadmap   \nmight be useful . Specific sections on decision models, data \nmodels and data sources could be cited in your roadmap . This \nroadmap also provides a structure  for presenting  subsequent \nsections.  \n \nSection 2 \u2013 Decis", "ure  for presenting  subsequent \nsections.  \n \nSection 2 \u2013 Decision Model s \n[1] Outline the contents of your decision models and steps of \nformulating decision models. For example, native language -\nbased  decision modeling, notation definition for the \nc", "guage -\nbased  decision modeling, notation definition for the \ncomponents involved in the decision models, functional \nrelationship for certain variables, and rigorous mathematical \nformulation of deci sion models.  \n[2] Use a hierarchical style for presen", "n of deci sion models.  \n[2] Use a hierarchical style for presenting  mathematically \nformulated  decision models with critical explanations and \njustifications ; subsections (e.g., notations, decision variables, 4 \n objective functions and constraints)  c", " decision variables, 4 \n objective functions and constraints)  could be used to make the \npresentation easy to read.  \n[3] Briefly discuss possible method(s) (and associated software \npackage(s)) to solve your optimization problem for decision  \nvariables.", "s)) to solve your optimization problem for decision  \nvariables.  \n \nSection 3 \u2013 Data Models  \n[1] Use general terms to discuss how your data models are \nneeded for supporting optimization of your decision models.  \n[2] Use a hierarchical style to present ", "your decision models.  \n[2] Use a hierarchical style to present  data models rigorously. \nPlease make sure notations are well defined, equation s or \nexpressions are explained and justified.  \n[3] Briefly discuss how to apply software package(s) to perform", "\n[3] Briefly discuss how to apply software package(s) to perform \ndata modeling.  \n \nSection 4 \u2013 Data Sources  \n[1] Discuss what types of data are needed to execute your data \nmodeling.  5 \n [2] Provide examples of sources for extracting or gathering \nneed", "2] Provide examples of sources for extracting or gathering \nneeded data.  For example, some data might be collected from \ninterviewing \u201cexperts\u201d (e.g., high school teachers).  \n[3] Because some data models include several common X -\nvariables. Let us  use ", "e data models include several common X -\nvariables. Let us  use a subs ection, \u201cdata source \narchitecture\u201d , to organize needed data variables  with \nrespect to their background, similarity , and their potential \nsources or/and methods of collecting them. ", "and their potential \nsources or/and methods of collecting them.  \n \nSection 5 \u2013 Conclusion , Future Work and Lesson Learned  \n[1] Briefly summarize key findings in this project study . \n[2] Discuss future work and their potential impact  to your \ncurrent s", "scuss future work and their potential impact  to your \ncurrent studies.  \n[3] Summarize lesson -learned from this project stud y. \n \nReference  \nAppendix  \n \n 6 \n II) Resampling and Ensemble Methods  \n(b) Ensemble Methods: Bagging, Stacking, Boosting, Rand", "ethods  \n(b) Ensemble Methods: Bagging, Stacking, Boosting, Random \nForest  \n1) Bagging:  \n \n \n7 \n  \n8 \n  \n9 \n  \n \n10 \n  \n11 \n Boosting Weight Examples:     Err (1-Err)/Err Alpha_m = Log[(1-Err)/Err] Exp(Alpha_m)   Model-Quality         weight-factor      ", "r)/Err] Exp(Alpha_m)   Model-Quality         weight-factor       0.8 0.25 -0.602059991 0.547682253   Not a good model    0.5 1 0 1       0.4 1.5 0.176091259 1.192546884   Good model                  \nAn Algorithm for Random Forest (Tree Constructions):  \n ", "       \nAn Algorithm for Random Forest (Tree Constructions):  \n \nAn Example \u2013 Comparison Between Bagging, Random \nForest and Boosting Procedures:  \n12 \n  \n----------------------------------------------------------------------------------  \nIII) Model Asses", "---------------------------------------------  \nIII) Model Assessment:  \nReference: Hastie, T., Tibshirani, R., and Friedman, J. (2017), \nThe Elements of Statistical Learning , Springer, New York. \nNote that this book is a typical textbook used in data \nmi", "ork. \nNote that this book is a typical textbook used in data \nmining or/and machine learning classes.  Downloadable \npdf file: https://web.stanford.edu/~hastie/ElemStatLearn/printings/ESLII_print12.pdf  \n \n13 \n  \n14 \n  \n \n15 \n  \n \n \n16 \n  \n \n--------------", "int12.pdf  \n \n13 \n  \n14 \n  \n \n15 \n  \n \n \n16 \n  \n \n-----------------------------------------------------------------------------------  \nIV) In-Class Exam -2 Subjects \u2013 focus on \u201chigh level\u201d concepts  \n \n1. Decision Models (30%)  \n \ni) Decision in An Uncert", "ncepts  \n \n1. Decision Models (30%)  \n \ni) Decision in An Uncertain Environment (Constrained -\nOptimization Model Formulation)  \nii) Game -Theoretic Models  \n \n2. Advanced Data Modeling (70%)  \ni) Classification (LDA/QDA, SVM)  \nii) Nonparametric Regressio", " \ni) Classification (LDA/QDA, SVM)  \nii) Nonparametric Regression  \niii) Cluster Analysis (K -Means, Multivariate Gaussian \nMixtures)  \n17 \n iv) Dimension Reduction (PCA, PLS, MD S, SOM)  \nv) Variable -Selections (Stepwise, All -Subsets, Ridge \nRegression,", "Variable -Selections (Stepwise, All -Subsets, Ridge \nRegression, Lasso)  \nvi) Resampling and Ensemble Methods (Bootstrap \nSampling; Cross -Validation, Boosting, Random Forest)  \n------------------------------------------------------------------------------", "----------------------------------------------------------------------  \nV) Past In -Class Exam -2 Problems:  \nA) True and False Questions  (5 points for each question and \nthere is no partial credit).  \n(True,  False )  1.  In K -means method a data -poin", " credit).  \n(True,  False )  1.  In K -means method a data -point cou ld be in \nseveral clusters with different probabilities (sum to \none).  \nAnswer: False. There is no probability or distribution \nassumption for the K -means method.  \n(True,  False )  2.", "ution \nassumption for the K -means method.  \n(True,  False )  2.  AIC metric could be used in the Stepwise \nRegression.  \nAnswer: False. AIC is used in the all -subsets regression. \nStepwise regression is based on the partial -F-tests.  \n (True,  False )  ", "egression is based on the partial -F-tests.  \n (True,  False )  3. In the four ensemble methods (bagging, \nstacking, boosting and random -forest) taught in the 18 \n lectures for regression predictions bagging  is the \nonly procedure uses equal -weights in ", "dictions bagging  is the \nonly procedure uses equal -weights in the average of \npredictions from m = 1000 (eg) individual models \nfitted to re -sampled -data.  \nAnswer: False. Random -forest also uses equal weights to \naverage predictions.  \n(True ,  False", "lso uses equal weights to \naverage predictions.  \n(True ,  False)  4.  Whether Y -data is normally or multin ominal \ndistributed, the results of PCA are the same.  \nAnswer: True. PCA is an unsupervised learning method dealing \nwith only X -data, where Y -d", "upervised learning method dealing \nwith only X -data, where Y -data and its distribution \nare not involved . \n(True,  False )  5.  AIC -, BIC - and PRESS -based all -subsets \nregression procedures are applicable to non -normal \ndata and non -linear models.", "ures are applicable to non -normal \ndata and non -linear models. Similarly, the stepwise \nregression procedures have the same properties.  \nAnswer: False. Stepwise regression depends on the normal \ndistribution and linear model assumptions such t hat \nthe ", "rmal \ndistribution and linear model assumptions such t hat \nthe partial -F-test has an F -distribution.  \n(True,  False )  6.  In the boosting procedure the weights for the \nmis-classified samples from the previous model are 19 \n always more than the weigh", "ples from the previous model are 19 \n always more than the weights for the non -mis-\nclassified samples.  \nAnswer: False. In boosting the weights for the mis -classified \nsamples are more than the weights for correctly \nclassified samples \u2013 this comparison", " the weights for correctly \nclassified samples \u2013 this comparison is only valid \nfor a set of samples , i.e., comparison within a set of \nsamples, but not between two sets of samples or \nsamples in differen t models. This is the property in \nboosting\u2019s algo", "s in differen t models. This is the property in \nboosting\u2019s algorithm Step -2(c). Thus, the sample -\nweight can be more or less than the weights given \nby the previous model.  \n(True ,  False)  7. When the X -data-columns are organized in \ndifferent sequen", "  7. When the X -data-columns are organized in \ndifferent sequences (e.g., X1, X3, X4 v ersus X4, \nX3, X1), it is possible that forward -selection \nproduces distinct models (even that alpha -to-enter is \nset at the same value, e.g., 15%).  \nAnswer: True. T", "o-enter is \nset at the same value, e.g., 15%).  \nAnswer: True. The partial -F-test in the forward -selections takes \nthe first (and then, the subsequent) variable (s) from \nthe X -data-columns given by the user. Different \nsequences could produce distinct ", " given by the user. Different \nsequences could produce distinct models.  20 \n (True ,  False)  8. One of the key differences in the LDA - and \nlogistic -classification is that LDA assumes the \ndistribution of X -variables (as a multivariate \nnormal).  \nAns", "\ndistribution of X -variables (as a multivariate \nnormal).  \nAnswer: True. Logistic -classification treats X -variables as given \nconstants, but LDA assumes them to have a \nmultivariate normal distribution (given a class of \nY). \n(True,  False )  9.  The w", " distribution (given a class of \nY). \n(True,  False )  9.  The weights for each one of the m = 1000 \nstacking -models and boosting -models are found \nbased on certain optimization objectives.  \nAnswer: False. It is true for the stacking method, but not tru", " \nAnswer: False. It is true for the stacking method, but not true for \nthe boosting method, where the model -weight is \nassigned  as a given function of \u201cErr (= error rate)\u201d, \nwhere no optimization objective function is used to \nderive the weights.  \n (Tru", "ation objective function is used to \nderive the weights.  \n (True,  False )  10.  Even that the covariance between X and Y \nstays the same, PLS -results could change depending \non the distribution assu mption of Y -data, e.g., log -\nnormal versus Weibull o", "tion assu mption of Y -data, e.g., log -\nnormal versus Weibull or Gamma.  21 \n Answer: False. PLS only works with the covariance between X \nand Y. The distribution (e.g., pdf) information is not \ninvolved.  \n(True,  False )  11.  The SVM -classification wi", "ot \ninvolved.  \n(True,  False )  11.  The SVM -classification will minimize the \nmis-classification counts.  \nAnswer: False. The SVM maximizes the margin of support -\nvectors  in different classes.  \n(True ,  False)  12.  In all variable -selection procedu", "sses.  \n(True ,  False)  12.  In all variable -selection procedures taught in \nthe lectures stepwise -regression is the only \nsequential procedure, i.e., the model s elected in the \nlatter stage will depend on the model(s) selected in \nthe earlier stage(s)", "ge will depend on the model(s) selected in \nthe earlier stage(s).  \nAnswer: True. The partial -F-test used in the stepwise regression \nis a sequential procedure. All other variable -\nselection procedures work with each possible model \nindependently.  \n 1 \n", " procedures work with each possible model \nindependently.  \n 1 \n ISyE DDA  \u2013 Agenda for 0 3/28/23 Lecture (Lec. 20) \nI) Large p Small n Variable -Selections  \nII) Resampling and Ensemble Methods  \n(a) Resampling:  Bootstrap and Jackknife  \n(b) Ensemble Met", "ds  \n(a) Resampling:  Bootstrap and Jackknife  \n(b) Ensemble Methods: Bagging, Stacking, Boosting, Random \nFores t \nIII) Model Assessments  \nIV) In-Class Exam -2 Topics  \nV) Past In-Class Exam -2 Problems  \n-------------------------------------------------", " -2 Problems  \n------------------------------------------------------------------------------------  \nDetailed Lectures:   \nI) Large p Small n Variable -Selections  \nReview: Variable -Selections for Linear (Normal) Regressions  \n(1) Traditional Problems ( ", "ns for Linear (Normal) Regressions  \n(1) Traditional Problems ( n \u2261 sample size > p \u2261 #x-variables )  \n(a) Stepwise Regression (with Partial F -Tests)  (ISyE \n3030/4031 materials)  \n(b) All-Subsets Regression  (ISyE 3030/4031 materials)  \n(2) Recent Proble", "bsets Regression  (ISyE 3030/4031 materials)  \n(2) Recent Problems ( n < p & n << p ) (our focus in ISyE 4034)  \n(a) Ridge Regression, Lasso, Elastic Net Regularization  \n(b) Adaptive  Lasso and Group Lasso  \n(c) Clustering and Representative -Selection  2", "nd Group Lasso  \n(c) Clustering and Representative -Selection  2 \n New: Variable -Selections for Linear Regressions  \n\u2212 Recent Problems ( n < p & n << p )  \n(a) Ridge Regression, Lasso, Elastic Net Regularization  \n(b) Adaptive Lasso and Group Lasso  \n(c) ", "c Net Regularization  \n(b) Adaptive Lasso and Group Lasso  \n(c) Clustering and Representative -Selection  \nDetails:  3 \n  \nLasso: Least Absolute Shrinkage and Selection Operator  \n----------------------------------------------------------------------------", "---------------------------------------------------------------------  \nII) Resampling and Ensemble Methods  \n(a) Resampling:  Bootstrap and Jackknife  \n4 \n (b) Ensemble Methods: Bagging, Stacking, Boosting, Random \nForest  \nDetails:  \n[1] Purpose of Resam", "king, Boosting, Random \nForest  \nDetails:  \n[1] Purpose of Resampling Methods:  \nIn statistics , resampling  is any of a variety of methods for doing \none of the following:  \n1. Estimating the precision of \nsample  statistics  (medians , variances , percen", " precision of \nsample  statistics  (medians , variances , percentiles ) by using \nsubsets of avail able data ( jackknifing ) or \ndrawing  randomly  with replacement from a set of data \npoints ( bootstrapping ) \n2. Exchanging labels on data points when \nper", "( bootstrapping ) \n2. Exchanging labels on data points when \nperforming  significance tests  (permutation tests , also \ncalled  exact tests , randomization tests, or re -randomization \ntests)  \n3. Validating models by using random subsets \n(bootstrapping, ", " \n3. Validating models by using random subsets \n(bootstrapping,  cross validation ). \n \n[2] Bootstrap Resampling:  5 \n Original Samples: Y orig \u2261{Y 1, Y 2, \u2026, Y n} =eg = {2, 4, 10, \n12, 7} with n = 5 \nBootstrap Samples:  \nPerform a random sampling with rep", "h n = 5 \nBootstrap Samples:  \nPerform a random sampling with replacement to collect n \n\u201cnew data\u201d from the original samples. For example, {4, 7, \n10, 4, 2} could be a set of bootstrap samples. Notice that \u201c4\u201d \nis repeated twice. This  is possible due to th", " Notice that \u201c4\u201d \nis repeated twice. This  is possible due to the \u201csampling \nWITH replacement\u201d procedure.  \nDenoted by the bootstrap samples as  \nY(1) \u2261{Y 1(1), Y 2(1), \u2026, Y n(1)} =eg = {4, 7, 10, 4, 2};  \nY(2) \u2261{Y 1(2), Y 2(2), \u2026, Y n(2)};  \n\u2026 \nY(m) \u2261{Y 1", " 10, 4, 2};  \nY(2) \u2261{Y 1(2), Y 2(2), \u2026, Y n(2)};  \n\u2026 \nY(m) \u2261{Y 1(m), Y 2(m), \u2026, Y n(m)}, \nwhere m is a large number (e.g., 10,000) to facilitate \nfurther distributional studies of the bootstrap samples.  \nBias Evaluation: The procedure explains below is ap", "p samples.  \nBias Evaluation: The procedure explains below is applicable \nfor evaluating bias in any sample -estimate, e.g., sample -\nmean, -median, 90th-percentile.  \n Continue the example  above. Denoted by \u03b8orig_hat as the \nsample -estimate from the ori", "bove. Denoted by \u03b8orig_hat as the \nsample -estimate from the original samples. Then, the \nbootstrapped sample -estimates  are as follows:  6 \n   \u03b8(1)_hat, \u03b8(2)_hat, \u2026, \u03b8(m)_hat,       (1) \nfor each one of the bootstrapped samples Y(i), i = 1, 2, \u2026, \nm, res", " each one of the bootstrapped samples Y(i), i = 1, 2, \u2026, \nm, respectively.  \n Then, get an average ( \u03b8(i)_hat_ave ) of these \nbootstrapped sample -estimates. Bias will be defined as  \n Bias = \u03b8orig_hat \u2212 (\u03b8(i)_hat_ave ), \nwhere the average ( \u03b8(i)_hat_ave )", "\u03b8orig_hat \u2212 (\u03b8(i)_hat_ave ), \nwhere the average ( \u03b8(i)_hat_ave ) acts like the population -\naverage E( \u03b8orig_hat) in evaluating this bias. \nVariance -Estimation: Continue the example above. Based \non m quantities of bootstrapped sample -estimates given in ", "sed \non m quantities of bootstrapped sample -estimates given in \nEq.(1), one can calculate the following bootstrap -variance. \nBy taking a square -root, one obtains the bootstrap \nstandard -deviation (sd).  \n  \u03c3b2_hat = \u03a3 i=1m ( \u03b8(i)_hat \u2212 (\u03b8(i)_hat_ave ) ", "viation (sd).  \n  \u03c3b2_hat = \u03a3 i=1m ( \u03b8(i)_hat \u2212 (\u03b8(i)_hat_ave ) ]2 / ( m \u2013 1 ). \n This bootstrap -variance estimates the population variance \n\u03c32 of the original samples Yorig. \nNote that many people use bootstrap Mean Squared Error , \nMSE = (Bias)2 + Varia", "people use bootstrap Mean Squared Error , \nMSE = (Bias)2 + Variance , to evaluate the quality of \nestimating a population parameter \u03b8 (e.g., mean, median \nor 90th-percentile).  7 \n Various bootstrap -based Confidence Intervals  (CIs) can be \nconstructed fo", "tstrap -based Confidence Intervals  (CIs) can be \nconstructed for estimating population parameter \u03b8. \nStudents of interest should look into lec ture-notes from \nISyE -6404 (Nonparametric Statistic) or Internet -materials.  \n \n[3] Jackknife Resampling:  \nBo", "stic) or Internet -materials.  \n \n[3] Jackknife Resampling:  \nBootstrap -resampling could be computing intensive (and thus, \ntime consuming), the following jackknife -resampling method \nis less computing intensive. Unlike the sampling with \nreplacement boo", "s computing intensive. Unlike the sampling with \nreplacement bootstrap method, Jackknife is NOT sampling \nwith replacement.  \n \nOriginal Samples: Y orig \u2261{Y 1, Y 2, \u2026, Y n} =eg = {2, 4, 10, \n12, 7} with n = 5 \nDelete -1 Jackknife Samples:  \nY(1) \u2261{ 4, 10, ", "2, 7} with n = 5 \nDelete -1 Jackknife Samples:  \nY(1) \u2261{ 4, 10, 12, 7 }, where the first sample \u201c2\u201d is not \nincluded;  \nY(2) \u2261{ 2, 10, 12, 7 }; where the second sample \u201c4\u201d is \nnot included;  \n\u2026 8 \n Y(n) \u2261{ 2, 4, 10, 12 }, where the last sample \u201c4\u201d is not \n", "\u2026 8 \n Y(n) \u2261{ 2, 4, 10, 12 }, where the last sample \u201c4\u201d is not \nincluded.  \nNaturally, it is required to have a large sample size n to \ncreate many Jackknife sam ples. Then, the methods \nintroduced in the bootstrap for estimating bias, \nvariance and MSE ca", "duced in the bootstrap for estimating bias, \nvariance and MSE can be applied to these jackknife \nsamples.  \nRemark: Instead of deleting one sample in creating the \nJackknife re -sample distribution, some people extend this \nmethod to delete -d-Jackknife, w", "ution, some people extend this \nmethod to delete -d-Jackknife, where d-samples (e.g., d = \n2, 3, \u2026) are deleted in each set of Jackknife sample.  \n \n[4] Cross -Validation Resampling:  \nAlthough the bootstrap method is applicable to regression \nproblem, whe", "h the bootstrap method is applicable to regression \nproblem, where each data point includes Y (outcome) and \nmany X j\u2019s (input -variables), many people prefer to use the \nfollowing cross -validation method to evaluate the quality of \nmodel -predictions.  \n", "dation method to evaluate the quality of \nmodel -predictions.  \n \nOriginal Samples: ( Yi,orig, X ij,orig, j = 1, 2, \u2026, p) with i = 1, \n2, \u2026, n for n sets of iid regression samples.  9 \n Cross -validate Estimation:  \nStep -1: Just like the delete -1 Jackkni", "-validate Estimation:  \nStep -1: Just like the delete -1 Jackknife sampling \nprocedure. One regression -data-point is removed \nto create one set of \u201ccross -validated -samples\u201d.  \nStep -2: Use each set of the delete -1 \u201ccross -validated -\nsamples\u201d to build ", "each set of the delete -1 \u201ccross -validated -\nsamples\u201d to build a  regression model; it could be \nlinear, nonlinear, GLM or non -parametric \nregression model. Then, use the \u201cdelete -1-built-\nmodel\u201d to predict the data -point, which was \ndeleted in the mode", "odel\u201d to predict the data -point, which was \ndeleted in the model -building process. Evaluate \nits \u201ccross -validated -prediction -error \u201d. Repe at \nthis process for all n sets of delete -1 \u201ccross -\nvalidated -samples\u201d.  \nStep -3: Calculate the variance fro", "oss -\nvalidated -samples\u201d.  \nStep -3: Calculate the variance from n \u201ccross -validated -\nprediction -errors \u201d. This is the \u201ccross -validation -\nvariance\u201d.  \n \nRemark:  This cross -validation method is popular in \nmodel -selections.  For example, in the \nnon", "thod is popular in \nmodel -selections.  For example, in the \nnonparametric regression there are tuning \nparameters like window -size h in Kernel -\nregression or smoothing -penalty \u03bb in Spline. By 10 \n trying different window -sizes (e.g., h = 0.2, 0.5, \n\u2026)", " By 10 \n trying different window -sizes (e.g., h = 0.2, 0.5, \n\u2026), one obtain their corresponding cross -\nvalidation -variance (e.g., 3.5, 2.7, \u2026). Select the \nh with smallest cross -validation -variance for this \nKernel -regression.  \n---------------------", " -variance for this \nKernel -regression.  \n-----------------------------------------------------------------------------------  \n(b) Ensemble Methods: Bagging, Stacking, Boosting, Random \nForest  \n1) Bagging:  \n \n11 \n  \n \n12 \n  \n13 \n  \n \n14 \n  \n15 \n Boosti", "st  \n1) Bagging:  \n \n11 \n  \n \n12 \n  \n13 \n  \n \n14 \n  \n15 \n Boosting Weight Examples:     Err (1-Err)/Err Alpha_m = Log[(1-Err)/Err] Exp(Alpha_m)   Model-Quality         weight-factor       0.8 0.25 -0.602059991 0.547682253   Not a good model    0.5 1 0 1   ", "0.25 -0.602059991 0.547682253   Not a good model    0.5 1 0 1       0.4 1.5 0.176091259 1.192546884   Good model                  \nAn Algorithm for Random Forest (Tree Constructions):  \n \nAn Example \u2013 Comparison Between Bagging, Random \nForest and Boosting", "xample \u2013 Comparison Between Bagging, Random \nForest and Boosting Procedures:  \n16 \n  \n----------------------------------------------------------------------------------  \nVI) Model Assessment:  \nReference: Hastie, T., Tibshirani, R., and Friedman, J. (2017", "  \nReference: Hastie, T., Tibshirani, R., and Friedman, J. (2017), \nThe Elements of Statistical Learning , Springer, New York. \nNote that this book is a typi cal textbook used in data \nmining or/and machine learning classes.  Downloadable \npdf file: https:", "or/and machine learning classes.  Downloadable \npdf file: https://web.stanford.edu/~hastie/ElemStatLearn/printings/ESLII_print12.pdf  \n \n17 \n  \n18 \n  \n \n19 \n  \n \n \n20 \n  \n \n----------------------------------------------------------------- -----------------", "---------------------------------------------- ------------------  \nVII) In-Class Exam -2 Subjects \u2013 focus on \u201chigh level\u201d concepts  \n \n1. Decision Models (30%)  \n \ni) Decision in An Uncertain Environment (Constrained -\nOptimization Model Formulation)  \nii", " Environment (Constrained -\nOptimization Model Formulation)  \nii) Game -Theoretic Models  \n \n2. Advanced Data Modeling (70%)  \ni) Classification (LDA/QDA, SVM)  \nii) Nonparametric Regression  \niii) Cluster Analysis (K -Means, Multivariate Gaussian \nMixture", "\niii) Cluster Analysis (K -Means, Multivariate Gaussian \nMixtures)  \n21 \n iv) Dimension Reduction (PCA, PLS, MDS, SOM)  \nv) Variable-Selections (Stepwise, All -Subsets, Ridge \nRegression, Lasso)  \nvi) Resampling and Ensemble Methods (Bootstrap \nSampling; C", "o)  \nvi) Resampling and Ensemble Methods (Bootstrap \nSampling; Cross -Validation, Boosting, Random Forest)  \n------------------------------------------------------------------------------------  \nVIII)  Past In -Class Exam -2 Problems:  \nA) True and False ", "-  \nVIII)  Past In -Class Exam -2 Problems:  \nA) True and False Questions  (5 points for each question and \nthere is no partial credit).  \n(True,  False )  1.  In K -means method a data -point could be in \nseveral clusters with different probabilities (sum", " could be in \nseveral clusters with different probabilities (sum to \none).  \nAnswer: False. There is no probability or distribution \nassumption for the K -means method.  \n(True,  False )  2.  AIC metric could be used in the Stepwi se \nRegression.  \nAnswer:", "AIC metric could be used in the Stepwi se \nRegression.  \nAnswer: False. AIC is used in the all -subsets regression. \nStepwise regression is based on the partial -F-tests.  \n (True,  False )  3. In the four ensemble methods (bagging, \nstacking, boosting and", ". In the four ensemble methods (bagging, \nstacking, boosting and random -forest) taught in the 22 \n lectures for regre ssion predictions bagging  is the \nonly procedure uses equal -weights in the average of \npredictions from m = 1000 (eg) individual models", "the average of \npredictions from m = 1000 (eg) individual models \nfitted to re -sampled -data.  \nAnswer: False. Random -forest also uses equal weights to \naverage predictions.  \n(True ,  False)  4.  Whether Y -data is normally or multinominal \ndistributed,", ")  4.  Whether Y -data is normally or multinominal \ndistributed, the results of PCA are the same.  \nAnswer: True. PCA is an unsupervised learning method dealing \nwith only X -data, where Y -data and its distribution \nare not involved . \n(True,  False )  5.", "ta and its distribution \nare not involved . \n(True,  False )  5.  AIC -, BIC - and PRESS -based all -subsets \nregression procedures are applicable to non -normal \ndata and non -linear models. Similarly, the stepwise \nregression procedures have the same pro", "Similarly, the stepwise \nregression procedures have the same properties.  \nAnswer: False. Stepwise regression depends on the normal \ndistribution and linea r model assumptions such that \nthe partial -F-test has an F -distribution.  \n(True,  False )  6.  In", "artial -F-test has an F -distribution.  \n(True,  False )  6.  In the boosting procedure the weights for the \nmis-classified samples from the previous model are 23 \n always more than the weights for the non -mis-\nclassified samples.  \nAnswer: False. In boos", "s for the non -mis-\nclassified samples.  \nAnswer: False. In boosting the weights for the mis -classified \nsamples are more than the weights for correctly \nclassified samples \u2013 this comparison is only valid \nfor a set of samples , i.e., comparison within a ", "is only valid \nfor a set of samples , i.e., comparison within a set of \nsamples, but not between two sets of samp les or \nsamples in different models. This is the property in \nboosting\u2019s algorithm Step -2(c). Thus, the sample -\nweight can be more or less t", "ithm Step -2(c). Thus, the sample -\nweight can be more or less than the weights given \nby the previous model.  \n(True ,  False)  7. When the X -data-columns are organized in \ndifferent seq uences (e.g., X1, X3, X4 versus X4, \nX3, X1), it is possible that f", "ces (e.g., X1, X3, X4 versus X4, \nX3, X1), it is possible that forward -selection \nproduces distinct models (even that alpha -to-enter is \nset at the same value, e.g., 15%).  \nAnswer: True. The partial -F-test in the forward -selections takes \nthe first (a", "e partial -F-test in the forward -selections takes \nthe first (and then , the subsequent) variable(s) from \nthe X -data-columns given by the user. Different \nsequences could produce distinct models.  24 \n (True ,  False)  8. One of the key differences in t", "odels.  24 \n (True ,  False)  8. One of the key differences in the LDA - and \nlogistic -classification is that LDA assumes the \ndistribution of X -variables (as a multivariate \nnormal).  \nAnswer: True. Logistic -classification treats X -variables as given ", "er: True. Logistic -classification treats X -variables as given \nconstants, but LDA assumes them to have a \nmultivariate normal distribution (given a class of \nY). \n(True,  False )  9.  The weights for each one of the m = 100 0 \nstacking -models and boosti", "ights for each one of the m = 100 0 \nstacking -models and boosting -models are found \nbased on certain optimization objectives.  \nAnswer: False. It is true for the stacking method, but not true for \nthe boosting method, where the model -weight is \nassigned", "e for \nthe boosting method, where the model -weight is \nassigned as a given function of \u201cErr (= error rate)\u201d, \nwhere no optimization objective function is used to \nderive the weights.  \n (True,  False )  10.  Even that the covariance between X and Y \nstays", ",  False )  10.  Even that the covariance between X and Y \nstays the same, PLS -results could change depending \non the distribution assumption of Y -data, e.g., log -\nnormal ver sus Weibull or Gamma.  25 \n Answer: False. PLS only works with the covariance ", " Gamma.  25 \n Answer: False. PLS only works with the covariance between X \nand Y. The distribution (e.g., pdf) information is not \ninvolved.  \n(True,  False )  11.  The SVM -classification will minimize the \nmis-classification counts.  \nAnswer: False. The ", "l minimize the \nmis-classification counts.  \nAnswer: False. The SVM maximizes the margin of support -\nvectors  in different classes.  \n(True ,  False)  12.  In all variable -selection procedures taught in \nthe lectures stepwise -regression is the only \nseq", "es taught in \nthe lectures stepwise -regression is the only \nsequential procedure, i.e., the model selected in the \nlatter stage will depend on the model(s) selected in \nthe earlier stage(s).  \nAnswer: True. The partial -F-test used in the stepwise regress", " \nAnswer: True. The partial -F-test used in the stepwise regression \nis a sequential procedure. All other variable -\nselection procedures work with each possible model \nindependently.  \n 1 \n ISyE DDA  \u2013 Agenda for 0 3/16/23 Lecture (Lec. 19) \nI) Cluster An", "SyE DDA  \u2013 Agenda for 0 3/16/23 Lecture (Lec. 19) \nI) Cluster Analysis  \u2013 Multivariate Gaussian Mixtures  \nII) Dimension Reduction (DR)  \nIII) Large p Small n Variable -Selections  \nIV) Resampling and Ensemble Methods  \n(a) Resampling:  Bootstrap and Jackk", "ling and Ensemble Methods  \n(a) Resampling:  Bootstrap and Jackknife  \n(b) Ensemble Methods: Bagging, Stacking, Boosting, Random \nFores t \n------------------------------------------------------------------------------------  \nDetailed Lectures:   \n \n2 \n  \n", "-------------------------------  \nDetailed Lectures:   \n \n2 \n  \nThe Gaussian Mixture Model (GMM) provides \u201csoft \nclustering\u201d or \u201cprobability clustering\u201d results.  \n \n \n \n3 \n  \nRemark: Please  view \u201cy\u201d notation as the index for K distributions, \ni.e., y = 1", "view \u201cy\u201d notation as the index for K distributions, \ni.e., y = 1, 2, \u2026, K. Students can treat this index y as \u201cj\u201d.  We will \nuse the \u201c j\u201d index from now on for representing the j-th probability \ndistribution in the mixture model.  \n \nExamples:  \n4 \n  \nTypi", "y \ndistribution in the mixture model.  \n \nExamples:  \n4 \n  \nTypically, in the GMMs, the following multivariate normal are \nused to model the probability distributions Pj(x|\u03b8j), j = 1, 2, \u2026, K. \n \nRemark: The mean \u03bc and variance -covariance \u2211 in the \nprobab", " \n \nRemark: The mean \u03bc and variance -covariance \u2211 in the \nprobability distributions Pj(x|\u03b8j), j = 1, 2, \u2026, K, should be \u03bc j and \n\u2211j from the     j-th multivariate normal distribution. Note that \n5 \n these means \u03bc j and variance -covariances \u2211 j from differ", "t \n5 \n these means \u03bc j and variance -covariances \u2211 j from different \ndistributions Pj(x|\u03b8j), j = 1, 2, \u2026, K, are usually different.  \n \nUsing the following Expectation -Maximization (EM) Algorithm to \nestimate these model parameters \u03bb j, \u03bcj and \u2211j  for j =", "ithm to \nestimate these model parameters \u03bb j, \u03bcj and \u2211j  for j = 1, 2, \u2026, K. \nDetails of the theoretical background and its derivation are \nskipped here. We provide a graphical presentation of the \nimplementation of the EM algorithm in the GMM parameter \ne", " the \nimplementation of the EM algorithm in the GMM parameter \nestimation process.  \n \nGraphical Presentation  of Implementing the EM -Algorithm in \nGMMs\u2019 Parameter Estimation w ith a K = 3 example:  \n6 \n  \nRemark: Here, \u201c pj =eg= 0.333\u201d is the \u201cweight\u201d \u03bb ", "ample:  \n6 \n  \nRemark: Here, \u201c pj =eg= 0.333\u201d is the \u201cweight\u201d \u03bb j, j = 1, 2, \u2026, \nK =eg= 3. The initial weights are usually equal weights.  \n7 \n  \n \n8 \n  \n \n9 \n  \n \n---------------------------------------------------------------------------------------  \nI)", "-----------------------------------------------------------  \nI) Dimension Reductions (DRs)  \nDimension Reduction (DR) is a school of Unsupervised \nLearning Procedures  (i.e., there is no Y -outcomes data ; only \n10 \n analyze X -data). This class focuses o", "utcomes data ; only \n10 \n analyze X -data). This class focuses on high -level concepts. The \nfollowing are three popular DR procedures.  \n(1) Principal Component Analysis (PCA)  \n(2) Multi -Dimensional Scaling (MDS)  \n(3) Partial Least Squares (PLS)  \nDeta", "mensional Scaling (MDS)  \n(3) Partial Least Squares (PLS)  \nDetails:  \n(1) Principal Component Analysis (PCA)  \nPrincipal components (PC)  of a set of X -data in Rp provide a \nsequence of best linear approximations  to that data , of all ranks q \n\u2264 p. Thes", " linear approximations  to that data , of all ranks q \n\u2264 p. These principal components are mutually uncorrelated and \nordered in variance . See the following figure for an example.  \n \n11 \n Denote the observations by x1, x2, . . . , xN, (each of them is a ", "note the observations by x1, x2, . . . , xN, (each of them is a p-dim \nvector) and consider the following rank -q linear model for \nrepresenting (or approximating) them:  \n \n \nExample  #1 (2-D X-data are projected to the first PC -line):  \nFigure 14.20 sho", " X-data are projected to the first PC -line):  \nFigure 14.20 shows a set of 2 -dimensional data points x1, x2, . . . , \nxN, plotted i n the R^2 space.  PC-Line projects these 2 D data xi's \nonto one-dimensional line with v1 as the direction  with a value \n", "to one-dimensional line with v1 as the direction  with a value \n(Ui1 * d1), and black -dot-point as the center.  Define an objective \nfunction as the sum -of-squares of distances from each point to its \northogonal projection onto the \u201cPC -line\u201d for locatin", "nt to its \northogonal projection onto the \u201cPC -line\u201d for locating the PC -line \n12 \n with the direction v1.  The parameter -vectors \u03bc and \u03bb, and also the  \nresulted lower -rank matrix Vq can be obtained.   \n \nThe solution of the matrix Vq can be expressed ", "e obtained.   \n \nThe solution of the matrix Vq can be expressed as follows. \nStack the (centered) observations into the rows of an N \u00d7 p matrix \nX. We construct the singular value decomposition  of X: X = \nUDVT, where U is an N \u00d7 p  orthogonal matrix ( UTU", "n  of X: X = \nUDVT, where U is an N \u00d7 p  orthogonal matrix ( UTU = Ip) whose \ncolumns uj are called the left singular vectors; V is a p\u00d7p \northogonal matrix ( VTV = Ip) with columns vj called the right \nsingular vectors, and D is a p\u00d7p diagonal matrix, wit", "the right \nsingular vectors, and D is a p\u00d7p diagonal matrix, with diagonal \n13 \n elements d1 \u2265 d2 \u2265 \u00b7 \u00b7 \u00b7 \u2265 d p \u2265 0 known as the singular values. For \neach rank q, the solution Vq consists of the first q columns of V. \nThe columns of UD are called the prin", "the first q columns of V. \nThe columns of UD are called the principal components of X. \nThe N optimal \u03bb i\u2019s (elements in the vector \u03bb) are given by the first \nq principal components (the N rows of the N \u00d7 q  matrix UqDq ).  \nImportant Remark:  Each princip", "s of the N \u00d7 q  matrix UqDq ).  \nImportant Remark:  Each principal component is a linearly \nweighted sum of the original p-data-columns  X. Note that the \noriginal data variances is decomposed into p variances d1 \u2265 d2 \u2265 \u00b7 \u00b7 \u00b7 \n\u2265 dp \u2265 0 \u201corthogonally.\u201d  The", " into p variances d1 \u2265 d2 \u2265 \u00b7 \u00b7 \u00b7 \n\u2265 dp \u2265 0 \u201corthogonally.\u201d  The data represented by the j-th principal \ncomponent captures dj amount of variance.   \nExample #2  (3-D X-data are projected to the first two PCs) : \n \n14 \n  \n \n \n \n15 \n  \n \n16 \n  \n \n17 \n  \n---", "he first two PCs) : \n \n14 \n  \n \n \n \n15 \n  \n \n16 \n  \n \n17 \n  \n---------------------------------------------------------------------------------  \nII) Large p Small n Variable -Selections  \nReview: Variable -Selections for Linear (Normal) Regressions  \n(1) T", "ew: Variable -Selections for Linear (Normal) Regressions  \n(1) Traditional Problems ( n  \u2261 sample size > p \u2261 #x -variables )  \n(a) Stepwise Regression (with Partial F -Tests)  (ISyE \n3030/4031 materials)  \n(b) All-Subsets Regression  (ISyE 3030/4031 materi", " materials)  \n(b) All-Subsets Regression  (ISyE 3030/4031 materials)  \n(2) Recent Problems ( n < p & n << p ) (our focus in ISyE 4034)  \n(a) Ridge Regression, Lasso, Elastic Net Re gularization  \n(b) Adaptive Lasso and Group Lasso  \n(c) Clustering and Repr", "n  \n(b) Adaptive Lasso and Group Lasso  \n(c) Clustering and Representative -Selection  \n---------------------------------------------------------------------------------------  \nNew: Variable -Selections for Linear Regressions  \n\u2212 Recent Problems ( n < p &", "-Selections for Linear Regressions  \n\u2212 Recent Problems ( n < p & n << p )  \n(a) Ridge Regression, Lasso, Elastic Net Regularization  \n18 \n (b) Adaptive Lasso and Group Lasso  \n(c) Clustering and Representative -Selection  \nDetails:  \n \nLasso: Least Absolut", "nd Representative -Selection  \nDetails:  \n \nLasso: Least Absolute Shrinkage and Selection Operator  \n19 \n IV) Resampling and Ensemble Methods  \n(a) Resampling:  Bootstrap and Jackknife  \n(b) Ensemble Methods: Bagging, Stacking, Boosting, Random \nForest  \nD", "nsemble Methods: Bagging, Stacking, Boosting, Random \nForest  \nDetails:  \n[1] Purpose of Resampling Methods:  \nIn statistics , resampling  is any of a variety of methods for doing \none of the following:  \n1. Estimating the precision of \nsample  statistics ", "following:  \n1. Estimating the precision of \nsample  statistics  (medians , variances , percentiles ) by using \nsubsets of available data ( jackknifing ) or \ndrawing  randomly  with replacement from a set of data \npoints ( bootstrapping ) \n2. Exchanging la", "t from a set of data \npoints ( bootstrapping ) \n2. Exchanging labels on data points when \nperforming  significance tests  (permutation tests , also \ncalled  exact tests , randomization tests, or re-randomization \ntests)  \n3. Validating models by using rand", "or re-randomization \ntests)  \n3. Validating models by using random subsets \n(bootstrapping,  cross validation ). \n 20 \n [2] Bootstrap Resampling:  \nOriginal Samples: Y orig \u2261{Y 1, Y 2, \u2026, Y n} =eg = {2, 4, 10, \n12, 7} with n = 5 \nBootstrap Samples:  \nPerfo", " =eg = {2, 4, 10, \n12, 7} with n = 5 \nBootstrap Samples:  \nPerform a random sampling with replacement to collect n \n\u201cnew data\u201d from the original samples. For example, {4, 7, \n10, 4, 2} could be a set of bootstrap samples. Notice that \u201c4\u201d \nis repeated twice", "e a set of bootstrap samples. Notice that \u201c4\u201d \nis repeated twice. This is possible due to the \u201csampling \nWITH replacement\u201d procedure.  \nDenoted by the bootstrap samples as  \nY(1) \u2261{Y 1(1), Y 2(1), \u2026, Y n(1)} =eg = {4, 7, 10, 4, 2};  \nY(2) \u2261{Y 1(2), Y 2(2),", "(1), \u2026, Y n(1)} =eg = {4, 7, 10, 4, 2};  \nY(2) \u2261{Y 1(2), Y 2(2), \u2026, Y n(2)};  \n\u2026 \nY(m) \u2261{Y 1(m), Y 2(m), \u2026, Y n(m)}, \nwhere m is a large number (e.g., 10,000) to facilitate \nfurther distributional studies of the bootstrap samples.  \nBias Evaluation: The pr", "onal studies of the bootstrap samples.  \nBias Evaluation: The procedure explains below is applicable \nfor evaluating bias in any sample -estimate, e.g., sample -\nmean, -median, 90th-percentile.  21 \n  Continue the example above. Denoted by \u03b8orig_hat as the", ".  21 \n  Continue the example above. Denoted by \u03b8orig_hat as the \nsample -estimate from the original samples. Then, t he \nbootstrapped sample -estimates  are as follows:  \n  \u03b8(1)_hat, \u03b8(2)_hat, \u2026, \u03b8(m)_hat,       (1) \nfor each one of the bootstrapped sampl", ", \u2026, \u03b8(m)_hat,       (1) \nfor each one of the bootstrapped samples Y(i), i = 1, 2, \u2026, \nm, respectively.  \n Then, get an average ( \u03b8(i)_hat_ave ) of these \nbootstrapped sample -estimates. Bias will be defined as  \n Bias = \u03b8orig_hat \u2212 (\u03b8(i)_hat_ave ), \nwhere", "will be defined as  \n Bias = \u03b8orig_hat \u2212 (\u03b8(i)_hat_ave ), \nwhere the average ( \u03b8(i)_hat_ave ) acts like the population -\naverage E( \u03b8orig_hat) in evaluating this bias.  \nVariance -Estimation: Continue the example above. Based \non m quantities of bootstrapp", "Continue the example above. Based \non m quantities of bootstrapped sample -estimates given in \nEq.(1), one can calculate the following bootstrap -variance. \nBy taking a square -root, one obtains the bootstrap \nstandard -deviation (sd).  \n  \u03c3b2_hat = \u03a3 i=1m", "ns the bootstrap \nstandard -deviation (sd).  \n  \u03c3b2_hat = \u03a3 i=1m ( \u03b8(i)_hat \u2212 (\u03b8(i)_hat_ave ) ]2 / ( m \u2013 1 ). \n This bootstrap -variance estimates the population variance \n\u03c32 of the original samples Yorig. 22 \n Note that many people use bootstrap Mean Squa", "amples Yorig. 22 \n Note that many people use bootstrap Mean Squared Error , \nMSE = (Bias)2 + Variance , to evaluate the quality of \nestimating a population parameter \u03b8 (e.g., mean, median \nor 90th-percentile).  \nVarious bootstrap -based Confidence Interval", "90th-percentile).  \nVarious bootstrap -based Confidence Intervals  (CIs) can be \nconstructed for estimating population parameter \u03b8. \nStudents of interest should look into lec ture-notes from \nISyE -6404 (Nonparametric Statistic) or Internet -materials.  \n ", "ISyE -6404 (Nonparametric Statistic) or Internet -materials.  \n \n[3] Jackknife Resampling:  \nBootstrap -resampling could be computing intensive (and thus, \ntime consuming), the following jackknife -resampling method \nis less computing intensive. Unlike the", "nife -resampling method \nis less computing intensive. Unlike the sampling with \nreplacement bootstrap method, Jackknife is NOT sampling \nwith replacement.  \n \nOriginal Samples: Y orig \u2261{Y 1, Y 2, \u2026, Y n} =eg = {2, 4, 10, \n12, 7} with n = 5 \nDelete -1 Jackk", " 2, \u2026, Y n} =eg = {2, 4, 10, \n12, 7} with n = 5 \nDelete -1 Jackknife Samples:  \nY(1) \u2261{ 4, 10, 12, 7 }, where the first sample \u201c2\u201d is not \nincluded;  23 \n Y(2) \u2261{ 2, 10, 12, 7 }; where the second sample \u201c4\u201d is \nnot included;  \n\u2026 \nY(n) \u2261{ 2, 4, 10, 12 }, wh", "ond sample \u201c4\u201d is \nnot included;  \n\u2026 \nY(n) \u2261{ 2, 4, 10, 12 }, where the last sample \u201c4\u201d is not \nincluded.  \nNaturally, it is required to have a large sample size n to \ncreate many Jackknife sam ples. Then, the methods \nintroduced in the bootstrap for estim", "m ples. Then, the methods \nintroduced in the bootstrap for estimating bias, \nvariance and MSE can be applied to these jackknife \nsamples.  \nRemark: Instead of deleting one sample in creating the \nJackknife re -sample distribution, some people extend this \n", "he \nJackknife re -sample distribution, some people extend this \nmethod to delete -d-Jackknife, where d-samples (e.g., d = \n2, 3, \u2026) are deleted in each set of Jackknife sample.  \n \n[4] Cross -Validation Resampling:  \nAlthough the bootstrap method is applic", "Validation Resampling:  \nAlthough the bootstrap method is applicable to regression \nproblem, where each data point includes Y (outcome) and \nmany X j\u2019s (input -variables), many people prefer to use the 24 \n following cross -validation method to evaluate th", "o use the 24 \n following cross -validation method to evaluate the quality of \nmodel -predictions.  \n \nOriginal Samples: ( Yi,orig, X ij,orig, j = 1, 2, \u2026, p) with i = 1, \n2, \u2026, n for n sets of iid  regression samples.  \nCross -validate Estimation:  \nStep -", " iid  regression samples.  \nCross -validate Estimation:  \nStep -1: Just like the delete -1 Jackknife sampling \nprocedure. One regression -data-point is removed \nto create one set of \u201ccross -validated -samples\u201d.  \nStep -2: Use each set of the delete -1 \u201ccro", "lidated -samples\u201d.  \nStep -2: Use each set of the delete -1 \u201ccross -validated -\nsamples\u201d to build a regression model; it could be \nlinear, nonlinear, GLM or non -parametric \nregression model. Then, use the \u201cdelete -1-built-\nmodel\u201d to predict the data -poin", "Then, use the \u201cdelete -1-built-\nmodel\u201d to predict the data -point, which was \ndeleted in the model -building process. Evaluate \nits \u201ccross-validated -prediction -error \u201d. Repeat \nthis process for all n sets of delete -1 \u201ccross -\nvalidated -samples\u201d.  \nStep", "for all n sets of delete -1 \u201ccross -\nvalidated -samples\u201d.  \nStep -3: Calculate the variance from n \u201ccross -validated -\nprediction -errors \u201d. This is the \u201ccross -validation -\nvariance\u201d.  \n 25 \n Remark:  This cross -validation me thod is popular in \nmodel -s", " Remark:  This cross -validation me thod is popular in \nmodel -selections. For example, in the \nnonparametric regression there are tuning \nparameters like window -size h in Kernel -\nregression or smoothing -penalty \u03bb in Spline. By \ntrying different window ", " or smoothing -penalty \u03bb in Spline. By \ntrying different window -sizes (e.g., h = 0.2, 0.5, \n\u2026), one obtain the ir corresponding cross -\nvalidation -variance (e.g., 3.5, 2.7, \u2026). Select the \nh with smallest cross -validation -variance for this \nKernel -reg", " with smallest cross -validation -variance for this \nKernel -regression.  \n-----------------------------------------------------------------------------------  \n(b) Ensemble Methods: Bagging, Stacking, Boosting, Random \nForest  \n1) Bagging:  \n \n26 \n  \n \n27", "Stacking, Boosting, Random \nForest  \n1) Bagging:  \n \n26 \n  \n \n27 \n  \n \n \n1 \n ISyE DDA  \u2013 Agenda for 0 3/14/23 Lecture (Lec. 18) \nI) Nonparametric (NP) Regressions  - Spline  \nII) Unsupervised Learning - Cluster Analysis   \nIII) Dimension Reduction (DR)  \nI", "Learning - Cluster Analysis   \nIII) Dimension Reduction (DR)  \nIV) Large p Small n Variable -Selection s \n------------------------------------------------------------------------------------  \nDetailed Lectures:   \nI) Nonparametric Regression s: \n(1) Kerne", "\nDetailed Lectures:   \nI) Nonparametric Regression s: \n(1) Kernel Regression (presented ) \n(2) Nearest -Neighbor NP -Regression  (presented ) \n(3) Splines  (new)  \n \nDetails:  \n(3) Splines  \nInterpolating splines  and smoothing splines  are motivated from ", "nterpolating splines  and smoothing splines  are motivated from \na different perspective than kernels and local polynomials; in the \nlatter case, we started off with a special kind of local averaging  \nand moved our way up to a higher -order local models. ", "eraging  \nand moved our way up to a higher -order local models. With \nsplines , we build up our estimate globally , from a set of select \nbasis functions . \n  These basis funct ions, as you might guess, are splines. \nLet\u2019s assume that d = 1  for one input ", "ght guess, are splines. \nLet\u2019s assume that d = 1  for one input variable , for simplicity.  A k-2 \n th order spline  is a piecewise polynomial function of degree k , \nthat is continuous and has continuous derivatives of orders 1, . . .,  \n k \u2212 1, at its kn", "s continuous derivatives of orders 1, . . .,  \n k \u2212 1, at its knot points . Please see below for details.  \n \n \n \n3 \n  \nRemarks:  It turns out that the cubic spline is in some sense \nasymptotically equivalent to a kernel regression, with an unusual \nchoice", "cally equivalent to a kernel regression, with an unusual \nchoice of kernel, \u201cSilverman kernel\u201d (Silverman, 1984).  \n \n4 \n  \n \n \n5 \n  \n \n\u201cTextbook\u201d: Kvam, Vidakovic and Kim  (2016) , Nonparametric \nStatistics with Applications in Science and Engineering, Jo", "ric \nStatistics with Applications in Science and Engineering, Joh n \nWiley. (ISBN: 978 -0-470-08147 -1). \n6 \n II) Unsupervised Learning  \n(1)   Clustering Analysis  \n \n-------------------------------------------------------------------------------  \n \n7 \n ", "-------------------------------------------------------  \n \n7 \n  \n \n \n8 \n  \n \n \n9 \n  \n10 \n  \n---------------------------------------------------------------------------  \n \n \n11 \n  \n12 \n  \n \n13 \n  \n \nThe Gaussian Mixture Model (GMM) provides \u201csoft \ncluster", "3 \n  \n \nThe Gaussian Mixture Model (GMM) provides \u201csoft \nclustering\u201d or \u201cprobability clustering\u201d results.  \n \n14 \n  \n \nRemark: Please  view \u201cy\u201d notation as the index for K distributions, \ni.e., y = 1, 2, \u2026, K. Students can treat this index y as \u201cj\u201d.  We wi", ", y = 1, 2, \u2026, K. Students can treat this index y as \u201cj\u201d.  We will \n15 \n use the \u201c j\u201d index from now on for representing the j-th probability \ndistribution in the mixture model.  \n \nExamples:  \n \nTypically, in the GMMs, the following multivariate normal ar", " \n \nTypically, in the GMMs, the following multivariate normal are \nused to model the probability distributions Pj(x|\u03b8j), j = 1, 2, \u2026, K. \n \n16 \n Remark: The mean \u03bc and variance -covariance \u2211 in the \nprobability distributions Pj(x|\u03b8j), j = 1, 2, \u2026, K, shoul", "n the \nprobability distributions Pj(x|\u03b8j), j = 1, 2, \u2026, K, should be \u03bc j and \n\u2211j from the     j-th multivariate normal distribution. Note that \nthese means \u03bc j and variance -covariances \u2211 j from different \ndistributions Pj(x|\u03b8j), j = 1, 2, \u2026, K, are usuall", "om different \ndistributions Pj(x|\u03b8j), j = 1, 2, \u2026, K, are usually different.  \n \nUsing the following Expectation -Maximization (EM) Algorithm to \nestimate these model parameters \u03bb j, \u03bcj and \u2211j  for j = 1, 2, \u2026, K. \nDetails of the theoretical background and", "  for j = 1, 2, \u2026, K. \nDetails of the theoretical background and its derivation are \nskipped here. We provide a graphical presentation of the \nimplementation of the EM algorithm in the GMM parameter \nestimation process.  17 \n  \nGraphical Presentation  of I", "ameter \nestimation process.  17 \n  \nGraphical Presentation  of Implementing the EM -Algorithm in \nGMMs\u2019 Parameter Estimation w ith a K = 3 example:  \n18 \n  \nRemark: Here, \u201c pj =eg= 0.333\u201d is the \u201cweight\u201d \u03bb j, j = 1, 2, \u2026, \nK =eg= 3. The initial weights are", "he \u201cweight\u201d \u03bb j, j = 1, 2, \u2026, \nK =eg= 3. The initial weights are usually equal weights.  \n19 \n  \n \n20 \n  \n \n21 \n  \n \n----------------------------- ----------------------------------------------------------  \nIII) Dimension Reductions  (DRs)  \nDimension Red", "-------------  \nIII) Dimension Reductions  (DRs)  \nDimension Reduction (DR) is a school of Unsupervised \nLearning Procedures  (i.e., there is no Y -outcomes data ; only \n22 \n analyze X -data). This class focuses on high -level concepts. The \nfollowing are ", " This class focuses on high -level concepts. The \nfollowing are three popular DR procedures.  \n(1) Principal Component Analysis (PCA)  \n(2) Multi -Dimensional Scaling (MDS)  \n(3) Partial Least Squares (PLS)  \nDetails:  \n(1) Principal Component Analysis (PC", " Squares (PLS)  \nDetails:  \n(1) Principal Component Analysis (PCA)  \nPrincipal components (PC)  of a set of X-data in Rp provide a \nsequence of best linear approximations  to that data , of all ranks q \n\u2264 p. These principal components are mutually uncorrel", "l ranks q \n\u2264 p. These principal components are mutually uncorrelated and \nordered in variance . See the following figure for an example.  \n \n23 \n Denote the observations by x1, x2, . . . , xN, (each of them is a p-dim \nvector) and consider the following ra", " (each of them is a p-dim \nvector) and consider the following rank -q linear model for \nrepresenting (or approximating) them:  \n \n \nExample  #1 (2-D X-data are projected to the first PC -line):  \nFigure 14.20 shows a set of 2 -dimensional data points x1, x", ":  \nFigure 14.20 shows a set of 2 -dimensional data points x1, x2, . . . , \nxN, plotted i n the R^2 space.  PC-Line projects these 2 D data xi's \nonto one-dimensional line with v1 as the direction  with a value \n(Ui1 * d1), and black -dot-point as the cent", "tion  with a value \n(Ui1 * d1), and black -dot-point as the center.  Define an objective \nfunction as the sum -of-squares of distances from each point to its \northogonal projection onto the \u201cPC -line\u201d for locating the PC -line \n24 \n with the direction v1. ", "C -line\u201d for locating the PC -line \n24 \n with the direction v1.  The parameter -vectors \u03bc and \u03bb, and also the  \nresulted lower -rank matrix Vq can be obtained.   \n \nThe solution of the matrix Vq can be expressed as follows. \nStack the (centered) observatio", "Vq can be expressed as follows. \nStack the (centered) observations into the rows of an N \u00d7 p matrix \nX. We construct the singular value decomposition  of X: X = \nUDVT, where U is an N \u00d7 p  orthogonal matrix ( UTU = Ip) whose \ncolumns uj are called the left", "hogonal matrix ( UTU = Ip) whose \ncolumns uj are called the left singular vectors; V is a p\u00d7p \northogonal matrix ( VTV = Ip) with columns vj called the right \nsingular vectors, and D is a p\u00d7p diagonal matrix, with diagonal \n25 \n elements d1 \u2265 d2 \u2265 \u00b7 \u00b7 \u00b7 \u2265 ", "diagonal matrix, with diagonal \n25 \n elements d1 \u2265 d2 \u2265 \u00b7 \u00b7 \u00b7 \u2265 d p \u2265 0 known as the singular values. For \neach rank q, the solution Vq consists of the first q columns of V. \nThe columns of UD are called the principal components of X. \nThe N optimal \u03bb i\u2019s ", " are called the principal components of X. \nThe N optimal \u03bb i\u2019s (elements in the vector \u03bb) are given by the first \nq principal components (the N rows of the N \u00d7 q  matrix UqDq ).  \nImportant Remark:  Each principal component is a linearly \nweighted sum of ", "emark:  Each principal component is a linearly \nweighted sum of the original p-data-columns  X. Note that the \noriginal data variances is decomposed into p variances d1 \u2265 d2 \u2265 \u00b7 \u00b7 \u00b7 \n\u2265 dp \u2265 0 \u201corthogonally.\u201d  The data represented by the j-th principal \ncom", "\u201corthogonally.\u201d  The data represented by the j-th principal \ncomponent captures dj amount of variance.   \nExample #2  (3-D X-data are projected to the first two PCs) : \n \n26 \n  \n \n \n \n27 \n  \n \n28 \n  \n \n29 \n  \n-----------------------------------------------", "\n28 \n  \n \n29 \n  \n---------------------------------------------------------------------------------  \nIV) Large p Small n Variable -Selections  \nReview: Variable -Selections for Linear (Normal) Regressions  \n(1) Traditional Problems ( n  \u2261 sample size > p \u2261", " Regressions  \n(1) Traditional Problems ( n  \u2261 sample size > p \u2261 #x -variables )  \n(a) Stepwise Regression (with Partial F -Tests)  (ISyE \n3030/4031 materials)  \n(b) All-Subsets Regression  (ISyE 3030/4031 materials)  \n(2) Recent Problems ( n < p & n << p ", "SyE 3030/4031 materials)  \n(2) Recent Problems ( n < p & n << p ) (our focus in ISyE 4034)  \n(a) Ridge Regression, Lasso, Elastic Net Regularization  \n(b) Adaptive Lasso and Group Lasso  \n(c) Clustering and Representative -Selection  \n---------------------", "Clustering and Representative -Selection  \n---------------------------------------------------------------------------------------  \nNew: Variable -Selections for Linear Regressions  \n\u2212 Recent Problems ( n < p & n << p )  \n(a) Ridge Regression, Lasso, Elas", " Problems ( n < p & n << p )  \n(a) Ridge Regression, Lasso, Elastic Net Regularization  \n30 \n (b) Adaptive Lasso and Group Lasso  \n(c) Clustering and Representative -Selection  \nDetails:  \n \nLasso: Leas t Absolute Shrinkage and Selection Operato r \n1 \n ISy", "asso: Leas t Absolute Shrinkage and Selection Operato r \n1 \n ISyE DDA  \u2013 Agenda for 0 3/09/23 Lecture (Lec. 17) \nI) Advanced Data Modeling \u2013 Classifications  \nA) Statistical Classification Procedures:  \nB) Computing/Optimization Based Classification Proced", "cedures:  \nB) Computing/Optimization Based Classification Procedures  \n(a) Separating Hyperplane  (done ) \n(b) Support Vector Machine  (done)  \n(c) Decision Tree  (done)  \n(d) Artificial Neural Network (ANN)  (done)  \n(e) K-Neararest Neighbor ( kNN) \nII) N", "l Network (ANN)  (done)  \n(e) K-Neararest Neighbor ( kNN) \nII) Nonpa rametric (NP) Regressions  \nIII) Cluster Anal ysis \n------------------------------------------------------------------------------------  \nDetailed Lectures:   \nI) Classifications  - K-Ne", "-------------  \nDetailed Lectures:   \nI) Classifications  - K-Neararest Neighbor ( kNN) \nGiven a query point x0-vec (to be classified), the kNN-classifier \nfinds the k data points x(r)-vec, r = 1, 2, \u2026, k (=eg= 5) closest in \ndistance to x0-vec, and then c", "= 1, 2, \u2026, k (=eg= 5) closest in \ndistance to x0-vec, and then classify using majority vote among the k \nneighbors.  \nIn selecting these k neighbors, data with distances that are tied \nwill be selected at random . For simplicity, we will assume that all x ", " selected at random . For simplicity, we will assume that all x -\nvariables are real -valued, and use the following Euclidean distance \nin the x -variable space:  2 \n d(i) = || x(i)-vec \u2212 x0-vec || \n= Sqrt[ ( x(i)1 \u2212 x01)2 + (x(i)2 \u2212 x02)2 + \u2026 + ( x(i)p \u2212 ", "ec || \n= Sqrt[ ( x(i)1 \u2212 x01)2 + (x(i)2 \u2212 x02)2 + \u2026 + ( x(i)p \u2212 x0p)2 ]. \nThe following shows two examples with k = 15 and 1. Note that \nthe figure in the bottom with k = 1 has very rugged decision -\nboundaries. The decision -boundaries for the k = 15 case", "ision -\nboundaries. The decision -boundaries for the k = 15 case is much \nsmoother. One can use either cross -validation or test -data to \nevaluat e their #mis -classifications to decide the best k to use for a \nparticular data set. We will introduce these", "est k to use for a \nparticular data set. We will introduce these model -assessment \nprocedures later.  \n \n3 \n  \n \n----------------------------------------------------------------------------------  \nII) Nonparametric Regression s: \n(1) Kernel Regression  \n", "----  \nII) Nonparametric Regression s: \n(1) Kernel Regression  \n(2) Nearest -Neighbor NP -Regression  \n(3) Splines  \nDetails:  \n4 \n  \nNote: m(x) is the mean function.  \n \n5 \n  \n \nFigure 11.4: (a) Normal and (b) Triangular Kernel Functions  \n \nFigure 11.4: ", "(a) Normal and (b) Triangular Kernel Functions  \n \nFigure 11.4: (c) Box and (b) Epanechnickov Kernel Functions  \n \n \n \n6 \n  \nThe following introduce s a few popular kernel regression estimators .  \n \n \n7 \n  \n \n \nRemarks for Kernel Bandwidth - Bias and Vari", "s .  \n \n \n7 \n  \n \n \nRemarks for Kernel Bandwidth - Bias and Variance Tradeoffs : \n1) Smaller width : few observations  in the \u201cwindow/band\u201d , each \ncontribution is closer to x 0: Leads to higher variance \n8 \n (estimated function will vary a lot), but lower", "er variance \n8 \n (estimated function will vary a lot), but lower bias  (i.e., \ncaptures more details of data patterns) . \n2) Larger width  leads to lower variance due to average of more \nobservations ; but the bias is larger - observations from further \naw", "vations ; but the bias is larger - observations from further \naway contribute to the estimated function at x 0. \nRemark s:  \n[1] Cross -Validation  is a common tool to select the \u201cbest\u201d  \ntuning parameter h.  \n \n Find h to minimize the above cross -validat", "ng parameter h.  \n \n Find h to minimize the above cross -validated MSE (cMSE).  \n \n[2] Other method for deciding h involves asymptotic MISE \n(mean integrated square error) defined as follows.  \n9 \n  \nDetails of MISE calculation is skipped. Because there is", " \n9 \n  \nDetails of MISE calculation is skipped. Because there is a \nlot of work  involved in estimating the MISE for model \nvalidation and comparisons. Thus, this class uses cross -\nvalidation to select the optimal bandwidth h. \n---------------------------", " to select the optimal bandwidth h. \n-----------------------------------------------------------------------------------  \n(2) Nearest -Neighbor NP -Regression  \n \n10 \n  \n11 \n  \n12 \n  \n-----------------------------------------------------------------------", "-----------------------------------------------------------------------------  \n(3) Splines  \nInterpolating splines  and smoothing splines  are motivated from \na different perspective than kernels and local polynomials; in the \nlatter case, we started off ", "nels and local polynomials; in the \nlatter case, we started off with a special kind of local averaging  \nand moved our way up to a higher -order local models. With \n13 \n splines , we build up our estimate globally , from a set of select \nbasis functions . ", "our estimate globally , from a set of select \nbasis functions . \n  These basis functions, as you might guess, are splines. \nLet\u2019s assume that d = 1  for one input variable , for simplicity.  A k-\nth order spline  is a piecewise polynomial function of degre", " k-\nth order spline  is a piecewise polynomial function of degree k , \nthat is continuous and has continuous derivatives of orders 1, . . .,  \n k \u2212 1, at its knot points . Please see below for details.  \n \n \n \n14 \n  \nRemarks:  It turns out that the cubic s", " details.  \n \n \n \n14 \n  \nRemarks:  It turns out that the cubic spline is in some sense \nasymptotically equivalent to a kernel regression, with an unusual \nchoice of kernel, \u201cSilverman kernel\u201d (Silverman, 1984).  \n \n15 \n  \n \n \n16 \n  \n \n\u201cTextbook\u201d: Kvam, Vid", "(Silverman, 1984).  \n \n15 \n  \n \n \n16 \n  \n \n\u201cTextbook\u201d: Kvam, Vidakovic and Kim  (2016), Nonparametric \nStatistics with Applications in Science and Engineering, Joh n \nWiley.  (ISBN: 978 -0-470-08147 -1). \n17 \n III) Unsupervised Learning  \n(1)   Clustering ", "-08147 -1). \n17 \n III) Unsupervised Learning  \n(1)   Clustering Analysis  \n \n-------------------------------------------------------------------------------  \n \n18 \n  \n \n \n19 \n  \n \n \n20 \n  \n21 \n  \n1 \n ISyE DDA  \u2013 Agenda for 0 3/07/23 Lecture (Lec. 16) \nAdv", " \n  \n1 \n ISyE DDA  \u2013 Agenda for 0 3/07/23 Lecture (Lec. 16) \nAdvanced Data Modeling \u2013 Classifications  \nA)  Statistical Classification Procedures:  \n(a) Bayes Classifier  (done)  \n(b) Discriminant Analysis: LDA/QDA/RDA (done)  \n(c) Na\u00efve Bayes Classifier  ", "nant Analysis: LDA/QDA/RDA (done)  \n(c) Na\u00efve Bayes Classifier  (done)  \n(d) Multinomial/ Logistic Regression Based Classification  \nB) Computing/Optimization Based Classification Procedures  \n(e) Separating Hyperplane  \n(f) Support Vector Machine  \n(g) De", "\n(e) Separating Hyperplane  \n(f) Support Vector Machine  \n(g) Decision Tree  \n(h) Artificial Neural Network (ANN)  \n(i) K-Neararest Neighbor ( kNN) \n------------------------------------------------------------------------------------  \nDetailed Lectures:  ", "-----------------------------------------  \nDetailed Lectures:   \n1. Advanced Data Modeling  - Classifications  \n------------------------------------------------------------------------------------  \nDetails:    \n(d) Multinomial/ Logistic Regression Based ", "-----  \nDetails:    \n(d) Multinomial/ Logistic Regression Based Classifications  \nStep-1: Focus on an example with K = 5 class es. When there are \nmore than two classes, instead of using a logistic regression to 2 \n fit the class Y -data, multinomial regre", "istic regression to 2 \n fit the class Y -data, multinomial regression should be used to \nfit the data. There will be multiple logit -transformation to link \n\u03c0j = Pr(Y = class j =eg= office dress) to regression functions \nfor classes, j = 1, 2, \u2026, K and \u2211 j", "ss) to regression functions \nfor classes, j = 1, 2, \u2026, K and \u2211 j=1K \u03c0j = 1. For example,  \n  loge[ Pr(Y = class = j) / Pr(Y = class = 1) ] \n  = \u03b20j + \u03b21j x1 + \u03b22j x2 + \u2026 + \u03b2 pj x1, \nwhere x1, x2, \u2026, xp, are p explanatory variables associated for \nall class", "x2, \u2026, xp, are p explanatory variables associated for \nall classes Y -data, and \u03b2 0j, \u03b21j, \u03b22j, \u2026, \u03b2 pj are (p + 1) \ncoefficients in the above logit -regression function for class -j \nagainst class -1 for j = 2, 3, \u2026, K (=eg= 5). Note that we use \nclass -1", "class -1 for j = 2, 3, \u2026, K (=eg= 5). Note that we use \nclass -1 as the \u201cbase\u201d for the \u201codd -ratio\u201d Pr(Y = class = j) / \nPr(Y = class = 1) against all other classes. With K = 5, there \nwill be FOUR logit -transformations with j = 2, 3, 4, 5 = K in \nthis mu", " FOUR logit -transformations with j = 2, 3, 4, 5 = K in \nthis multinomial regression. In each one of these logit -\nregressions, their regression coefficients \u03b2 0j, \u03b21j, \u03b22j, \u2026, \u03b2 pj will \nbe different for distinct class, j = 2, 3, \u2026, K. 3 \n  Similar to the", "ifferent for distinct class, j = 2, 3, \u2026, K. 3 \n  Similar to the logistic regression, parameters are estimated \nvia the maximum likelihood estimation (MLE) method. There, \none needs to replace the Bernoulli distribution with the \nmultin omial distribution ", " the Bernoulli distribution with the \nmultin omial distribution and replace the distribution \nparameters \u03c0 j = Pr(Y = class j), j = 1, 2, \u2026, K, \u2211j=1K \u03c0j = 1, \nwith th ose multiple logit -regressions discussed above.  Then, \nemploy a numerical method such a", "ssions discussed above.  Then, \nemploy a numerical method such as Newton -Raphson method \nto optimize log -likelihood with respect to the regression \ncoefficients. Predictions \u03c0 j_hat = Pr(Y = class j)_hat, j = 1, 2, \n\u2026, K, can then be obtained by replacin", " class j)_hat, j = 1, 2, \n\u2026, K, can then be obtained by replacing the unknown beta -\ncoefficients  with their MLEs.  \n For classifying a new data point (Y 0, x10, x20, \u2026, x p0) to a \nclass, one use the new set of explanatory variables ( x10, x20, \u2026, \nxp0) ", "e use the new set of explanatory variables ( x10, x20, \u2026, \nxp0) to predict this case\u2019s class -probabilities \u03c0 j_hat = Pr(Y 0 = \nclass j)_hat, for all K classes with j = 1, 2, \u2026, K. Then, a \nsimple decision rule for classification is  4 \n  \u201cassign this data", "mple decision rule for classification is  4 \n  \u201cassign this data case to class m if its class -probability  \n  \u03c0m_hat = Pr(Y 0 = class m)_hat is the highest  \n compared to all other class -probabilities\u201d,  \nwhere m is one of the  members in j = 1, 2, \u2026, K.", "babilities\u201d,  \nwhere m is one of the  members in j = 1, 2, \u2026, K.  \nRemark:  \n[1] Multinomial/Logistic regression based  classification \nprocedures are statistical procedures (why?), but they are not \nBayes Classifiers (why?).  \n[2] When misclassification c", "re not \nBayes Classifiers (why?).  \n[2] When misclassification costs are provided, one can develop a \ncost-based decision rule other than the one assign a data class \nwith the highest clas s-probability.  \n--------------------------------------------------", "robability.  \n------------------------------------------------------------------------------  \n \nGeneral Remarks for Statistical Classification procedures:  \n[1] Statistical classifications are more rigorous but require more \nassumptions. Thus, it might no", "e more rigorous but require more \nassumptions. Thus, it might not be as flexible as computing \nprocedures to be presented next. However, statistical 5 \n classifications address the \u201cpopulation\u201d problem . Computing \nprocedures tend  to address \u201csample\u201d prob", "\u201d problem . Computing \nprocedures tend  to address \u201csample\u201d problem , i.e., the \nclassification results vary according to data sampled.  \n[2] Statistical classifications involves distributions (e.g., prior, \ndata-likelihood, posterior in Bayes classifiers,", " (e.g., prior, \ndata-likelihood, posterior in Bayes classifiers, and multinomial \ndistribution in \u201c Multinomia l Regression Based \nClassifications\u201d). Computing procedures do not involve any \ndistribution, but they have objective functions and constraints. ", "istribution, but they have objective functions and constraints.  \n---------------------------------------------------------------------------------  \nThe following procedures are co mputing or optimization -based  \nprocedures.  \n#4) Separating Hyperplane: ", " optimization -based  \nprocedures.  \n#4) Separating Hyperplane:  This is a \u201ccomputing\u201d procedure that \nfinds linear or nonlinear \u201chyperplanes\u201d (i.e., function of x-\nvariables in a p-dimension space) to \u201cseparate\u201d data in different \nclasses. The following p", "space) to \u201cseparate\u201d data in different \nclasses. The following present three examples.  6 \n  \n \n7 \n  \n8 \n #5) Support Vector Machine (SVM)  \nLet us use the following figures to explain the construction \nof decision boundary in the SVM. In the left figure ,", "struction \nof decision boundary in the SVM. In the left figure , there is no \nmis-classification case . The two green dots and one red dot in the \nborders of the yellow box are called \u201c support vectors \u201d. The siz e \nand location of the yellow box are decid", "t vectors \u201d. The siz e \nand location of the yellow box are decided by these support \nvectors. An optimization program will find these support vectors \nfor a data set to maximize the size (i.e., margins) of the yellow \nbox. The decision boundary for this SV", ", margins) of the yellow \nbox. The decision boundary for this SVM is the middle line in the \nyellow box.  \n \n9 \n The right figure extends the simple SVM described above \nto handle potential \u201cmis -classification\u201d cases. Note that there are \none red -dot cla", "is -classification\u201d cases. Note that there are \none red -dot classified into green -decision -region, and there is one \ngreen -dot (with \u03be3* notation) classified in th e left -side of the \ndecision -boundary , i.e., red -decision -region. These are mis -\nc", "ision -boundary , i.e., red -decision -region. These are mis -\nclassification cases. The idea of SVM in this \u201cmis -classification\u201d \nsituation is to set a total budget to allow a small amount of mis -\nclassifications. For example, in the right f igure, ther", "f mis -\nclassifications. For example, in the right f igure, there are FIVE \ncases that can be considered as \u201cmis -classifications\u201d. The sum of \ntheir distances to the \u201ccorrect -margins\u201d is \u03be1* (for the red -dot in the \nyellow -box and its distance to \u201cred ", " (for the red -dot in the \nyellow -box and its distance to \u201cred -margin\u201d) + \u03be2* (similar to \u03be1* in \nthe red -zone) + \u03be3* (for t he green -dot in the yellow -box and its \ndistance to \u201cgreen -margin\u201d) + \u03be4* (similar to \u03be3*) + \u03be5* (for the red -\ndot in the gr", "rgin\u201d) + \u03be4* (similar to \u03be3*) + \u03be5* (for the red -\ndot in the green -zone and its distance to \u201cred -margin\u201d).  \nThe budget of these \u201cmis -classification \u201d cases controls how \nmany \u201cmis -classified\u201d points will be IGNORED in searching for \nthe maximum margi", "fied\u201d points will be IGNORED in searching for \nthe maximum margin .  For example, when these FIVE cases \naddressed above are ignored, the support vectors are two green -\ndots on the margin of the yellow -box. The decision bou ndary for \nthis SVM classifica", "the yellow -box. The decision bou ndary for \nthis SVM classification procedure is the middle line of the yellow -\nbox. When the budget of \u201cmis -classification\u201d cases is changed, the 10 \n support vectors will change. Then, the decision boundary will \nchange", "rt vectors will change. Then, the decision boundary will \nchange correspondingly.  \n \n#6) Mathematical Program ming (MP) Based Separating \nHyperplanes  \n \n \n11 \n  \n#7) Decision Tree : This school of procedures could be statistical or \ncomputational. The ex", "ool of procedures could be statistical or \ncomputational. The example presented below is a computing \nbased decision tree.  \nThe let -bottom figure presents one example with five-nodes \nin a binary -split decision tree. Its decision boundaries in the two -", "inary -split decision tree. Its decision boundaries in the two -\nx-variable (X 1 and X 2) domain is shown in the upper -right figure. \nThe bottom right figure is the 3 -D representation of these decision \nboundaries and their predictive surfaces fo r Y-cla", "se decision \nboundaries and their predictive surfaces fo r Y-class -outcomes.  \n12 \n    The left -top figure shows that this type of non -binary -split \ndecision boundaries cannot be handled by the traditional decision -\ntree procedures, which are usually ", "y the traditional decision -\ntree procedures, which are usually binary -split trees.  \n \n \nObjectives  in the optimization procedures for building decision \ntrees will be presented next.  \n13 \n Notations:  \n[1] X -vec = (X 1, X 2)T in the above example; y ", "\n Notations:  \n[1] X -vec = (X 1, X 2)T in the above example; y -data = a \ncollection of all y \u2261 outcomes;  \n Note that outcomes in the decision -trees can be classes (for \nclassification) or numerical values  (for regression) ; This \nis why decision -tree", "numerical values  (for regression) ; This \nis why decision -trees are called \u201c Classification and \nRegression Trees \u201d; \n[2] Decision -Regions Rm, m = 1, 2, \u2026, 5, are decision -regions \ndefined in the upper -right figure;  \n[3] (L 1, U 1), (L 2, U 2) are lo", " in the upper -right figure;  \n[3] (L 1, U 1), (L 2, U 2) are lower and upper bounds for X 1 and X 2, \nrespectively;  \n[4] T is the collection of all terminal nodes defined by decision -\nregions Rm, m = 1, 2, \u2026, 5; | T| \u2261 the size of the decision -tree \n= ", "ns Rm, m = 1, 2, \u2026, 5; | T| \u2261 the size of the decision -tree \n= the number of terminal nodes =eg= 5;  \n[5] Nm = #{data in Rm}; Note that because Rm is defined for X -\nvariables, #{data in Rm} is evaluated in terms of X -variable \ndata in a specific region ", "is evaluated in terms of X -variable \ndata in a specific region Rm; \n[6] cm_hat = average(y -data with their X -vec in Rm). \n 14 \n Classification/Prediction Function:  \nf_hat ( X-vec) = \u2211 m=15 cm_hat *  I( X-vec in Rm ) \n=  average(y -data with their X -ve", " cm_hat *  I( X-vec in Rm ) \n=  average(y -data with their X -vec in R1) *  \nI( R1 \u2261 L1 \u2264 X1 \u2264 t1, L2 \u2264 X2 \u2264 t2 ) \n+ average(y -data with their X -vec in R2) *  \nI( R2 \u2261 L1 \u2264 X1 \u2264 t1,  t2 \u2264 X2 \u2264 U2 ) \n+ average(y -data with their X -vec in R3) *  \nI( R3 \u2261 ", " \u2264 U2 ) \n+ average(y -data with their X -vec in R3) *  \nI( R3 \u2261 t1 \u2264 X1 \u2264 t3, L2 \u2264 X2 \u2264 U2 ) \n+ average(y -data with their X -vec in R4) *  \nI( R4 \u2261 t3 \u2264 X1 \u2264 U1, L2 \u2264 X2 \u2264 t4 ) \n+ average(y -data with their X -vec in R5) *  \nI( R5 \u2261 t3 \u2264 X1 \u2264 U1, t4 \u2264 X2 ", "data with their X -vec in R5) *  \nI( R5 \u2261 t3 \u2264 X1 \u2264 U1, t4 \u2264 X2 \u2264 U2 ). \n \nObjective Function  to Construct Decision -Trees:  \n Find all decision -regions Rm (including which  x-variable  at \nwhat  split-node of the tree and tm-value of the split -decision", "what  split-node of the tree and tm-value of the split -decision),  m = \n1, 2, \u2026, M \u2261 | T | (=eg= 5) to  \n Minimize   15 \n  C\u03b1(T) = \u2211m=1M \u2211xi-vec in Rm  (yi \u2212 cm_hat)2 + \u03b1 | T |, \nwhere the first component represents the model -fitting quality and \nis the ", "rst component represents the model -fitting quality and \nis the sum -of-squares (SS) of prediction -errors (SSE). Note that in \nthe classification problems, the above SSE can be changed to some \nmetrics related to #mis -classifi cation cases. The second co", "e \nmetrics related to #mis -classifi cation cases. The second component \nrepresents the size of the tree, and \u03b1 is a tuning parameter for \nbalancing the fitting -quality against the complexity of the tree. \nTypically, \u03b1 is decided by a cross -validation pr", " of the tree. \nTypically, \u03b1 is decided by a cross -validation procedure, which will \nbe presented later.  T he complexity of the tree is presented by the \nsize of the tree | T | = #terminal nodes.  \n There are many algorithms for constructing decision -tre", "des.  \n There are many algorithms for constructing decision -trees to \ndecide which x -variable should be used at what split -node and \nwhat should be its threshold -value (i.e ., tm-value) for the split -\ndecision.  HW-2 will ask students to review softwa", "r the split -\ndecision.  HW-2 will ask students to review software available for \ndecision -trees.  \n---------------------------------------------------------------------------------------  \n(h) Neural Network (or Artificial Neura l Network (ANN)):  \nANN  ", "h) Neural Network (or Artificial Neura l Network (ANN)):  \nANN  is a two -stage regression or classification procedure . See \nFigure 11.2 below for a schematic diagram of a typical ANN. 16 \n  \n  For K-class classification there are K units at the top (whic", "\n  For K-class classification there are K units at the top (which is \nthe output layer in the ANN-diagram), with the k-th unit modeling \nthe probability of class k in {1, 2, \u2026, K}. There are K target \nmeasurements Y k, k = 1, 2, \u2026, K, each being coded as 0", " target \nmeasurements Y k, k = 1, 2, \u2026, K, each being coded as 0 -1 variable \nfor the k-th class.  \n  The middle  layer is called \u201chidden -layer \u201d. \u201cDerived features \u201d \nZm are created from linear combinations of the inputs  X-vec = (X 1, \nX2, \u2026, X p).  The", "ear combinations of the inputs  X-vec = (X 1, \nX2, \u2026, X p).  Then the target Y k is modeled /predicted  as fk(X-vec) = \ngk(T-vec), which is a function of linear combinations of Zm\u2019s. \n17 \n  \n \nThe activation function \u03c3( v) is usually chosen to be the \nsigm", "\nThe activation function \u03c3( v) is usually chosen to be the \nsigmoid \u03c3( v) = 1/[1 + exp(\u2212 v)].  See Figure 11.3 below  for a plot \nof this function. Sometimes Gaussian radial basis functions are \nused for the activation functions.  Then, the ANN is called r", "e \nused for the activation functions.  Then, the ANN is called radial \nbasis function neural network.  \n \n18 \n  There are many computing algorithms developed for \ncalculating these ANN parameters \u03b1 0m, \u03b1m (a p-dim vector),  \u03b20k, \u03b2K \n(a M-dim vector), where", "ers \u03b1 0m, \u03b1m (a p-dim vector),  \u03b20k, \u03b2K \n(a M-dim vector), where m = 1, 2, \u2026, M \u2261 #hidden -nodes = \n#Neurons, k = 1, 2, \u2026, K \u2261 #classes.  \nThere are many rule -of-thumb methods for determining the \ncorrect number of neurons to use in the hidden layers, suc", " the \ncorrect number of neurons to use in the hidden layers, such as \nthe following:  \n\u2022 The number of hidden neurons should be between the size of \nthe input layer and the size of the output layer.  \n\u2022 The number of hidden neurons should be 2/3 the size o", "layer.  \n\u2022 The number of hidden neurons should be 2/3 the size of the \ninput layer, plus the size of the output layer.  \n\u2022 The numbe r of hidden neurons should be less than twice the \nsize of the input layer.  \nThese three rules provide a starting point fo", "the input layer.  \nThese three rules provide a starting point for you to consider. \nUltimately, the selection of an architecture for your neural network \nwill come down to trial and error  for getting a quality ANN for \nreasonable % mis -classifications or", " getting a quality ANN for \nreasonable % mis -classifications or SS -prediction errors.  \n--------------------------------------------------------------------------------------  \n \n 1 \n ISyE DDA  \u2013 Agenda for 0 3/02/23 Lecture (Lec. 15) \nAdvanced Data Mode", "DA  \u2013 Agenda for 0 3/02/23 Lecture (Lec. 15) \nAdvanced Data Modeling \u2013 Classifications  \nA)  Statistical Classification Procedures:  \n(a) Bayes Classifier  \n(b) Discriminant Analysis: LDA/QDA/RDA  \n(c) Na\u00efve Bayes Classifier  \n(d) Multinomial/ Logistic Reg", "RDA  \n(c) Na\u00efve Bayes Classifier  \n(d) Multinomial/ Logistic Regression Based Classification  \nB) Computing/Optimization Based Classification Procedures  \n(e) Separating Hyperplane  \n(f) Support Vector Machine  \n(g) Decision Tree  \n(h) Artificial Neural Ne", "rt Vector Machine  \n(g) Decision Tree  \n(h) Artificial Neural Network (ANN)  \n(i) K-Neararest Neighbor ( kNN) \n------------------------------------------------------------------------------------  \nDetailed Lectures:   \n1. Advanced Data Modeling  - Classif", "---  \nDetailed Lectures:   \n1. Advanced Data Modeling  - Classifications  \n------------------------------------------------------------------------------------  \nDetails:    \nClassification is similar to regression. A classification model is \nconstructed/e", " similar to regression. A classification model is \nconstructed/estimated for predicting a set of data with input \nvariables  x-vec (e.g.,  x1 = long sleeves, x2 = $600, x3 = cotton in 2 \n Example -2 below) to a class -outcome (e.g., \u201c office  dress\u201d (as \nC", "ple -2 below) to a class -outcome (e.g., \u201c office  dress\u201d (as \nClass -1), \u201cparty dress\u201d  (as Class -2)). This type of model could be \nuseful in developing decision rules for sharing mom\u2019s clothes \nwith others. This is like Airbnb.com for sharing rooms with", "hes \nwith others. This is like Airbnb.com for sharing rooms with \nothers.   \n Our presentation for classification procedures will focus on \nconcepts such that students know when to use which procedure. \nHW-2 asks students to learn how to use software packa", "rocedure. \nHW-2 asks students to learn how to use software packages to \nperform classifications.  \n--------------------------------------------------------------------------------------  \n(a) Bayes Classifier:  \nBayes classifier is a  statistical procedure", "Bayes Classifier:  \nBayes classifier is a  statistical procedure , which  classifies a  case to \nthe most probable  class, using the (posterior -) conditional distribution \nPr(G | X = x).  Note that G has  a discrete distribution with probability \nmass ass", "e that G has  a discrete distribution with probability \nmass assigned to  a few outcomes \u2261 classes, k = 1, 2, \u2026, K.  \nReview \u2013 Prior, Likelihood, Posterior Distribution and Bayes \nTheorem:  \n1. Structure prior  (probability ) distribution Pr(G = k) for \ncl", ". Structure prior  (probability ) distribution Pr(G = k) for \nclasses k = 1, 2, \u2026, K.  3 \n Example -1: A typical prior distribution for K = 2 classes is \nthe Bernoulli distribution  of Pr(G = 1) = \u03c0 and Pr(G = 2) = 1 \n\u2013 \u03c0 with probability 0 \u2264 \u03c0 \u2264 1. Extend", "1) = \u03c0 and Pr(G = 2) = 1 \n\u2013 \u03c0 with probability 0 \u2264 \u03c0 \u2264 1. Extending this concept, a \npopular prior distribution for general K =eg= 5 classes is the \nMultinomial distribution  with \u201ccell probabilities\u201d Pr(G = 1) =  \n\u03c01, Pr(G = 2) =  \u03c02, \u2026, Pr(G = 5) =  \u03c05, ", "ilities\u201d Pr(G = 1) =  \n\u03c01, Pr(G = 2) =  \u03c02, \u2026, Pr(G = 5) =  \u03c05, with 0 \u2264 \u03c0k \u2264 1, k = 1, 2, \n\u2026, 5 and \u2211 k=15 \u03c0k = 1. Note that in applications, there is a \ncoding process needed to define these nature classes such as \n\u201cred\u201d, \u201cblack\u201d, \u2026, \u201cblue\u201d as class -1, ", " nature classes such as \n\u201cred\u201d, \u201cblack\u201d, \u2026, \u201cblue\u201d as class -1, class -2, \u2026, class -5, \nrespectively.  \n \n2. Given/conditioning on a particular class \u201cG = k\u201d (e.g., \u201cred\u201d in \nclass -1), co llect data  for understanding regressor/classifier\u2019s \nprobability d", "ct data  for understanding regressor/classifier\u2019s \nprobability distribution, Pr(X = x | G = k), which is usually \ncalled \u201c data likelihood \u201d. \nExample -2: One example of the input variables could be \nstyle, price and material of mom\u2019s clothes. For instance", "uld be \nstyle, price and material of mom\u2019s clothes. For instance, for a \n\u201coffice  dress \u201d in class -1, x1 = long sleeves, x2 = $600, x3 = \ncotton, \u2026. For a \u201cparty dress \u201d in class -2, x2 = short  sleeves, \nx2 = $1000, x3 = expensive materials , \u2026. \n 4 \n 3.", "rt  sleeves, \nx2 = $1000, x3 = expensive materials , \u2026. \n 4 \n 3. Use the Bayes Theorem  to construct/derive the conditional \nprobability distribution for Pr(G = k | X_vec  = x_vec). Then,  \ngiven a  set of  \u201cinput s\u201d X_vec  = x_vec, predict/classify th is ", "ven a  set of  \u201cinput s\u201d X_vec  = x_vec, predict/classify th is case \ninto a particular class, e.g., G = k. The conditional probability \nPr(G = k | X = x) is called the posterior distribution  in Bayes \nClassifiers.  \nExample -3: Classification is similar ", " in Bayes \nClassifiers.  \nExample -3: Classification is similar to regression. A \nclassification model will be constructed to link input variables \nX_vec  = x_vec to their outcomes, which are classes G = k, k = 1, \n2, \u2026, K =eg=5. In Bayes Classifiers , Bay", "classes G = k, k = 1, \n2, \u2026, K =eg=5. In Bayes Classifiers , Bayes Theorem is used to \nconstruct a posterio r distribution Pr(G = k given that  X = x), \nusing prior distribution and data -likelihood. Please see note #4 \nbelow for construction of posterior ", "lihood. Please see note #4 \nbelow for construction of posterior distribution.  \nLet us show an example of using posterior distribution to \nmake classifications. If Pr(G = Class -1 = \u201coffice dress\u201d  given \nthat x1 = long sleeves, x2 = $600, x3 = cotton, \u2026) ", "ess\u201d  given \nthat x1 = long sleeves, x2 = $600, x3 = cotton, \u2026) is the highest \namong all posterior probabilities for all classes , e.g., Pr(G = \nClass -2 = \u201c party dress \u201d given that x1 = long sleeves, x2 = $600, \nx3 = expensive materials , \u2026) and Pr(G = ", "g sleeves, x2 = $600, \nx3 = expensive materials , \u2026) and Pr(G = Class -3, \u2026, or Class -5 \ngiven the same set of inputs), this Bayes Classifier classifies a \ndress with inputs x1 = long sleeves, x2 = $600, x3 = cotton, \u2026 as \na \u201coffice  dress\u201d in Class -1. 5", ", x2 = $600, x3 = cotton, \u2026 as \na \u201coffice  dress\u201d in Class -1. 5 \n  \n4. Bayes Theorem:  Pr(G = k | X = x) = Pr( G = k and X = x) / \nPr(X = x) = [ Pr(X = x | G = k) * Pr(G = k) ] / Pr(X = x), where \nthe numerator is a multiplication between the prior \nproba", "here \nthe numerator is a multiplication between the prior \nprobability  Pr(G = k) and the \u201cdata likelihood\u201d  Pr(X = x | G \n= k) as explained above. They are the essential components to \nconstruct/derive the posterior distribution in Bayes Classifiers.  \nTh", "uct/derive the posterior distribution in Bayes Classifiers.  \nThe denominator is usually the \u201cnormalizing constant\u201d for \nmaking the conditional pdf Pr( G = k and X = x) a proper \ndensity, i.e., integration of this density over its domain is equal \nto one. ", ", integration of this density over its domain is equal \nto one. T here are computational methods to find this \ndenominator, and thus, it is not necessary to \u201cderive\u201d its \nexpression.  \n-----------------------------------------------------------------------", "---------------------------------------------------------------------------  \n(b) Discriminant Analysis (LDA/QDA/RDA):   \nDiscriminant analysis (DA) is one of the oldest classification \nprocedures. LDA/QDA/RDA are special cases of Bayes \nClassifiers  state", "ures. LDA/QDA/RDA are special cases of Bayes \nClassifiers  stated in #3 above.   \nModel Assumptions:  6 \n In these Discriminant Analysis procedures, Multivariate \nNormal Distributions are assumed  for the joint distribution  of p-\ndimensional X -variables ", "med  for the joint distribution  of p-\ndimensional X -variables with density  fk(xk-matrix ) = Pr(X k-\nmatrix  = xk-matrix  | G = k) (i.e., the \u201c data likelihood \u201d). Note \nthat for each class G = k, k = 1, 2, \u2026, K, its inputs are considered \nas random vari", "G = k, k = 1, 2, \u2026, K, its inputs are considered \nas random variables  and they are different from the inputs for \nthe other classes.  \nFocus on Class -k data. Denoted by Xk-matrix  a matrix of  p-\ndimensional  input -variables , i.e., Xk-matrix  = (X1k-ve", "f  p-\ndimensional  input -variables , i.e., Xk-matrix  = (X1k-vec, X 2k-\nvec, \u2026, X pk-vec), where each Xjk-vec has n rows of data -\nsamples , and  j = 1 (short/long sleeves), 2 (price), \u2026, p. \nFor a class G = k, the mean parameter -vectors  is \u03bck = (\u03bc1, \n\u03bc", "\nFor a class G = k, the mean parameter -vectors  is \u03bck = (\u03bc1, \n\u03bc2, \u2026, \u03bcp)T for Xk-matrix  = (X1k-vec, X 2k-vec, \u2026, X pk-vec). Note \nthat mean -vectors from different classes are usually  different , \ni.e., \u03bck \u2260 \u03bck\u2019 for k \u2260 k\u2019 in {1, 2, \u2026, K}. 7 \n The matri", "rent , \ni.e., \u03bck \u2260 \u03bck\u2019 for k \u2260 k\u2019 in {1, 2, \u2026, K}. 7 \n The matrix \u03a3k of their  variance -covariance s in the general \nsituations are different. For example, the first element in \u03a3k is \nVar(X 1k-vec), which could have different values for different \nclasses", "k-vec), which could have different values for different \nclasses  of X1k-vec data-vectors. The second element in \u03a3k is \nCov(X1k-vec, X2k-vec), which could also have different values \nfor different classes  of X1k-vec and X2k-vec data-vectors.  \nIn the Line", "rent classes  of X1k-vec and X2k-vec data-vectors.  \nIn the Linear Discriminant Analysis (LDA), there is an \nadditional  assumption that all variance -covariance matrices \nhave an equal variance -covariance structure, i.e., \u03a3 k = \u03a3 for \nall classes k = 1, ", "ce -covariance structure, i.e., \u03a3 k = \u03a3 for \nall classes k = 1, 2, \u2026, K. For the Quadratic Discriminant \nAnalysis (QDA), there is no equal variance -covariance \nassumption. Regularized Discriminant Analysis (RDA) assumes \nthat \u03a3k(\u03b1) = \u03b1 \u03a3k + (1 \u2212 \u03b1) \u03a3 with", "inant Analysis (RDA) assumes \nthat \u03a3k(\u03b1) = \u03b1 \u03a3k + (1 \u2212 \u03b1) \u03a3 with \u03b1 given as a tuning parameter \ndecided by a cross -validation procedure.  \n \nDeta ils of Discriminant Analysis \u2013 LDA and QDA:  8 \n 1. Assume that given a particular class G = k, the pdf of th", "8 \n 1. Assume that given a particular class G = k, the pdf of the input -\nvariables X k-matrix = xk-matrix , fk(xk-matrix ) = Pr(X k-matrix  = \nxk-matrix  | G = k), has a multivariate normal distribution  with the \nfollowing pdf.  \n \n2. For LDA (Linear Dis", "istribution  with the \nfollowing pdf.  \n \n2. For LDA (Linear Discriminant Analysis)  further  assume that the \nvariance -covariance matrix \u03a3k = \u03a3 is the same for all classes k = 1, \n2, \u2026, K. Then,  \n9 \n  \n10 \n  \n \n11 \n  \n12 \n Note that the left -plot is th", "hen,  \n9 \n  \n10 \n  \n \n11 \n  \n12 \n Note that the left -plot is the classification from the LDA  \nin a five-dimensional space (X 1, X 2, X 1*X 2, X 12, X22). Then, \nproject s LDA\u2019s  linear decision boundar ies into a 2-dimensional \nspace (X 1, X 2) for a vis", "ion boundar ies into a 2-dimensional \nspace (X 1, X 2) for a visualization plot. The right -plot is the \nclassific ation from the QDA using X 1 and X 2 variables (2 -\ndimensions) only.  The results from these two procedures are \nsimilar, but different slig", "sults from these two procedures are \nsimilar, but different slightly.  \n------------------------------------------------------------------------------------  \n(c) Na\u00efve Bayes Classifier  \nThis is a special case of (general) Bayes Classifier defined in #3 \n", " is a special case of (general) Bayes Classifier defined in #3 \nabove. It can also be a special case of LDA/QDA/RDA.  \nInstead of using a (dependent) multivariate distribution to \nmodel the data -likelihood, all X -variables are assumed to be \nindependent ", "ta -likelihood, all X -variables are assumed to be \nindependent , and thus,  \n fk(xk-matrix ) = Pr(X k-matrix  = xk-matrix  | G = k)  \nis a product of marginal densities , i.e., pdfs for each X1k-vec, \nX2k-vec, \u2026, X pk-vec. In the example of LDA, QDA and R", "X1k-vec, \nX2k-vec, \u2026, X pk-vec. In the example of LDA, QDA and RDA, \ncorrelations between all X -variables are all zeros . This implies \nthat the variance -covariance matrix \u03a3k only has diagonal elements \n(i.e., variances) and all off -diagonal elements (i", "al elements \n(i.e., variances) and all off -diagonal elements (i.e., covariances) are \nall zeros.  \n 13 \n (d) Multinomial/ Logistic Regression Based Classifications  \nStep-1: Focus on an example with K = 5 class es. When there are \nmore than two classes, i", "le with K = 5 class es. When there are \nmore than two classes, instead of using a logistic regression to \nfit the class Y -data, multinomial regression should be used to \nfit the data. There will be multiple logit -transformation to link \n\u03c0j = Pr(Y = class", "ill be multiple logit -transformation to link \n\u03c0j = Pr(Y = class j =eg= office dress) to regression functions \nfor classes, j = 1, 2, \u2026, K and \u2211 j=1K \u03c0j = 1. For example,  \n  loge[ Pr(Y = class = j) / Pr(Y = class = 1) ] \n  = \u03b20j + \u03b21j x1 + \u03b22j x2 + \u2026 + \u03b2 ", "s = j) / Pr(Y = class = 1) ] \n  = \u03b20j + \u03b21j x1 + \u03b22j x2 + \u2026 + \u03b2 pj x1, \nwhere x1, x2, \u2026, xp, are p explanatory variables associated for \nall classes Y -data, and \u03b2 0j, \u03b21j, \u03b22j, \u2026, \u03b2 pj are (p + 1) \ncoefficients in the above logit -regression function for ", " + 1) \ncoefficients in the above logit -regression function for class -j \nagainst class -1 for j = 2, 3, \u2026, K (=eg= 5). Note that we use \nclass -1 as the \u201cbase\u201d for the \u201codd -ratio\u201d Pr(Y = class = j) / \nPr(Y = class = 1) against all other classes. With K =", "ss = j) / \nPr(Y = class = 1) against all other classes. With K = 5, there \nwill be FOUR logit -transformations with j = 2, 3, 4, 5 = K in 14 \n this multinomial regression. In each one of these logit -\nregressions, their regression coefficients \u03b2 0j, \u03b21j, \u03b2", " logit -\nregressions, their regression coefficients \u03b2 0j, \u03b21j, \u03b22j, \u2026, \u03b2 pj will \nbe different for distinct class, j = 2, 3, \u2026, K. \n Similar to the logistic regression, parameters are estimated \nvia the maximum likelihood estimation (MLE) method. There, \no", "d \nvia the maximum likelihood estimation (MLE) method. There, \none needs to replace the Bernoulli distribution with the \nmultin omial distribution and replace the distribution \nparameters \u03c0 j = Pr(Y = class j), j = 1, 2, \u2026, K, \u2211j=1K \u03c0j = 1, \nwith th ose mu", "= Pr(Y = class j), j = 1, 2, \u2026, K, \u2211j=1K \u03c0j = 1, \nwith th ose multiple logit -regressions discussed above.  Then, \nemploy a numerical method such as Newton -Raphson method \nto optimize log -likelihood with respect to the regression \ncoefficients. Predictio", "kelihood with respect to the regression \ncoefficients. Predictions \u03c0 j_hat = Pr(Y = class j)_hat, j = 1, 2, \n\u2026, K, can then be obtained by replacing the unknown beta -\ncoefficients  with their MLEs.  \n For classifying a new data point (Y 0, x10, x20, \u2026, x ", " MLEs.  \n For classifying a new data point (Y 0, x10, x20, \u2026, x p0) to a \nclass, one use the new set of explanatory variables ( x10, x20, \u2026, 15 \n xp0) to predict this case\u2019s class -probabilities \u03c0 j_hat = Pr(Y 0 = \nclass j)_hat, for all K classes with j = ", "es \u03c0 j_hat = Pr(Y 0 = \nclass j)_hat, for all K classes with j = 1, 2, \u2026, K. Then, a \nsimple decision rule for classification is  \n \u201cassign this data case to class m if its class -probability  \n  \u03c0m_hat = Pr(Y 0 = class m)_hat is the highest  \n compared to ", "\n  \u03c0m_hat = Pr(Y 0 = class m)_hat is the highest  \n compared to all other class -probabilities\u201d,  \nwhere m is one of the  members in j = 1, 2, \u2026, K.  \nRemark:  \n[1] Multinomial/Logistic regression based  classification \nprocedures are statistical procedure", "sion based  classification \nprocedures are statistical procedures (why?), but they are not \nBayes Classifiers (why?).  \n[2] When misclassification costs are provided, one can develop a \ncost-based decision rule other than the one assign a data class \nwith ", "ased decision rule other than the one assign a data class \nwith the highest clas s-probability.  \n------------------------------------------------------------------------------  \n 16 \n General Remarks for Statistical Classification procedures:  \n[1] Statis", " Remarks for Statistical Classification procedures:  \n[1] Statistical classifications are more rigorous but require more \nassumptions. Thus, it might not be as flexible as computing \nprocedures to be presented next. However, statistical \nclassifications ad", "s to be presented next. However, statistical \nclassifications address the \u201cpopulation\u201d problem . Computing \nprocedures tend  to address \u201csample\u201d problem , i.e., the \nclassification results vary according to data sampled.  \n[2] Statistical classifications i", "y according to data sampled.  \n[2] Statistical classifications involves distributions (e.g., prior, \ndata-likelihood, posterior in Bayes classifiers, and multinomial \ndistribution in \u201c Multinomia l Regression Based \nClassifications\u201d). Computing procedures ", "mia l Regression Based \nClassifications\u201d). Computing procedures do not involve any \ndistribution, but they have objective functions and constraints.  \n---------------------------------------------------------------------------------  \nThe following procedu", "----------------------------------------  \nThe following procedures are co mputing or optimization -based  \nprocedures.  \n#4) Separating Hyperplane:  This is a \u201ccomputing\u201d procedure that \nfinds linear or nonlinear \u201chyperplanes\u201d (i.e., function of x-\nvariab", "s linear or nonlinear \u201chyperplanes\u201d (i.e., function of x-\nvariables in a p-dimension space) to \u201cseparate\u201d data in different \nclasses. The following present three examples.  17 \n  \n \n18 \n  \n19 \n #5) Support Vector Machine (SVM)  \nLet us use the following fi", "\n #5) Support Vector Machine (SVM)  \nLet us use the following figures to explain the construction \nof decision boundary in the SVM. In the left figure , there is no \nmis-classification case . The two green dots and one red dot in the \nborders of the yellow", "The two green dots and one red dot in the \nborders of the yellow box are called \u201c support vectors \u201d. The siz e \nand location of the yellow box are decided by these support \nvectors. An optimization program will find these support vectors \nfor a data set to", "ation program will find these support vectors \nfor a data set to maximize the size (i.e., margins) of the yellow \nbox. The decision boundary for this SVM is the middle line in the \nyellow box.  \n \n20 \n The right figure extends the simple SVM described abov", "  \n \n20 \n The right figure extends the simple SVM described above \nto handle potential \u201cmis -classification\u201d cases. Note that there are \none red -dot classified into green -decision -region, and there is one \ngreen -dot (with \u03be3* notation) classified in th", "nd there is one \ngreen -dot (with \u03be3* notation) classified in th e left -side of the \ndecision -boundary , i.e., red -decision -region. These are mis -\nclassification cases. The idea of SVM in this \u201cmis -classification\u201d \nsituation is to set a total budget ", " this \u201cmis -classification\u201d \nsituation is to set a total budget to allow a small amount of mis -\nclassifications. For example, in the right f igure, there are FIVE \ncases that can be considered as \u201cmis -classifications\u201d. The sum of \ntheir distances to the ", "d as \u201cmis -classifications\u201d. The sum of \ntheir distances to the \u201ccorrect -margins\u201d is \u03be1* (for the red -dot in the \nyellow -box and its distance to \u201cred -margin\u201d) + \u03be2* (similar to \u03be1* in \nthe red -zone) + \u03be3* (for t he green -dot in the yellow -box and it", " red -zone) + \u03be3* (for t he green -dot in the yellow -box and its \ndistance to \u201cgreen -margin\u201d) + \u03be4* (similar to \u03be3*) + \u03be5* (for the red -\ndot in the green -zone and its distance to \u201cred -margin\u201d).  \nThe budget of these \u201cmis -classification \u201d cases contro", "gin\u201d).  \nThe budget of these \u201cmis -classification \u201d cases controls how \nmany \u201cmis -classified\u201d points will be IGNORED in searching for \nthe maximum margin .  For example, when these FIVE cases \naddressed above are ignored, the support vectors are two green", " \naddressed above are ignored, the support vectors are two green -\ndots on the margin of the yellow -box. The decision bou ndary for \nthis SVM classification procedure is the middle line of the yellow -\nbox. When the budget of \u201cmis -classification\u201d cases i", "e yellow -\nbox. When the budget of \u201cmis -classification\u201d cases is changed, the 21 \n support vectors will change. Then, the decision boundary will \nchange correspondingly.  \n \n#6) Mathematical Program ming (MP) Based Separating \nHyperplanes  \n \n \n22 \n  \n#7)", "Program ming (MP) Based Separating \nHyperplanes  \n \n \n22 \n  \n#7) Decision Tree : This school of procedures could be statistical or \ncomputational. The example presented below is a computing \nbased decision tree.  \nThe let -bottom figure presents one exampl", "ased decision tree.  \nThe let -bottom figure presents one example with five-nodes \nin a binary -split decision tree. Its decision boundaries in the two -\nx-variable (X 1 and X 2) domain is shown in the upper -right figure. \nThe bottom right figure is the 3", "wn in the upper -right figure. \nThe bottom right figure is the 3 -D representation of these decision \nboundaries and their predictive surfaces fo r Y-class -outcomes.  \n23 \n    The left -top figure shows that this type of non -binary -split \ndecision bound", "igure shows that this type of non -binary -split \ndecision boundaries cannot be handled by the traditional decision -\ntree procedures, which are usually binary -split trees.  \n \n \nObjectives  in the optimization procedures for building decision \ntrees will", "in the optimization procedures for building decision \ntrees will be presented next.  \n24 \n Notations:  \n[1] X -vec = (X 1, X 2)T in the above example; y -data = a \ncollection of all y \u2261 outcomes;  \n Note that outcomes in the decision -trees can be classes ", "es;  \n Note that outcomes in the decision -trees can be classes (for \nclassification) or numerical values  (for regression) ; This \nis why decision -trees are called \u201c Classification and \nRegression Trees \u201d; \n[2] Decision -Regions Rm, m = 1, 2, \u2026, 5, are d", "ession Trees \u201d; \n[2] Decision -Regions Rm, m = 1, 2, \u2026, 5, are decision -regions \ndefined in the upper -right figure;  \n[3] (L 1, U 1), (L 2, U 2) are lower and upper bounds for X 1 and X 2, \nrespectively;  \n[4] T is the collection of all terminal nodes de", "respectively;  \n[4] T is the collection of all terminal nodes defined by decision -\nregions Rm, m = 1, 2, \u2026, 5; | T| \u2261 the size of the decision -tree \n= the number of terminal nodes =eg= 5;  \n[5] Nm = #{data in Rm}; Note that because Rm is defined for X -\n", "[5] Nm = #{data in Rm}; Note that because Rm is defined for X -\nvariables, #{data in Rm} is evaluated in terms of X -variable \ndata in a specific region Rm; \n[6] cm_hat = average(y -data with their X -vec in Rm). \n 25 \n Classification/Prediction Function: ", "their X -vec in Rm). \n 25 \n Classification/Prediction Function:  \nf_hat ( X-vec) = \u2211 m=15 cm_hat *  I( X-vec in Rm ) \n=  average(y -data with their X -vec in R1) *  \nI( R1 \u2261 L1 \u2264 X1 \u2264 t1, L2 \u2264 X2 \u2264 t2 ) \n+ average(y -data with their X -vec in R2) *  \nI( R2", " X2 \u2264 t2 ) \n+ average(y -data with their X -vec in R2) *  \nI( R2 \u2261 L1 \u2264 X1 \u2264 t1,  t2 \u2264 X2 \u2264 U2 ) \n+ average(y -data with their X -vec in R3) *  \nI( R3 \u2261 t1 \u2264 X1 \u2264 t3, L2 \u2264 X2 \u2264 U2 ) \n+ average(y -data with their X -vec in R4) *  \nI( R4 \u2261 t3 \u2264 X1 \u2264 U1, L2 \u2264", "(y -data with their X -vec in R4) *  \nI( R4 \u2261 t3 \u2264 X1 \u2264 U1, L2 \u2264 X2 \u2264 t4 ) \n+ average(y -data with their X -vec in R5) *  \nI( R5 \u2261 t3 \u2264 X1 \u2264 U1, t4 \u2264 X2 \u2264 U2 ). \n \nObjective Function  to Construct Decision -Trees:  \n Find all decision -regions Rm (includin", "ruct Decision -Trees:  \n Find all decision -regions Rm (including which  x-variable  at \nwhat  split-node of the tree and tm-value of the split -decision),  m = \n1, 2, \u2026, M \u2261 | T | (=eg= 5) to  \n Minimize   26 \n  C\u03b1(T) = \u2211m=1M \u2211xi-vec in Rm  (yi \u2212 cm_hat)2", "  \n Minimize   26 \n  C\u03b1(T) = \u2211m=1M \u2211xi-vec in Rm  (yi \u2212 cm_hat)2 + \u03b1 | T |, \nwhere the first component represents the model -fitting quality and \nis the sum -of-squares (SS) of prediction -errors (SSE). Note that in \nthe classification problems, the above ", "ors (SSE). Note that in \nthe classification problems, the above SSE can be changed to some \nmetrics related to #mis -classifi cation cases. The second component \nrepresents the size of the tree, and \u03b1 is a tuning parameter for \nbalancing the fitting -quali", "e, and \u03b1 is a tuning parameter for \nbalancing the fitting -quality against the complexity of the tree. \nTypically, \u03b1 is decided by a cross -validation procedure, which will \nbe presented later.  T he complexity of the tree is presented by the \nsize of the ", ".  T he complexity of the tree is presented by the \nsize of the tree | T | = #terminal nodes.  \n There are many algorithms for constructing decision -trees to \ndecide which x -variable should be used at what split -node and \nwhat should be its threshold -v", "be used at what split -node and \nwhat should be its threshold -value (i.e ., tm-value) for the split -\ndecision.  HW-2 will ask students to review software available for \ndecision -trees.  \n------------------------------------------------------------------", "-------------------------------------------------------------------------------------  \n(h) Neural Network (or Artificial Neura l Network (ANN)):  \nANN  is a two -stage regression or classification procedure . See \nFigure 11.2 below for a schematic diagram", "ation procedure . See \nFigure 11.2 below for a schematic diagram of a typical ANN. 27 \n  \n  For K-class classification there are K units at the top (which is \nthe output layer in the ANN-diagram), with the k-th unit modeling \nthe probability of class k in ", "am), with the k-th unit modeling \nthe probability of class k in {1, 2, \u2026, K}. There are K target \nmeasurements Y k, k = 1, 2, \u2026, K, each being coded as 0 -1 variable \nfor the k-th class.  \n  The middle  layer is called \u201chidden -layer \u201d. \u201cDerived features \u201d", "he middle  layer is called \u201chidden -layer \u201d. \u201cDerived features \u201d \nZm are created from linear combinations of the inputs  X-vec = (X 1, \nX2, \u2026, X p).  Then the target Y k is modeled /predicted  as fk(X-vec) = \ngk(T-vec), which is a function of linear combin", " as fk(X-vec) = \ngk(T-vec), which is a function of linear combinations of Zm\u2019s. \n28 \n  \n \nThe activation function \u03c3( v) is usually chosen to be the \nsigmoid \u03c3( v) = 1/[1 + exp(\u2212 v)].  See Figure 11.3 below  for a plot \nof this function. Sometimes Gaussian ", "re 11.3 below  for a plot \nof this function. Sometimes Gaussian radial basis functions are \nused for the activation functions.  Then, the ANN is called radial \nbasis function neural network.  \n \n29 \n  There are many computing algorithms developed for \ncalc", "\n \n29 \n  There are many computing algorithms developed for \ncalculating these ANN parameters \u03b1 0m, \u03b1m (a p-dim vector),  \u03b20k, \u03b2K \n(a M-dim vector), where m = 1, 2, \u2026, M \u2261 #hidden -nodes = \n#Neurons, k = 1, 2, \u2026, K \u2261 #classes.  \nThere are many rule -of-thum", "urons, k = 1, 2, \u2026, K \u2261 #classes.  \nThere are many rule -of-thumb methods for determining the \ncorrect number of neurons to use in the hidden layers, such as \nthe following:  \n\u2022 The number of hidden neurons should be between the size of \nthe input layer an", "hidden neurons should be between the size of \nthe input layer and the size of the output layer.  \n\u2022 The number of hidden neurons should be 2/3 the size of the \ninput layer, plus the size of the output layer.  \n\u2022 The numbe r of hidden neurons should be less", "e output layer.  \n\u2022 The numbe r of hidden neurons should be less than twice the \nsize of the input layer.  \nThese three rules provide a starting point for you to consider. \nUltimately, the selection of an architecture for your neural network \nwill come dow", "ection of an architecture for your neural network \nwill come down to trial and error  for getting a quality ANN for \nreasonable % mis -classifications or SS -prediction errors.  \n-----------------------------------------------------------------------------", "-------------------------------------------------------------------------  \n \n 1 \n ISyE DDA  \u2013 Agenda for 0 2/28/23 Lecture (Lec. 14) \n1. Economic Decision Models & Game Theoretic Model  \n2. Advanced Data Modeling  (switch to data analytics  here)  \ni) Cla", "dvanced Data Modeling  (switch to data analytics  here)  \ni) Classifications  \n(a) Bayes Classifier  \n(b) Discriminant Analysis: LDA/QDA/RDA  \n(c) Na\u00efve Bayes Classifier  \n------------------------------------------------------------------------------------", "----------------------------------------------------------------  \nDetailed Lectures:   \n1. Economic Decision Models & Game Theoretic Model  \nReference: Lu et al.  (2011), \u201cCompetition Under \nManufactuer Service and Retail Price\u201d, Economic \nModeling 28, 12", "Manufactuer Service and Retail Price\u201d, Economic \nModeling 28, 1256 -1264.  \n \nMultiple decision -makers are involved.  Each one has his/her \nown decision -variable(s), objective -function(s) and \nconstraint(s). Consider the situation with two decision -mak", "nd \nconstraint(s). Consider the situation with two decision -makers , \ne.g., one manufacturer and one retailer, where the manufacturer \nsupplies retailer products to sell . The following are four typical \ndecision models.   \n 2 \n 1. \u201cIntegrated\u201d decisions:", "our typical \ndecision models.   \n 2 \n 1. \u201cIntegrated\u201d decisions:  \nThe decision -variables, objective -functions and constraints \nfrom both decision -makers are integrated (e.g., added ) together \nto formulate a single set of decision problems. Physically,", "her \nto formulate a single set of decision problems. Physically, this \nimplies that there is ONE \u201csuper -manager\u201d making decisions \nwith an integrated decision function. In the supply -chain \nexample, the super -manager owns both manufacturing and \nretail ", "example, the super -manager owns both manufacturing and \nretail operations. In this model, individual\u2019s objectives are \n\u201cintegrated\u201d together into one objective function.  \n \n2. Manufacturer Stackelberg decisions:  \nIn this model, manufacturer (the leader)", "tackelberg decisions:  \nIn this model, manufacturer (the leader) has more bargaining \npower in making decisions based on his/her objective function, \nconditioning on retailer\u2019s (the follower) response function. \nUsually, the optimal decisions for both manu", "response function. \nUsually, the optimal decisions for both manufacturer and \nretailers are solved backwards .  See the following example for \ndetails.  \n \nThe System of Two Manufacturers and One Retailer:  3 \n  \nRetailer\u2019s Reaction Function:  Decide his/h", "One Retailer:  3 \n  \nRetailer\u2019s Reaction Function:  Decide his/her optimal prices \np1* and p2* to maximize his/her equilibrium profit. That is,  \n pi* = arg Max (w.r.t. pi) \u220fR( p1, p2* | w1, w2, s1, s2), i, j = 1, 2,  \nwhere w1, w2, s1, ss are decision -va", "2, s1, s2), i, j = 1, 2,  \nwhere w1, w2, s1, ss are decision -variables made by two \nmanufacturers.  See Figure 1 for the definition of notations. \nNote that Retailer\u2019s profit function \u220fR has two decision -\nvariables p1 and p2, which have to be optimized \n", "two decision -\nvariables p1 and p2, which have to be optimized \nsimultaneously.  \n Example -R1: Demand function for Prod uct i supplied by \nManufacturer  i (= 1, 2) is  \n \n4 \n which is a linear function of its product\u2019s price pi and service \nlevel si, and ", "r function of its product\u2019s price pi and service \nlevel si, and also difference of two prices ( pj \u2212 pi) and two \nservice levels ( sj \u2212 si). Retailer\u2019s profit function is a function of \ndemand times the difference of retail price ( pi) to the \nwholesale pr", " times the difference of retail price ( pi) to the \nwholesale price ( wi). The contributions from two \nmanufacturers are added together equally to form retailer\u2019s \nprofit function.  \n \n \n \nManufacturers\u2019 Decisions:  \n5 \n Using retailer's reaction function,", "ufacturers\u2019 Decisions:  \n5 \n Using retailer's reaction function, we can derive each \nmanufacturer's optimal wholesale price (wi*) and service level  \n(si*). This is carried out by maximizing each manufacturer's pro\ufb01t  \n \u220fM( wi*, wj, si*, sj | p1*, p2*), i,", "ach manufacturer's pro\ufb01t  \n \u220fM( wi*, wj, si*, sj | p1*, p2*), i, j = 1, 2,  \ngiven optimal prices p1*, p2* and optimal demands Q1* and Q2*. \nNote that manufacturer's pro\ufb01t function depends on  Qi* (i = 1 \nor 2), which is a function of ( wi, wj, si, sj ). M", " Qi* (i = 1 \nor 2), which is a function of ( wi, wj, si, sj ). Moreover, the \noptimal prices, p1*, p2*, are also functions of ( wi, wj, si, sj ). \nRecall that the  two manufacturers have equal bargaining \npower, and thus, they make decisions for their deci", " bargaining \npower, and thus, they make decisions for their decision -\nvariables according to Nash Equilibrium (see #3 below for \ndetails).  \n \nExample -R2: Similar to Retailer\u2019s profit function, \nmanufacturer\u2019s profit fu nction is given as  \n \nRemarks:  S", "on, \nmanufacturer\u2019s profit fu nction is given as  \n \nRemarks:  Service level si is involved in manufacturer\u2019s \nprofit function in a \u201cnegative\u201d quadratic form.  That is, if a \n6 \n manufacturer provides more after -sale service to customers, \nhis/her profit ", "provides more after -sale service to customers, \nhis/her profit will be smaller.  \n \n \n7 \n  \n \n3. \u201cNash equilibrium\u201d decisions:  \nIn this model, every decision -maker has equal bargaining \npower and thus makes his/her decisions simultaneously . In \nthe sup", "er and thus makes his/her decisions simultaneously . In \nthe supply chain example, this scenario arises in a market in \nwhich there are relatively small to medium -sized manufa cturers \nand retailers.  In this market it is reasonable to assume that a \nmanu", "tailers.  In this market it is reasonable to assume that a \nmanufacturer  may not know the competitor's wholesale price but \ncan observe its  retail price. Since a manufacturer cannot \n8 \n dominate the market over the retailer, his price decision is \ncondi", "inate the market over the retailer, his price decision is \nconditioned on how the retailer prices the product. On the other \nhand, the retailer must also condition its retail price decisions on \nthe wholesale price.  \nGame-theoretic framework is employed t", "n \nthe wholesale price.  \nGame-theoretic framework is employed to derive the \nreaction  function (see below for examp les) of each decision -\nmaker  in the supply chain. Solving these reaction functions \nsimultaneously  yields the  Nash equilibrium  soluti", " functions \nsimultaneously  yields the  Nash equilibrium  solution. Note that \nthe solution process here is different from the one considered in \n#1, \u201cintegrated\u201d decisions\u201d. Here, there are two sets of objective \nfunctions involved in these reaction funct", "wo sets of objective \nfunctions involved in these reaction functions; but, in the \nintegrated decisions, there is only one set of objective function.  \nExample N -1: By solving reactive functions from both \nretailer and manufacturers simultaneously, we hav", "ons from both \nretailer and manufacturers simultaneously, we have  \n \n9 \n 4. Retailer Stackelberg decisions:  \nIn this model, retailer has more bargaining power in making \ndecisions. The Retailer Stackelberg scenario arises in markets \nwhere retailers' siz", "ler Stackelberg scenario arises in markets \nwhere retailers' sizes are large compared to their suppliers. For \nexample, large retailers like Walma rt and Target can in\ufb02uence \neach product's sales by lowering the price. Because of their sizes, \nthe retailer", "les by lowering the price. Because of their sizes, \nthe retailers can maintain their margin on sales while squeezing \npro\ufb01t from their suppliers. The suppliers are mostly concerned \nwith receiving orders from the re tail giants.  \n  Similar game -theoretic", "ving orders from the re tail giants.  \n  Similar game -theoretic framework as applied in the \nManufacturer Stackelberg case is implemented to solve this \nproblem; i.e., the problem is solved backwards. First, the \nmanufacturer/ suppliers' problem is solved", "ackwards. First, the \nmanufacturer/ suppliers' problem is solved to derive the response \nfuncti on conditional on the retail prices chosen by the retailer. \nThe retailer problem is then solved given that the retailer knows \nhow the manufacturers would reac", " given that the retailer knows \nhow the manufacturers would react to the retail prices he sets.  \nDetails are skipped here.  \n---------------------------------------- -------------------------------------------  \n(New Data Analytics Materials for Exam -2) ", "------------------  \n(New Data Analytics Materials for Exam -2) \n2. Advanced Data Modeling  - Classifications  \n------------------------------------------------------------------------------------  10 \n Detailed Lectures  \u2013 Classifications : \n(a) Bayes Cla", "----  10 \n Detailed Lectures  \u2013 Classifications : \n(a) Bayes Classifier  \n(b) Discriminant Analysis: LDA/QDA/RDA  \n(c) Na\u00efve Bayes Classifier  \n(d) Logistic -Regression Based Classifier  \n(e) Separating Hyperplane  \n(f) Support Vector Machine (SVM)  \n(g) M", "Separating Hyperplane  \n(f) Support Vector Machine (SVM)  \n(g) Mathematical Programming Based Classification  \n(h) Decision Tree  \n----------------------------------------------------------------------------------  \nDetails:    \nClassification is similar t", "---------------------  \nDetails:    \nClassification is similar to  regression. A classification model is \nconstructed/estimated for predicting a set of data with input \nvariables  x-vec (e.g.,  x1 = short sleeves, x2 = $800, x3 = cotton in \nExample -2 belo", "  x1 = short sleeves, x2 = $800, x3 = cotton in \nExample -2 below) to a class -outcome (e.g., \u201cred dress\u201d (as Class -\n1), \u201cblack jacket (as Class -2)). This type of model could be useful \nin developing decision rules for sharing mom\u2019s clothes with \nothers.", "eveloping decision rules for sharing mom\u2019s clothes with \nothers. This is similar to Airbnb.com for sharing rooms with \nothers.   \n Our presentation for classi fication procedures will focus on \nconcepts such that students know when to use which procedure. ", " \nconcepts such that students know when to use which procedure. 11 \n HW-2 asks students to learn how to use software packages to \nperform classifications.  \n \n[1] Introduction \u2013 10 Classification Procedures  \n \nNotes: Because logistic -regression based cla", "ion Procedures  \n \nNotes: Because logistic -regression based classification is closer to \nseparating hyperplane, support vector machine, we will present it after \nBayes classifier and LDA/QDA/RDA.  \n---------------------------------------------------------", "RDA.  \n--------------------------------------------------------------------------------------  \n(a) Bayes  Classifier:  \n12 \n Bayes classifier is a  statistical procedure , which  classifies a  case to \nthe most probable  class, using the (posterior -) con", "  case to \nthe most probable  class, using the (posterior -) conditional distribution \nPr(G | X = x).  Note that G has  a discrete distribution with probability \nmass assigned to  a few ou tcomes \u2261 classes, k = 1, 2, \u2026, K.  \nReview \u2013 Prior, Likelihood, Pos", "mes \u2261 classes, k = 1, 2, \u2026, K.  \nReview \u2013 Prior, Likelihood, Posterior Distribution and Bayes \nTheorem:  \n1. Structure prior (probability ) distribution Pr(G = k) for \nclasses k = 1, 2, \u2026, K.  \nExample -1: A typical prior distribution for K = 2 classes is ", " \nExample -1: A typical prior distribution for K = 2 classes is \nthe Bernoulli distribution  of Pr(G = 1) = \u03c0 and Pr(G = 2) = 1 \n\u2013 \u03c0 with probability 0 \u2264 \u03c0 \u2264 1. Extending this concept, a \npopular prior distribution for general K =eg= 5 classes is the \nMult", "lar prior distribution for general K =eg= 5 classes is the \nMultinomial distributi on with \u201ccell probabilities\u201d Pr(G = 1) =  \n\u03c01, Pr(G = 2) =  \u03c02, \u2026, Pr(G = 5) =  \u03c05, with 0 \u2264 \u03c0k \u2264 1, k = 1, 2, \n\u2026, 5 and \u2211 k=15 \u03c0k = 1. Note that in applications, there is a", ", \n\u2026, 5 and \u2211 k=15 \u03c0k = 1. Note that in applications, there is a \ncoding process needed to define these nature classes such as \n\u201cred\u201d, \u201cblack\u201d, \u2026, \u201cblue\u201d as class -1, class -2, \u2026, class -5, \nrespectively.  \n \n2. Given/conditioning on a particular class \u201cG ", "espectively.  \n \n2. Given/conditioning on a particular class \u201cG = k\u201d (e.g., \u201cred\u201d in \nclass -1), co llect data  for understanding regressor/classifier\u2019s 13 \n probability distribution, Pr(X = x | G = k), which is usually \ncalled \u201c data likelihood \u201d. \nExampl", " | G = k), which is usually \ncalled \u201c data likelihood \u201d. \nExample -2: One example of the input variables could be \nstyle, price  and material of mom\u2019s clothes. For instance, for a \n\u201cred  dress \u201d in class -1, x1 = short sleeves, x2 = $800, x3 = \ncotton, \u2026. ", " \u201d in class -1, x1 = short sleeves, x2 = $800, x3 = \ncotton, \u2026. For a \u201cblack  jacket\u201d  in class -2, x2 = long sleeves, \nx2 = $1000, x3 = leather, \u2026.  \n \n3. Use the Bayes Theorem  to construct/derive the conditional \nprobability distribution for Pr(G = k | ", "derive the conditional \nprobability distribution for Pr(G = k | X_vec  = x_vec). Then,  \ngiven a  set of  \u201cinput s\u201d X_vec  = x_vec, predict/classify th is case \ninto a particular class, e.g., G = k. The conditional probability \nPr(G = k | X = x) is calle d", "G = k. The conditional probability \nPr(G = k | X = x) is calle d the posterior distribution  in Bayes \nClassifiers.  \nExample -3: Classification is similar to regression. A \nclassification model will be constructed to link input variables \nX_vec  = x_vec t", "el will be constructed to link input variables \nX_vec  = x_vec to their outcomes, which are classes G = k, k = 1, \n2, \u2026, K =eg=5. In Bayes Classifiers , Bayes Theorem is used to \nconstruct a posterior distribution Pr(G = k given that  X = x), \nusing prior ", "osterior distribution Pr(G = k given that  X = x), \nusing prior distribution and data -likelihood. Please see note #4 \nbelow for cons truction of posterior distribution.  14 \n Let us show an example of using posterior distribution to \nmake classifications.", "xample of using posterior distribution to \nmake classifications. If Pr(G = Class -1 = \u201cred -dress\u201d  given that \nx1 = short sleeves, x2 = $800, x3 = cotton, \u2026) is the highest \namong all posterior probabilities for all classes , e.g., Pr(G = \nClass -2 = \u201cBla", "or probabilities for all classes , e.g., Pr(G = \nClass -2 = \u201cBlack jacket\u201d given that x1 = short sleeves, x2 = $800, \nx3 = cotton, \u2026) and Pr(G = Class -3, \u2026, or Class -5 given the \nsame set of inputs), this Bayes Classifier classifies a dress with \ninputs ", " inputs), this Bayes Classifier classifies a dress with \ninputs x1 = short sleeves, x2 = $800, x3 = cotton, \u2026 as a \u201cred \ndress\u201d in Class -1. \n \n4. Bayes Theorem:  Pr(G = k | X = x) = Pr( G = k and X = x) / \nPr(X = x) = [ Pr(X = x | G = k) * Pr(G = k) ] / P", " and X = x) / \nPr(X = x) = [ Pr(X = x | G = k) * Pr(G = k) ] / Pr(X = x), where \nthe numerator is a multiplication between the prior \nprobability  Pr(G = k) and the \u201cdata likelihood\u201d  Pr(X = x | G \n= k) as explained above. They are the essential components", " | G \n= k) as explained above. They are the essential components to \nconstruct/derive the posterior distribution in Bayes Classifiers.  \nThe denominator is usually the \u201cnormalizing constant\u201d for \nmaking th e conditional pdf Pr( G = k and X = x) a proper \nd", "or \nmaking th e conditional pdf Pr( G = k and X = x) a proper \ndensity, i.e., integration of this density over its domain is equal \nto one. There are computational methods to find this \ndenominator, and thus, it is not necessary to \u201cderive\u201d its \nexpression", "nator, and thus, it is not necessary to \u201cderive\u201d its \nexpression.  15 \n ---------------- ------------------------------------------------------------------  \n(b) Discriminant Analysis (LDA/QDA/RDA):   \nDiscriminant analysis (DA) is one of the oldest classi", "/RDA):   \nDiscriminant analysis (DA) is one of the oldest classification \nprocedures. LDA/QDA/RDA are special cases of Bayes \nClassifiers  stated in #3 above.   \nModel Assumptions:  \nIn these Discriminant Analysis procedures, Multivariate \nNormal Distribut", "Discriminant Analysis procedures, Multivariate \nNormal Distributions are assumed  for the joint distribution  of p-\ndimensional X -variables with density  fk(xk-matrix ) = Pr(X k-\nmatrix  = xk-matrix  | G = k) (i.e., the \u201c data likelihood \u201d). Note \nthat fo", "-matrix  | G = k) (i.e., the \u201c data likelihood \u201d). Note \nthat for each class G = k, k = 1, 2, \u2026, K, its inputs are considered \nas random variables  and they are different from the inputs for \nthe other classes.  \nFocus on Class -k data. Denoted by Xk-matri", "the other classes.  \nFocus on Class -k data. Denoted by Xk-matrix  a matrix of  p-\ndimensional  input -variables , i.e., Xk-matrix  = (X1k-vec, X 2k-\nvec, \u2026, X pk-vec), where each Xjk-vec has n rows of data -\nsamples , and  j = 1 (short/long sleeves), 2 (p", "n rows of data -\nsamples , and  j = 1 (short/long sleeves), 2 (price), \u2026, p. 16 \n For a class G = k, the mean parameter -vectors  is \u03bck = (\u03bc1, \n\u03bc2, \u2026, \u03bcp)T for Xk-matrix  = (X1k-vec, X 2k-vec, \u2026, X pk-vec). Note \nthat mean -vectors from different classes a", " \u2026, X pk-vec). Note \nthat mean -vectors from different classes are usually  different , \ni.e., \u03bck \u2260 \u03bck\u2019 for k \u2260 k\u2019 in {1, 2, \u2026, K}. \nThe matrix \u03a3k of their  variance -covariance s in the general \nsituations are different. For example, the first element in ", "al \nsituations are different. For example, the first element in \u03a3k is \nVar(X 1k-vec), which could have different values for different \nclasses  of X1k-vec data-vectors. The second element in \u03a3k is \nCov(X1k-vec, X2k-vec), which could also have different val", "k is \nCov(X1k-vec, X2k-vec), which could also have different values \nfor different classes  of X1k-vec and X2k-vec data-vectors.  \nIn the Linear Discriminant Analysis (LDA), there is an \nadditional  assumption that all variance -covariance matrices \nhave a", "ional  assumption that all variance -covariance matrices \nhave an equal variance -covariance structure, i.e., \u03a3 k = \u03a3 for \nall classes k = 1, 2, \u2026, K. For the Quadratic Discriminant \nAnalysis (QDA), there is no equal variance -covariance \nassumption. Regul", "(QDA), there is no equal variance -covariance \nassumption. Regularized Discriminant Analysis (RDA) assumes 17 \n that \u03a3k(\u03b1) = \u03b1 \u03a3k + (1 \u2212 \u03b1) \u03a3 with \u03b1 given as a tuning parameter \ndecided by a cross -validation procedure.  \n \nDetails of Discriminant Analysis", "ross -validation procedure.  \n \nDetails of Discriminant Analysis \u2013 LDA and QDA:  \n1. Assume that given a particular class G = k, the pdf of the input -\nvariables X k-matrix = xk-matrix , fk(xk-matrix ) = Pr(X k-matrix  = \nxk-matrix  | G = k), has a multiva", "-matrix ) = Pr(X k-matrix  = \nxk-matrix  | G = k), has a multivariate normal distribution  with the \nfollowing pdf.  \n \n2. For LDA (Linear Discriminant Analysis)  further  assume that the \nvariance -covariance matrix \u03a3k = \u03a3 is the same for all classes k = ", "iance -covariance matrix \u03a3k = \u03a3 is the same for all classes k = 1, \n2, \u2026, K. Then,  \n18 \n  \n19 \n  \n \n20 \n  \n21 \n Note that the left -plot is the classification from the LDA  \nin a five-dimensional space (X 1, X 2, X 1*X 2, X 12, X22). Then, \nproject s LDA\u2019", "onal space (X 1, X 2, X 1*X 2, X 12, X22). Then, \nproject s LDA\u2019s  linear decision boundar ies into a 2-dimensional \nspace (X 1, X 2) for a visualization plot. The right -plot is the \nclassific ation from the QDA using X 1 and X 2 variables (2 -\ndimensions", "c ation from the QDA using X 1 and X 2 variables (2 -\ndimensions) only.  The results from these two procedures are \nsimilar, but different slightly.  \n------------------------------------------------------------------------------------  \n(c) Na\u00efve Bayes Cl", "-------------------------------------------  \n(c) Na\u00efve Bayes Classifier  \nThis is a special case of (general) Bayes Classifier defined in #3 \nabove. It can also be a special case of LDA/QDA/RDA.  \nInstead of using a (dependent) multivariate distribution t", "DA.  \nInstead of using a (dependent) multivariate distribution to \nmodel the data -likelihood, all X -variables are assumed to be \nindependent , and thus,  \n fk(xk-matrix ) = Pr(X k-matrix  = xk-matrix  | G = k)  \nis a product of marginal densities , i.e.,", "xk-matrix  | G = k)  \nis a product of marginal densities , i.e., pdfs for each X1k-vec, \nX2k-vec, \u2026, X pk-vec. In the example of LDA, QDA and RDA, \ncorrelations between all X -variables are all zeros . This implies \nthat the variance -covariance matrix \u03a3k ", "l zeros . This implies \nthat the variance -covariance matrix \u03a3k only has diagonal elements \n(i.e., variances) and all off -diagonal elements (i.e., covariances) are \nall zeros.  1 \n ISyE DDA  \u2013 Agenda for 0 2/23/23 Lecture (Lec. 13) \n1. Semester Project \u2019s", "\u2013 Agenda for 0 2/23/23 Lecture (Lec. 13) \n1. Semester Project \u2019s Decision -Model -1 (DM -1) Feedback  \na) General comments for DM -1 and DM -2 reports  \nb) General Decision -Model Structures  \nc) How is a decision model  linked to a data model ? \nd) Layer ", "\nc) How is a decision model  linked to a data model ? \nd) Layer s-of-Presentation (LoP)  \n2. Decisions in an Uncertain Environment  (DiUE) \u2013 Data \nModeling  \n----------------------------------------------------------------------------------  \nDetails : \n1.", "------------------------------------------------  \nDetails : \n1. Semester Project \u2019s Decision -Model -1 Feedback  \n \na) General Comments for DM -1 and DM -2 reports : \n \nIn students \u2019 decision -model -2 (DM -2) reports,  the following \nshould be presented ", " -model -2 (DM -2) reports,  the following \nshould be presented in layers -of-presentation sequence. \nSome details can be included in an appendix  to keep the \nmain content flow smoothly.  In DM -2 reports , all notations \nneed to be defined, and all equat", "DM -2 reports , all notations \nneed to be defined, and all equations need to be exp lained \nor justified.  2 \n  DM-2 reports need  to include a \u201ctransition \u201d paragraph for \nlinking the presentation of decision models to LoM studies of \nproblem background. ", "ation of decision models to LoM studies of \nproblem background. It is important to understand the rational \nof how students formu late a \u201cfocused  project prob lem\u201d out of \nmany possibilities in the problem background studies.  \n \nb) General Decision -Mode", "in the problem background studies.  \n \nb) General Decision -Model Structures  \nA decision model includes :  \n(1) decision variable (s), \n(2) objective functi on(s) to be optimized,  \n(3) constraint (s), \n(4) assumptions.  \n \nThree types of quantities might", "raint (s), \n(4) assumptions.  \n \nThree types of quantities might be involved in objective \nfunction(s) and constraint(s).  \n[1] decision variables  to be found via an optimization of the \nobjective functio n(s) and constraint(s) , \n[2] \u201cneeded quantities \u201d", "ctive functio n(s) and constraint(s) , \n[2] \u201cneeded quantities \u201d to be predicted, estimated,  or calculated \nvia data models , \n[3] \u201cgiven constants \u201d provided by users  of the decision \nmodel(s) . \n 3 \n c) How is a decision model  linked to a data model ?", "(s) . \n 3 \n c) How is a decision model  linked to a data model ? \nA decision model is linked to a data model via the \u201cneeded \nquantit ies\u201d discussed above. See examples below.  \n \nd) Layer s-of-Presentation (LoP)  \nLet us see two top DM -1 reports for illu", "f-Presentation (LoP)  \nLet us see two top DM -1 reports for illustrating the ir \napplications of the LoP technique.  \n \nTravel It inerary Creation:  \n \n \n4 \n  \n \n \n5 \n  \n \n \nRental Property:  \n \n6 \n  \n \n-----------------------------------------------------", "\n \n6 \n  \n \n--------------------------------------------------------------------------------  \n2. Decisions in an Uncertain Environment  (DiUE) \u2013 Data Modeling  \n(continuation  of materials presented b efore Exam -1) \nThe Supply Chain System:  \n7 \n  \nStep -", "sented b efore Exam -1) \nThe Supply Chain System:  \n7 \n  \nStep -1: Decision Model : \nA. Decision Variab le:  Q T = Total O rder -Quantity  for all \nsuppliers  \n \nB. Objective Function:  \nRetailer\u2019s Profit =  \n\u03a0(Q) = sales revenue \u2013 procurement cost \u2013 inven", "ler\u2019s Profit =  \n\u03a0(Q) = sales revenue \u2013 procurement cost \u2013 inventory cost  \n\u2013 \u201cstock -out\u201d cost  \n= r Min[ \u03be, (1 \u2013 Y)Q ] \u2013 c(1 \u2013 Y)Q \u2013 h[(1 \u2013 Y)Q \u2013 \u03be]+  \n\u2013 \u03c0[\u03be \u2212 (1 \u2013 Y)Q]+,       Eq. (2.2)  \nwhere [A]+ represents max[A, 0].  \n8 \n     Notations:  \n[1] r = ", "where [A]+ represents max[A, 0].  \n8 \n     Notations:  \n[1] r = unit -profit for products sold, \u03be = amount of products sold;  \n[2] Y is the average (random) proportion of defects for all \nproducts arrived at the retail store ; Thus, (1 \u2013 Y)Q T = \n#products", "ucts arrived at the retail store ; Thus, (1 \u2013 Y)Q T = \n#products (ordered and arrived at the store) without defects;  \n[3] c = unit -procurement cost, h = unit -holding -cost, and \u03c0 = unit -\nstockout -cost, where stock -out means that  no product to sell. ", "tockout -cost, where stock -out means that  no product to sell.  \n \nStep -2: Data Models  for Y : \n \nA. Defect -Data (Y) Modeling  includes the following four \nstages : \n(1) #defect s occurred during shipping from a Supplier S j (j = \n1, 2, \u2026, K) to DC; \n(", " during shipping from a Supplier S j (j = \n1, 2, \u2026, K) to DC; \n(2) Aggregation of products at the DC;  \n(3) #defect s occurred during shipping from DC to Store (R);  \n(4) Total #defects occurred during (1) \u2013 (3) above. See \ndetailed discussion of this stag", "ed during (1) \u2013 (3) above. See \ndetailed discussion of this stage in Layer -2 modeling in \nfile 1.2) Details _Supplier_to -DC-to-Store\u2026..  \n 9 \n B. \u201cContingent\u201d versus \u201cTypical\u201d Situations:  \nIn this problem our focus of the uncertainty  is that there are ", "In this problem our focus of the uncertainty  is that there are \ntwo situations for the shipping process: (i) contingent \nsituation and (ii) typical situation. In the contingent situation, \nthe proportion of #defects in the shipped products is large, \ne.g.", "e proportion of #defects in the shipped products is large, \ne.g., 40% , but the chance to face this situation is small, e.g., 0 \n\u2013 5%. On the other hand, in the typical situation, the \nproportion of #defects is small, e.g., 5%, but the chance for \nthis to ", "ion of #defects is small, e.g., 5%, but the chance for \nthis to happen is large, e.g., 95%.  \n \nThe following provides an example of modelin g the \n#defects in the process of shipping products from a supplier \nSj (j = 1, 2, \u2026, K) to DC . Denoted by XjC and", " from a supplier \nSj (j = 1, 2, \u2026, K) to DC . Denoted by XjC and XjN (for j = 1, 2, \n\u2026, K) the (random)  proportion of defective products in a unit -\nproduct shipment during the contingent and typical situations, \nrespectively. Define an indicator function", " typical situations, \nrespectively. Define an indicator function Ij as Ij = 1 if it is a \ncontingent situation; Ij = 1, otherwise. For a supplier Sj the \nproportion of defects for a uni t of products is then  \nPjDC = (1 \u2212 Ij)*XjN + Ij*XjC,   j = 1, 2, \u2026, K", "roducts is then  \nPjDC = (1 \u2212 Ij)*XjN + Ij*XjC,   j = 1, 2, \u2026, K,  (1) \nwhich is a random variable consisting of two cases with their \nown corresponding proportions of defects. Discussion of the 10 \n distributions  of these three  random variables  are ski", "he 10 \n distributions  of these three  random variables  are skipped here.  \nSee file  1.2) Example_Supplier_to -DC-to-Store\u2026.. for \ndetails.  \n[2] Details of Defect -Data (Y) Modeling:  \nThe following provide details of probability -based Y -data modeling", "following provide details of probability -based Y -data modeling \nfor the four stages  (discussed in page 4 above) from suppliers to \nthe retail store.  \n \n1> Stage -1: Shipping from Supplier S j (j = 1, 2, \u2026, K) to DC:  \nFor a supplier Sj the proportion o", "S j (j = 1, 2, \u2026, K) to DC:  \nFor a supplier Sj the proportion of  defects  for a unit of \nproducts is then  \nPjDC = (1 \u2212 Ij)*XjN + Ij*XjC,   j = 1, 2, \u2026, K,   (1) \nwhich is a random variable with a mixture distribution of two \ncases with their own corresp", "with a mixture distribution of two \ncases with their own corresponding proportions of defects.  \n \n2> Stage -2: Aggregation of Products at DC  - \u201cAverage -\nAggregation\u201d:  \n(1) Unevenly -split Ordered -Quantity Q Sj for j = 1, 2, \u2026, K:  11 \n Because for eac", "Ordered -Quantity Q Sj for j = 1, 2, \u2026, K:  11 \n Because for each supplier there are Q Sj*PjDC #defects \namong Q Sj #ordered -products, the average -aggregated \nproportion of defects from all suppliers  is \n \n Pau,DC = \u03a3j=1K (QSj*PjDC) / Q T,            (2", "suppliers  is \n \n Pau,DC = \u03a3j=1K (QSj*PjDC) / Q T,            (2) \n \nwhere Q T = \u03a3j=1K QSj is the total number of ordered -\nproducts.  Note that  the numerator in Eq.(2) is the total \nnumber of defects from all suppliers\u2019 products . \n \n3> Stage -3: Shippin", "f defects from all suppliers\u2019 products . \n \n3> Stage -3: Shipping from DC to Store :  \n \nOur goal is to formulate Y* \u2261 the average proportion of defects \nfor one unit of products shipped from suppliers through DC \nand to the store, which was the goal of th", "suppliers through DC \nand to the store, which was the goal of the defect -data-\nmodeling studies.  \n \n(1) Unevenly -split Ordered -Quantity Q Sj for j = 1, 2, \u2026, K:  \nSimilar to the definitions of the three random variables (1) \nabove, for shipping from DC", "s of the three random variables (1) \nabove, for shipping from DC to store  we have XC* and XN* \n(for j = 1, 2, \u2026, K) the proportion of defective products in a 12 \n unit-product shipment during the contingent  and typical \nsituations, respectively. The indi", " the contingent  and typical \nsituations, respectively. The indicator function I0 is defined \nas I0 = 1 if it is a contingent situation ; I0 = 1, otherwise. \nThen, the proportion ( PR) of defects from shipping \nbetween DC and store  is \nPR = (1 \u2013 I0)*XN* +", "cts from shipping \nbetween DC and store  is \nPR = (1 \u2013 I0)*XN* + I0*XC*.     (3) \nNote that there are \u03a3 j=1K (QSj*PjDC) amount of defects out \nof Q T total number of products -ordere d (and shipped from \nsuppliers). Assume that there is NO INSPECTION at th", "ipped from \nsuppliers). Assume that there is NO INSPECTION at the \nDC for taking out defective products. There are   \nQT \u2212 \u03a3j=1K (QSj*PjDC)  \n= Q T \u2013 QT *Pau,DC = QT *(1 \u2212 Pau,DC)                  (4)            \namount of non-defective products shipped fr", "     (4)            \namount of non-defective products shipped from DC to \nstore . See Eq. (2) for understanding the first equality \nabove.  \nSince the Q T *(1 \u2212 Pau,DC) amount of non-defective \nproducts shipped from DC to store will subject to further \nshi", " \nproducts shipped from DC to store will subject to further \nshipping damage (with the probability PR defined in \nEq.(3)), the #defects for non-defective products shipped \nfrom DC and arrived at the store is  13 \n QT *(1 \u2212 Pau,DC) * PR. \nNote that there ar", "at the store is  13 \n QT *(1 \u2212 Pau,DC) * PR. \nNote that there are only Q T *(1 \u2212 Pau,DC) * (1 \u2212 PR) amount \nof non -defective products arrived at the store eventually.  \n \n4> Stage -4: Calculate total #defects occurred at all stages.  \nFrom supplier\u2019s (or ", "te total #defects occurred at all stages.  \nFrom supplier\u2019s (or logistics service provider\u2019s) point of \nview, the total #defects (and its proportion) occurred at Stage \n(1) and (3)\u2019s shipping processes is important for calculating \nthe cost of product -sup", "processes is important for calculating \nthe cost of product -supply. From retailer\u2019s (store manager\u2019s) \npoint of view, the #good -products arrived at the store and \nalso the proportion (#good -products arrived at the store / \n#total -ordered -products) is ", "-products arrived at the store / \n#total -ordered -products) is important for supporting their \nsales (to meet customer demands).  \n \n(1) Unevenly -split Ordered -Quantity Q Sj for j = 1, 2, \u2026, \nK:  \n \nThere are \u03a3 j=1K (QSj*PjDC) amount of defects in Stage", ", \nK:  \n \nThere are \u03a3 j=1K (QSj*PjDC) amount of defects in Stage -1. \nAmong Q T *(1 \u2212 Pau,DC) good -products (see Eq.(4)) 14 \n shipped in Stage -3, there are Q T *(1 \u2212 Pau,DC) * PR \namount of defects. Thus, the total #defects is  \n \u03a3j=1K (QSj*PjDC) + Q T *", "defects. Thus, the total #defects is  \n \u03a3j=1K (QSj*PjDC) + Q T *(1 \u2212 Pau,DC) * PR. \nIf one is interested in the average -proportion of defects \nin all stages , it is then  \nY = [ \u03a3 j=1K (QSj*PjDC) + Q T *(1 \u2212 Pau,DC) * PR ] / Q T . \n-----------------------", "jDC) + Q T *(1 \u2212 Pau,DC) * PR ] / Q T . \n------------------------------------------------------------------------------------  \nStep -3: Optimizatio n-Solution Procedures  \n1) Risk Neutral:  Find Q \u2261 QT,opt = total order -quantity to \nmaximize Expected Pro", "ind Q \u2261 QT,opt = total order -quantity to \nmaximize Expected Profit . \n2) Risk Averse:  \ni) Constrained Optimization I \u2013 Profit Constraint  \nMaximize the Expected Profit  \nsubject to that the expected profit in the contingent \nsituation is over a certain t", "expected profit in the contingent \nsituation is over a certain threshold. That is,  15 \n  \nNotations : \n[1] G is the distribution for the random variable Y (= \naverage proportion of defects for products arrived at the \nstore). G has the mixture distributio", "r products arrived at the \nstore). G has the mixture distribution mixing from \ndistributions in both contingent and typical situations ; \nThe expectation in the main objecti ve is taken with \nrespect to (w.r.t.) the distribution G; See File 1.2) \nExample_S", "respect to (w.r.t.) the distribution G; See File 1.2) \nExample_Supplier\u2026. for details of G.  \n[2] G c is the distribution for the random variable Y in the \ncontingent situation ; The expectation in the constraint is \ntaken w.r.t. G c. \n \n16 \n ii)  Constrai", "on in the constraint is \ntaken w.r.t. G c. \n \n16 \n ii)  Constraine d Optimization II \u2013 Probability \nConstraint  \nMaximize Expected Profit  \nsubject to that in the contingent situation the \nprobability of (profit being less than a given \namount) is less tha", "bability of (profit being less than a given \namount) is less than or equal to a certain threshold.  \n \nRemarks:  \n[1] The expectation for the  objective should be taken w.r.t. \nto G defined in (i) above.  \n[2] The probability evaluation for the constraint ", " (i) above.  \n[2] The probability evaluation for the constraint should be \ntaken w.r.t. to G c for the contingent situation.  \n17 \n  \niii) Mean -Variance Solution  \n \nwhere GN is the distribution for the random variable Y \nin the typical situation ; \n \niv)", "ion for the random variable Y \nin the typical situation ; \n \niv) Max -Min Solution  \n \nRemark s: The worse -case of the expected -profit occurs in \nthe contingent situation, where 40% of products shipped \n18 \n are defective. Thus, the optimal total order -", "cts shipped \n18 \n are defective. Thus, the optimal total order -quanti ty Q T,opt \nis located to maximize this worse -case expected -profit.  \n------------------------------------------------------------------------------------  \nFinal Remarks:  \nWhen a pr", "-----------------------------------  \nFinal Remarks:  \nWhen a procedure is developed, one needs to explore properties \nof this procedure and compare them with respect to a few \nalternative solutions (i.e., optimization models/methods). In \nexploring these ", "utions (i.e., optimization models/methods). In \nexploring these properties, data models\u2019 distribution parameter \nvalues  should be changed to represent various real -world \nsituations. Moreover, several constants  involved in the decision -\nmodel (e.g., un", "r, several constants  involved in the decision -\nmodel (e.g., unit -profit, and unit -procurement, - holding, -\nstockout costs) need to be varied for exploring different situations \npossibly occurr ed in real -life supply -chain practices.  \n   The origina", "ccurr ed in real -life supply -chain practices.  \n   The original studies Kim, Lu, Kvam and Tsao (2011) have \napplied analytical methods and numerical calculations to explore \nproperties of the developed models and optimization methods. \nThe following prov", "e developed models and optimization methods. \nThe following provides an examp le of a brief summary of these \nproperties.  \n \n 1 \n ISyE DDA  \u2013 Agenda for 0 2/16/23 Lecture (Lec. 12) \n1. Exam -1 Review \u2013 Exam -1 Topics  \n2. 2022 & 2020 Past Exam -1 Problems", "1 Review \u2013 Exam -1 Topics  \n2. 2022 & 2020 Past Exam -1 Problems and Solutions  \n----------------------------------------------------------------------------------  \nDetails:  \nISyE-DDA - Exam -1 Subjects  \nExams in 202 3 Spring  will all be in -class exam", " -1 Subjects  \nExams in 202 3 Spring  will all be in -class exams .  \n \n1. Data Modeling (50%) \u2013 focus on  \n \ni) Logistic  Regression , GLM and Nonlinear Regression  \n \n1. Decision Modeling (40%) \u2013 focus on formulating simple real -world \nproblems into dec", "0%) \u2013 focus on formulating simple real -world \nproblems into decision -models using the following techniques.  \ni) Linear Programming (including Linear Integer and Linear \nMixed Integer Programming)  (skipped in your exam)  \nii) Non-Linear Programming  (hi", "mming)  (skipped in your exam)  \nii) Non-Linear Programming  (high -level conceptual questions)  \niii) Multi -Objective Optimization  \n \n2. Semester -Proje ct Questions (10%): \ni) Problem Formulation Techniques: LoM  \nii) Decision Model Formulation Techniq", "ulation Techniques: LoM  \nii) Decision Model Formulation Techniques : Formulating \nobjective function(s), decision variables and constraints with \nEnglish.  2 \n There will be a few high-level conceptual from various  semester \nprojects . Examples will be p", "conceptual from various  semester \nprojects . Examples will be presented in lectures.  \n=================================================  \n2022 Fall ISyE 4034 Exam #1 (V1)  Name :__ Solution     \nA) True and False Questions  (5 points for each question). ", "    \nA) True and False Questions  (5 points for each question).  \n(True,  False ) 1.  R2 is used in Logistic Regression and Generalized \nLinear Models for evaluating how well a model fits the \ndata.  \nAnswer: False. Because the ANOVA decomposition, SSTO = ", "\ndata.  \nAnswer: False. Because the ANOVA decomposition, SSTO = SSR + SSE does not hold in \nthe logistic, GLM and Nonlinear regressions, R2 = SSR/SSTO does not \nexist.  \n(True,  False )  2.  The following is a nonlinear regression model:  \n   Y = \u03b20 + exp(", "he following is a nonlinear regression model:  \n   Y = \u03b20 + exp(\u03b2 1)*(x2) + \u03b5. \nAnswer: False. One can redefine \u03b2 2 = exp(\u03b2 1) and x2 = (x2) to re -formulate the above as the \ntypical linear regression model: Y = \u03b2 0 + \u03b22 *x2 + \u03b5. \n(True ,  False)  3.  The", "egression model: Y = \u03b2 0 + \u03b22 *x2 + \u03b5. \n(True ,  False)  3.  The following is a nonlinear -programming model for \noptimizing decision variables, x 1, x2, x3: g(x 1, x2, x3) = \nexp(x 1) * (x 2)2 + x 3. \nAnswer: True. Notice the nonlinear form of the decisio", "2 + x 3. \nAnswer: True. Notice the nonlinear form of the decision variable x1, and also the \nmultiplication of two decision variables x1 and x2, which makes the above \nmodel nonlinear.  \n(True,  False )  4.  In \u03b5-constraint and Lexicographic multi -objecti", ",  False )  4.  In \u03b5-constraint and Lexicographic multi -objective \noptimization methods, the objective function or 3 \n constraint must be linear, i.e.,  it cannot be a nonlinear \nobjective/constraint.  \nAnswer: False. Some of the objective functions or/an", "nstraint.  \nAnswer: False. Some of the objective functions or/and constraints can be nonlinear in both \n\u03b5-constraint and Lexicographic multi -objective optimization methods.  \nOne just needs to follow the definitions of th ese two methods to find \nthreshol", "o follow the definitions of th ese two methods to find \nthresholds/bounds \u03b5 j or \u03b5i, respectively.  \n(True ,  False)  5.  The maximum likelihood estimation (MLE) is used in \nall GLM distributions including Poisson, Exponential, \nGamma and Normal, where in ", "ons including Poisson, Exponential, \nGamma and Normal, where in the Normal distribution \ncase, MLE is equivalent as the LSE (Least Squares \nEstimation).  \nAnswer: True. All GLM regressions require formulations of their likelihoods, which are \nderived from ", "uire formulations of their likelihoods, which are \nderived from their respective Y -data distributions.  \n(True,  False )  6.  In logistic regression s, MLE is the one respon sible for \nrelaxing the constraint that the regression mean = E(Y) \n= \u03c0 = Pr(Y = ", "ng the constraint that the regression mean = E(Y) \n= \u03c0 = Pr(Y = 1) is in (0, 1) interval.  \nAnswer: False. Logit -transformation (not the MLE) is the one responsible for relaxing the \nconstraint that the regression mean = E(Y) = \u03c0 = Pr(Y = 1) is  in (0, 1)", "nt that the regression mean = E(Y) = \u03c0 = Pr(Y = 1) is  in (0, 1) \ninterval. MLE is used to estimate unknown parameters.  \n \n(True,  False )  7.  The LoM (Layer -of-Modeling) tool is helpful in \ndirecting the steps that students should follow in their \nseme", " \ndirecting the steps that students should follow in their \nsemester -project studies.  \nAnswer: False. \u201cStudy Blueprint\u201d is the tool helpful in directing the \nsteps that students should follow in their semester -4 \n project studies. LoM is the tool for un", "w in their semester -4 \n project studies. LoM is the tool for understanding \nbreadth and depth of the problem background.  \n \n(True ,  False)  8. In this DDA class,  our data model is only used to \nsupport decision models. That is, if analyzing a data set ", "d to \nsupport decision models. That is, if analyzing a data set \ndoes not help completing decision models, it is not \nneeded in this class.  \nAnswer: True. This \u201crequirement\u201d is emphasized a few times in \nlectures.  \n(True ,  False)  9.  For selecting vari", "ew times in \nlectures.  \n(True ,  False)  9.  For selecting variables in  logistic or GLM regressions, \nexplanatory/input variables are selected to maximize a \nfunction of likelihood.  \nAnswer: True. AIC is a negative and linear function of log -likelihood", ": True. AIC is a negative and linear function of log -likelihood.  One \nselects regression variables to minimize the  AIC, which \nimplies that the log -likelihood is maximized. Thus, the \nlikelihood is maximized correspondingly.  \n(True ,  False) 10.  In l", "lihood is maximized correspondingly.  \n(True ,  False) 10.  In logistic  and GLM regressions, standard deviations \nof regression parameter estimates are derived from a \nlarge -sample CLT (Ce ntral Limit Theory).  \nAnswer: True. Because the unknown paramete", "tral Limit Theory).  \nAnswer: True. Because the unknown parameters including regression coefficients are \nestimated via the MLEs.  The large -sample CLT theory is used to derive \nthe estimates of the standard deviations of regression parameter \nestimates. ", " of the standard deviations of regression parameter \nestimates.  \n 5 \n B) Fill-In Blanks (5 points for each question):  \n11. In optimizing multi -objectives with the \u03b5 -Constraint Method. \nOne will  \n  Minimize   fj (x-vec)  with respect to x-vec in X -spa", " will  \n  Minimize   fj (x-vec)  with respect to x-vec in X -space  \nSubject to   fi (x-vec) \u2264 \u03b5j   for  i = 1, 2, \u2026, K except j.  \nWhat are the two key words in locating a \u201csingle\u201d upper bound \u03b5 j \nfor all secondary objectives (e.g., #job openings) that h", "d \u03b5 j \nfor all secondary objectives (e.g., #job openings) that have \ndifferent  metric values?  \n Answer:   Distribution Percentile    . \n \n Detailed Answers: One use the same percentile from the distributions of \nsecondary objective functions fi (x-vec), ", "the distributions of \nsecondary objective functions fi (x-vec), i = 1, 2, \u2026, K except j. The distribution \nof an objective function is constructed from all values of the objective evaluated \nwith all combinations of its decision variables.  \n \n12. What is ", "ith all combinations of its decision variables.  \n \n12. What is the distribution used to calculate p -values for the \nregression parameter estimates in the Nonlinear Regressions?  \nAnswer:   Normal distribution        \n \nDetailed Answers:  Note that finite", "ormal distribution        \n \nDetailed Answers:  Note that finite -sample student -t distributions for regression parameter \nestimates obtained  from the Nonlinear Least Squares method  taught in the class do \nnot exist. If the data (or errors) are distribu", "in the class do \nnot exist. If the data (or errors) are distributed as normal, the nonlinear least squares \nestimates are equivalent to the MLEs . Then, the large -sample CLT theory for the \nMLEs are used to approximate the distribution of the regression p", "LEs are used to approximate the distribution of the regression parameter estimates. \nThis implies that the MLEs of regression parameter estimates have normal 6 \n distributions approximately . Thus, normal distribution s should be used to calculate p -\nvalu", "Thus, normal distribution s should be used to calculate p -\nvalues for testing whether them are statistically significant.  \n \n \nC) Essay questions: (40 points in total)  \n \n13. What are the steps in formulating a Gamma regression \nprocedure? Please provid", "teps in formulating a Gamma regression \nprocedure? Please provide details including likelihood and link \nfunction.   [30 points]  \nAnswer:  \n \nStep -1: Formulate the Gamma regression model.  \n Let us use regression over mean of a GLM distribution here to f", " Let us use regression over mean of a GLM distribution here to formulate a \nGamma regression model.  \n[1] Y i = E(Y i) + \u03b5i, i = 1, 2, \u2026, n, \nwhere Y i  has a Gamma distribution with two parameters ( \u03b1, \u03b4i), and \nthe parameter \u03b1 is an unknown parameter. Th", "eters ( \u03b1, \u03b4i), and \nthe parameter \u03b1 is an unknown parameter. The second unknown \nparameter \u03b4i is linked to the regression function (see Item [3] \nbelow for details). Also, see pages 18 -19 Lecture -Notes W2.1.3) \nfor deta ils of Gamma regressions. Note th", "cture -Notes W2.1.3) \nfor deta ils of Gamma regressions. Note that I change the notation \u03b2 \nto \u03b4 in this presentation to avoid confusions to the regression \ncoefficients \u03b20, \u03b21, \u2026, \u03b2 m-1. \n The mean (\u2261 expected value) is a deterministic component in \nthis ", "e mean (\u2261 expected value) is a deterministic component in \nthis regression, and the modeling error \u03b5 i is a random variable \ndescribing the randomness of Y i-data.  7 \n  \n[2] According to the Gamma( \u03b1, \u03b4i) distribution posted in Lecture -Notes \nW2.1.3),  \n", "Gamma( \u03b1, \u03b4i) distribution posted in Lecture -Notes \nW2.1.3),  \nE(Y i) = \u03b1 / \u03b4i, i = 1, 2, \u2026, n, \nwhere the parameter \u03b4i is unknown and is related to the i-th subject, \ni.e., different data Y i has a distinct parameter \u03b4i.  \n \n[3] In the GLM regression, so", "i has a distinct parameter \u03b4i.  \n \n[3] In the GLM regression, some distribution parameters are \u201clinked\u201d to \nregression coefficients. In Gamma regressions, based on Lecture -Notes \nW2.1.3), the link function is  \n\u2212 \u03b4i = \u03b20 + \u03b21 x1i + \u2026 + \u03b2 m-1 xm-1i, \nwhere", " link function is  \n\u2212 \u03b4i = \u03b20 + \u03b21 x1i + \u2026 + \u03b2 m-1 xm-1i, \nwhere there could be one intercept and ( m \u2212 1) explanatory/input \nvariables, x1i, x2i, \u2026, xm-1i, and their corresponding UNKNOWN \nregression coefficients are \u03b2 0, \u03b21, \u2026, \u03b2 m-1. \n \n[4] Because the ", "gression coefficients are \u03b2 0, \u03b21, \u2026, \u03b2 m-1. \n \n[4] Because the mean E(Y i) = \u03b1 / \u03b4i involves the Gamma distribution \nparameter \u03b4i in the denominator, we need to \u201ctransform\u201d the link -\nfunction to 1/ \u03b4i. Note that from the link -function above  \n1/ \u03b4i = \u22121", "n to 1/ \u03b4i. Note that from the link -function above  \n1/ \u03b4i = \u22121 / [ \u03b20 + \u03b21 x1i + \u2026 + \u03b2 m-1 xm-1i ]. \nThus,  \nE(Y i) = \u03b1 / \u03b4i  \n= \u2212\u03b1 / [ \u03b20 + \u03b21 x1i + \u2026 + \u03b2 m-1 xm-1i ], 8 \n which is a NONLINEAR regression just like the logistic regression.  \n[5] In concl", "EAR regression just like the logistic regression.  \n[5] In conclusion, a Gamma regression model is  \nYi = \u2212\u03b1 / [ \u03b20 + \u03b21 x1i + \u2026 + \u03b2 m-1 xm-1i ] + \u03b5i,  i = 1, 2, \u2026, n, \nwhere the unknown distribution parameter \u03b1 and the regression \ncoefficients \u03b2 0, \u03b21, \u2026,", "ibution parameter \u03b1 and the regression \ncoefficients \u03b2 0, \u03b21, \u2026, \u03b2 m-1 will be estimated via the following MLE \nmethod.  \nPrediction of this Gamma regression is  \n Yi_hat = E(Y i)_hat  \n= \u2212\u03b1_hat / [ \u03b20_hat + \u03b21_hat x1i + \u2026 + \u03b2 m-1_hat xm-1i ]. \n \nStep -2: ", "at / [ \u03b20_hat + \u03b21_hat x1i + \u2026 + \u03b2 m-1_hat xm-1i ]. \n \nStep -2: Formulate the Likelihood Function preparing the ML estimation of \nregression coefficients.  \n[1] There are Y 1, Y2, \u2026, Y n data points in this regression problem. \nAssumption of mutual indepen", "points in this regression problem. \nAssumption of mutual independence  of these data implies that the \njoint distribution  of these n random variables is a product of their \nindividual \u201cmarginal distributions\u201d. Denoted by fYi(.) the pdf of the \ndistributio", "al distributions\u201d. Denoted by fYi(.) the pdf of the \ndistribution for data point Y i, i = 1, 2, \u2026, n. \n   If these data points all have the same distribution (other than \ntheir parameters), we say that these n random variables are \nidentically distributed ", " say that these n random variables are \nidentically distributed , i.e., fYi(.) = fY(.) without the specific subscript \n\u201ci\u201d in the pdf. Then, the joint distribution of these data, which is the \nlikelihood of th e data becomes  9 \n    Likelihood = \u220f i=1n fY(", "\nlikelihood of th e data becomes  9 \n    Likelihood = \u220f i=1n fY(.). \n   In the Negative Binomial distribution, according to page 22 \nof Lecture -Notes W2.1.3), NB\u2019s distribution pdf is  \n fY(.) = [ \u03b4\u03b1 y\u03b1-1 / \u0393(\u03b1) ] exp { \u2013 \u03b4 y }. \nApply this pdf to Y 1, Y2", ") = [ \u03b4\u03b1 y\u03b1-1 / \u0393(\u03b1) ] exp { \u2013 \u03b4 y }. \nApply this pdf to Y 1, Y2, \u2026, Y n data points, which have observations y 1, y2, \n\u2026, y n and their corresponding parameters ( \u03b1, \u03b41), (\u03b1, \u03b42), \u2026, ( \u03b1, \u03b4n). \nNote that the (shape) parameter \u03b1 is the same for all data po", ". \nNote that the (shape) parameter \u03b1 is the same for all data point due to \nthe identical distribution assumption. The unknown parameter \u03b4i, i = 1, \n2, \u2026, n, \u201cacts\u201d like Normal regression\u2019s mean \u03bc i = \u03b20 + \u03b21 x1i + \u2026 + \u03b2 m-\n1 xm-1i. In the Gamma regression", "an \u03bc i = \u03b20 + \u03b21 x1i + \u2026 + \u03b2 m-\n1 xm-1i. In the Gamma regression case, our parameters  \n   \u03b4i = \u2013 [ \u03b20 + \u03b21 x1i + \u2026 + \u03b2 m-1 xm-1i ], \ndiscussed in page 5 Item [4] above.  \nBased on the discussion above, the likelihood for a Gamma regression is  \n Likelihoo", "ion above, the likelihood for a Gamma regression is  \n Likelihood = \u220f i=1n { [ \u03b4i\u03b1 yi\u03b1-1 / \u0393(\u03b1) ] exp { \u2013 \u03b4i yi } } \n= \u220fi=1n { { [\u2013 ( \u03b20 + \u03b21 x1i + \u2026 + \u03b2 m-1 xm-1i )]\u03b1 yi\u03b1-1 / \u0393(\u03b1) } \n  * exp[ ( \u03b20 + \u03b21 x1i + \u2026 + \u03b2 m-1 xm-1i ) * yi ] } \nwhich involves all ", " ( \u03b20 + \u03b21 x1i + \u2026 + \u03b2 m-1 xm-1i ) * yi ] } \nwhich involves all data points y1, y2, \u2026, y n and unknown \ndistribution parameter \u03b1 and regression coefficients, \u03b20, \u03b21, \u2026, \u03b2 m-1. \n[2] Because every pdf has a value between 0 and 1, multiplication of these \npdf", "ry pdf has a value between 0 and 1, multiplication of these \npdf\u2019s n times will make the value of the likelihood very small. \nTraditionally, to find the MLEs of these regression coefficients, one 10 \n maximizes logarithmic of the likelihood, called  log-Li", "one 10 \n maximizes logarithmic of the likelihood, called  log-Likelihood with \nrespect to these m unknown regression coefficient.  \nStep -3: Apply a computing algorithm such as Newton -Raphson method \nto maximize the Log -Likelihood(\u03b1; \u03b2 0, \u03b21, \u2026, \u03b2 m-1) f", " method \nto maximize the Log -Likelihood(\u03b1; \u03b2 0, \u03b21, \u2026, \u03b2 m-1) for locating the \nMLEs, \u03b1_hat, \u03b2 0_hat, \u03b2 1_hat, \u2026, \u03b2 m-1_hat.  \n \nStep -4: Use the MLEs in a Gamma regression function to make a \nprediction. Large -Sample CLT theorem can be used to obtain \nt", " \nprediction. Large -Sample CLT theorem can be used to obtain \nthe confidence interval of the prediction and test whether each \nregression coefficient estimate is significant.  \n \n14. List the steps log ically in using the linearly weighted sum method \nfor", " steps log ically in using the linearly weighted sum method \nfor optimizing multiple objectives?   [10 points]  \nAnswer:  \nStep -1: Normalized all objective functions such that their values are \ncompatible, e.g., their values are all in the [0, 1] regions.", "e \ncompatible, e.g., their values are all in the [0, 1] regions.  \nA procedure to normalize objective functions is to use the \nfollowing re -centering and re -scaling formula to make their values \ninto [0, 1] regions.  \nNormalized Objective = fiN(decision ", "ues \ninto [0, 1] regions.  \nNormalized Objective = fiN(decision variables)  \n= (Objective function \u2013 Min) / ( Max \u2013 Min ),  \nwhere Min (or Max) = minimum (or maximum) of this objective \nfunction evaluated with respect to (w.r.t.) all possible values of \nde", "on evaluated with respect to (w.r.t.) all possible values of \ndecision variables.  11 \n  \nStep -2: Decide the weights wi, i = 1, 2, \u2026, K (= #objectives), for each \nobjective. Note that sum of all weights is one.  \n \nStep -3: Create a single objective by ad", "all weights is one.  \n \nStep -3: Create a single objective by adding all normalized objectives \nmultiplied by their corresponding weights.  \n Overall Objective(decision variables) = \u2211 i=1K wi * fiN(decision \nvariables).  \n \nStep -4: Perform the optimizatio", "* fiN(decision \nvariables).  \n \nStep -4: Perform the optimization of the above overall objective \nw.r.t. decision variables.  \n-------------------------------------------------------------------------------------------  \n 2020 Fall  ISyE 4803/8803 (LUJ -DD", "--------------------------  \n 2020 Fall  ISyE 4803/8803 (LUJ -DDA) (V1) Exam #1    \n[70%]  \nA) True and False Questions  (5 points for each question).  \n(True ,  False) 1.  In logistic regression s the logit -transformation can be \nreplaced by any transfor", "ion s the logit -transformation can be \nreplaced by any transformation that maps \u03c0 i = Pr(Y i = 1) \nwith the [0, 1] range to another parameter with (\u2212\u221e, +\u221e) \nrange.  \nAnswer: True. For example , Probit transformation \u03a6\u22121(\u03c0i) can do the same as what logit-\n", " , Probit transformation \u03a6\u22121(\u03c0i) can do the same as what logit-\ntransformation does.  Please google Probit -transformation for details.  12 \n (True ,  False) 2.  In Poisson  Regression s (an example of GLM) the mean \nof Y-data is a nonlinear function of re", "xample of GLM) the mean \nof Y-data is a nonlinear function of regression parameters \n\u03b20, \u03b21, \u03b22, \u2026 \nAnswer: True. Because the link func tion in Poisson -regression is log(\u03bb) \n= \u03b20 + \u03b21 x1 + \u03b22 x2 + \u2026, the mean of Y -data = E(Y) = \u03bb is \nlinked to regression", " x2 + \u2026, the mean of Y -data = E(Y) = \u03bb is \nlinked to regression parameters as \u03bb = exp(\u03b2 0 + \u03b21 x1 + \u03b22 \nx2 + \u2026), which is nonlinear.  \n(True,  False ) 3.  To formulate the likelihood for the maximum -\nlikelihood -estimation (MLE) of model parameters, the ", "maximum -\nlikelihood -estimation (MLE) of model parameters, the \nonly information  needed is that the i.i.d. assumption is \nvalid.  \nAnswer: False. Besides the i.i.d. assumption, the Y -data-distribution information is critical in \nformulating the likeliho", "istribution information is critical in \nformulating the likelihood . \n(True,  False ) 4.  In logistic  regression s, p-values for parameter -\nestimates should be calculated from the student -t \ndistribution like those in the typical linear -regressions.  \n", " \ndistribution like those in the typical linear -regressions.  \nAnswer: False. Because MLE is used to estimate parameters in the logistic -regression, normal \ndistribution shall be used to calculate their p -values (assuming that the sample \nsize is large)", "culate their p -values (assuming that the sample \nsize is large).  \n(True,  False ) 5.  R -square or Adjusted -R-square commonly seen in \ntypical regression should be useful in logistic  regression s. \nAnswer: False. Th e assumptions needed to calculate th", "ssion s. \nAnswer: False. Th e assumptions needed to calculate the R -square or Adjust -R-square (e.g., \nANOVA decomposition to calculate SSR) do not exist in the logistic -\nregression.  13 \n (True,  False ) 6.  Both stepwise -regression and all -subsets -r", "True,  False ) 6.  Both stepwise -regression and all -subsets -regression are \nnot useable for selecting im portant variables in logistic  \nregression s. \nAnswer: False. All  subsets  regression is still useful. However, the AIC -\nmetric should be used in ", "on is still useful. However, the AIC -\nmetric should be used in comparing models with various \nvariable -combinations.  \n(True,  False ) 7.  When a logistic  regression is used to classi fy the \npredicted outcomes into Class -1 or Class -0, one always \nuse", "e \npredicted outcomes into Class -1 or Class -0, one always \nuses the rule that Prediction of Pr(Y 0 = 1) \u2265 0.5, Classify \nY0 into Class -1; otherwise, classify it into Class -0. The \npercentage 0.5 in the decision -rule cannot  be changed to \nanother perc", "ge 0.5 in the decision -rule cannot  be changed to \nanother percentage.  \nAnswer: False. The percentage 0.5 is used for convenience  only. In \npractice, if the risk of the mis -classification into Cla ss-1 is \nhigher, one can raise this percentage to 0.6 (", "into Cla ss-1 is \nhigher, one can raise this percentage to 0.6 (or higher) to \nmake its mis -classification rate smaller.  \n \n(True ,  False) 8. In solving multi -objective optimization problems, the \u03f5-\nconstraint method only maximizes (or minimizes) one \n", "ms, the \u03f5-\nconstraint method only maximizes (or minimizes) one \nobjective -function and leaves the other objective -functions \ninto constraints.  \nAnswer: True. This is the definition of the \u03f5-constraint method.  14 \n (True,  False ) 9.  In applying layer ", "-constraint method.  14 \n (True,  False ) 9.  In applying layer -of-modeling to explore uncertainties \nin the airplane -defrosting -management -system (ADMS), \nweather -with-heavy -snow or weather -with-no-snow \nshould be modeled in the top -layer, but sou", "ther -with-no-snow \nshould be modeled in the top -layer, but source -of-\nuncertainty such as weather -condition and external -factor \n(e.g., VIP -plane arrivals and takeoffs) should be modeled \nin the second layer . \nAnswer:  False. They should be reversed", " \nin the second layer . \nAnswer:  False. They should be reversed. That is, details of the weather \ncondition (e.g., heavy or no snow) should be modeled in \nthe second layer . \n(True ,  False) 10.  The first task in building a simulation system for \nenterta", "10.  The first task in building a simulation system for \nentertaining what -if decisions in the ADMS is to layout all \nsteps an airplane needs to go through before departing. The \nsecond task is then to compile past -data for understanding \nthe distributio", "is then to compile past -data for understanding \nthe distribution of elapse -time in each step.  \nAnswer: True.  \n \nB) Short -Answer Questions:  \n11.  What are the three  best properties of the MLEs?  [6 points]  \nAnswer: When sample -size is large (e.g., ", "e MLEs?  [6 points]  \nAnswer: When sample -size is large (e.g., more than 30),  \n (1) the MLEs have a normal distribution,  \n (2) consistency, which means that the bias (= E(MLE) \u2013 true \nparameter value) goes to zero,  15 \n  (3) smallest varianc e compared", "eter value) goes to zero,  15 \n  (3) smallest varianc e compared variances from all other estimation \nmethods.  \n \n12.  (a) Present one example briefly for the nonlinear -optimization \nmodel. Use generic notation that the objective function f (x1, \nx2, x3)", "Use generic notation that the objective function f (x1, \nx2, x3) is a function of three decision -variables x1, x2 and x3.  [6 \npoints]  \n(b) NAME the key -technique addressed in the lecture for solving \nthe nonlinear optimization problem?  [4 points]  \nAn", "or solving \nthe nonlinear optimization problem?  [4 points]  \nAnswer: (a)  f (x1, x2, x3) = x1 * x2 +  x3. \n(b) Linear approximation (based on the Taylor expansion).  \n \n13.  Consider a multi -objective -optimization problem with two \nobjective -functions.", "-objective -optimization problem with two \nobjective -functions.  \n (a) Use a figure  to present the Pareto  Frontier ,   [5 points]  \n(b) Use the above figure to explain how to select the optimal \nsolution(s).   [5 points]  \nAnswer: See lecture notes. Stu", "imal \nsolution(s).   [5 points]  \nAnswer: See lecture notes. Students did quite well for this problem.  \n \nC) Essay Questions:  \n14.  In the plane -defrosting project suppose that there are three \nobjectives listed in the order of importance as below. Prov", "ree \nobjectives listed in the order of importance as below. Provide \nsteps with just enough details to describe how to implement the 16 \n Lexicographic method for this multi -objective optimization \nproblem.    [24 points]  \n(1) Minimize the percentage of ", "ation \nproblem.    [24 points]  \n(1) Minimize the percentage of planes, which did not meet the \n\u201cless -than -40-minute\u201d elapse -time  between door -closed -time to \nplane -depart -defrosting -station -time.  \n(2) Minimize the average elapse -time  defined ", "station -time.  \n(2) Minimize the average elapse -time  defined in (1).  \n(3) Minimize the average amount of the any defrosting -station is \nidled (i.e., not defrosting any plane) . \nAnswer: See lecture notes and past-exam solutions. Students did quite \nwe", "ee lecture notes and past-exam solutions. Students did quite \nwell with this problem.  \n \n 1 \n ISyE DDA  \u2013 Agenda for 0 2/14/23 Lecture (Lec. 11) \n1. New Materials for Exam -2  \ni) Decisions in an Uncertain Environment  (DiUE) \u2013 Data \nModeling  \nii) Conclu", "n an Uncertain Environment  (DiUE) \u2013 Data \nModeling  \nii) Concluding  Remarks  for DiUE studies  \n Note that the decision analytics modeling technique is \nexplained in this topic.  \n--------------------------------------------------------------------------", "------------------------------------------------------------------------  \nDetails:  \n1. Decisions in an Uncertain Environmen t \nExample \u2013 Order Quantity  Decisions Considering Uncertainty \nin Supply -Chain Logistics Operations (Kim, Lu, Kvam, Tsao, \n2011)", " Supply -Chain Logistics Operations (Kim, Lu, Kvam, Tsao, \n2011)  \nStep -0:  Problem Background  - Figure 1 in Kim at el.  (2011)  \nOur goal in this study is to decide the optimal Order \nQuantities Q i (i = 1, 2, \u2026, K) for K (= eg= 3) suppliers such \nthat ", "ities Q i (i = 1, 2, \u2026, K) for K (= eg= 3) suppliers such \nthat Retailer\u2019s profit is maximized. These suppliers Si (i = 1, \n2, \u2026, k)  ship the same product  through a distribution center \n(\u201cDC\u201d below) to one Retail (\u201cR\u201d notation). See Figure 1 2 \n below fo", "\u201d below) to one Retail (\u201cR\u201d notation). See Figure 1 2 \n below for a graphical display of this logistic system . Note that \nthere are uncertainties in the shipping process. The \nuncertainties include defect occurred during the shipping \nprocess and delayed ", "nclude defect occurred during the shipping \nprocess and delayed schedules for shipments. They are all \nquantified in \u201c defects \u201d from imperfect shipping in our studies \nbelow.  \n \n \n \nStep -1: Decision Model   \nThe goal is to locate the optimal order -quan", " Decision Model   \nThe goal is to locate the optimal order -quantity  by \nmaximizing the profit. However, due to uncertainty in the \nregular or contingent situations, the optimization process \nis much more involved. See Step -3 for details.  \n \n3 \n A. Deci", "\nis much more involved. See Step -3 for details.  \n \n3 \n A. Decision Variab le:  Q T = Total O rder -Quantity  for all \nsuppliers  \n \nB. Objective Function:  \nRetailer\u2019s Profit =  \n\u03a0(Q) = sales revenue \u2013 procurement cost \u2013 inventory cost  \n\u2013 \u201cstock -out\u201d c", "s revenue \u2013 procurement cost \u2013 inventory cost  \n\u2013 \u201cstock -out\u201d cost  \n= r Min[ \u03be, (1 \u2013 Y)Q ] \u2013 c(1 \u2013 Y)Q \u2013 h[(1 \u2013 Y)Q \u2013 \u03be]+  \n\u2013 \u03c0[\u03be \u2212 (1 \u2013 Y)Q]+,       Eq. (2.2)  \nwhere [A]+ represents max[A, 0].  \n    Notations:  \n[1] r = unit -profit for products sold, ", " 0].  \n    Notations:  \n[1] r = unit -profit for products sold, \u03be = amount of products sold;  \n[2] Y is the average (random) proportion of defects for all \nproducts arrived at the retail store ; Thus, (1 \u2013 Y)Q T = \n#products (ordered and arrived at the sto", " ; Thus, (1 \u2013 Y)Q T = \n#products (ordered and arrived at the store) without defects;  \n[3] c = unit -procurement cost, h = unit -holding -cost, and \u03c0 = unit -\nstockout -cost, where stock -out means that  no product to sell.  4 \n  \nStep -2: Data Models  for", "means that  no product to sell.  4 \n  \nStep -2: Data Models  for Y : \n \n[1] Background:  \n \nA. Defect -Data (Y) Modeling  includes the following four \nstages : \n(1) #defect s occurred during shipping from a Supplier S j (j = \n1, 2, \u2026, K) to DC; \n(2) Aggreg", "hipping from a Supplier S j (j = \n1, 2, \u2026, K) to DC; \n(2) Aggregation of products at the DC;  \n(3) #defect s occurred during shipping from DC to Store (R);  \n(4) Total #defects occurred during (1) \u2013 (3) above. See \ndetailed discussion of this stage in Laye", " (1) \u2013 (3) above. See \ndetailed discussion of this stage in Layer -2 modeling in \nfile 1.2) Details _Supplier_to -DC-to-Store\u2026..  \n \nB. \u201cContingent\u201d versus \u201cTypical\u201d Situations:  \nIn this problem our focus of the uncertainty  is that there are \ntwo situati", "lem our focus of the uncertainty  is that there are \ntwo situations for the shipping process: (i) contingent \nsituation and (ii) typical situation. In the contingent situation, \nthe proportion of #defects in the shipped products is large, \ne.g., 40% , but ", " of #defects in the shipped products is large, \ne.g., 40% , but the chance to face this situation is small, e.g., 0 \n\u2013 5%. On the other hand, in the typical situation, the 5 \n proportion of #defects is small, e.g., 5%, but the chance for \nthis to happen is", "efects is small, e.g., 5%, but the chance for \nthis to happen is large, e.g., 95%.  \nThe following provides an example of modelin g the \n#defects in the process of shipping products from a supplier \nSj (j = 1, 2, \u2026, K) to DC . Denoted by XjC and XjN (for j", "plier \nSj (j = 1, 2, \u2026, K) to DC . Denoted by XjC and XjN (for j = 1, 2, \n\u2026, K) the (random)  proportion of defective products in a unit -\nproduct shipment during the contingent and typical situations, \nrespectively. Define an indicator function Ij as Ij =", "tuations, \nrespectively. Define an indicator function Ij as Ij = 1 if it is a \ncontingent situation; Ij = 1, otherwise. For a supplier Sj the \nproportion of defects for a uni t of products is then  \nPjDC = (1 \u2212 Ij)*XjN + Ij*XjC,   j = 1, 2, \u2026, K,  (1) \nwhi", "then  \nPjDC = (1 \u2212 Ij)*XjN + Ij*XjC,   j = 1, 2, \u2026, K,  (1) \nwhich is a random variable consisting of two cases with their \nown corresponding proportions of defects. Discussion of the \ndistributions  of these three  random variables  are skipped here.  \nSe", "utions  of these three  random variables  are skipped here.  \nSee file  1.2) Example_Supplier_to -DC-to-Store\u2026.. for \ndetails.  \nRemark:   There could be more uncertain situations than our \nexample above with two situations (one is the contingent \nsituatio", "ample above with two situations (one is the contingent \nsituation and the other is the typical s ituation). One can \nassign a probability to each case, respectively, to formulate \na \u201cmixture\u201d data -model similar to Eq. (1) above.  6 \n ---------------------", "data -model similar to Eq. (1) above.  6 \n ------------------------------------------------------------------------------------  \n[2] Details of Defect -Data (Y) Modeling:  \nThe following provide details of probability -based Y -data modeling \nfor the four", "ide details of probability -based Y -data modeling \nfor the four stages  (discussed in page 4 above) from suppliers to \nthe retail store.  \n \n1> Stage -1: Shipping from Supplier S j (j = 1, 2, \u2026, K) to DC:  \nDenoted by XjC and XjN (for j = 1, 2, \u2026, K) the ", " \u2026, K) to DC:  \nDenoted by XjC and XjN (for j = 1, 2, \u2026, K) the proportion of \ndefective products in a unit -product shipment during the \ncontingent  and typical situations , respectively. They are both \nrandom -variables with distributions GC and GN, resp", "y are both \nrandom -variables with distributions GC and GN, respectively.  \nDefine an indicator function Ij as Ij = 1 if it is a contingent \nsituation ; Ij = 0, otherwise. The distribution of Ij is a Bernoulli \nwith Pr( Ij = 1) = p and Pr( Ij = 0) = 1 \u2013 p.", "Ij is a Bernoulli \nwith Pr( Ij = 1) = p and Pr( Ij = 0) = 1 \u2013 p. Assume that the three \nrandom -variables, XjC, XjN and Ij are mutually independent. For a \nsupplier Sj the proportion of  defects  for a unit of products is \nthen  \nPjDC = (1 \u2212 Ij)*XjN + Ij*X", "ts  for a unit of products is \nthen  \nPjDC = (1 \u2212 Ij)*XjN + Ij*XjC,   j = 1, 2, \u2026, K,   (1) \nwhich is a random variable with a mixture distribution of two \ncases with their own corresponding proportions of defects.  \n 7 \n 2> Stage -2: Aggregation of Produc", "roportions of defects.  \n 7 \n 2> Stage -2: Aggregation of Products at DC  - \u201cAverage -\nAggregation\u201d:  \n \n(1) Unevenly -split Ordered -Quantity Q Sj for j = 1, 2, \u2026, K:  \nBecause for each supplier there are Q Sj*PjDC #defects \namong Q Sj #ordered -products,", "ier there are Q Sj*PjDC #defects \namong Q Sj #ordered -products, the average -aggregated \nproportion of defects from all suppliers  is \n \n Pau,DC = \u03a3j=1K (QSj*PjDC) / Q T,            (2) \n \nwhere Q T = \u03a3j=1K QSj is the total number of ordered -\nproducts.  ", "ere Q T = \u03a3j=1K QSj is the total number of ordered -\nproducts.  Note that  the numerator in Eq.(2) is the total \nnumber of defects from all suppliers\u2019 products . \n \n(2) Evenly -split Ordered -Quantity Q Sj = Q T /K for j = 1, 2, \n\u2026, K \u2013 this is our focus. ", "Quantity Q Sj = Q T /K for j = 1, 2, \n\u2026, K \u2013 this is our focus.  \n \nThis option is a special case of (1) unevenly -split \nordered -quantity above. Apply the same formula with Q Sj \n= Q T /K to get  \n 8 \n  Pae,DC = \u03a3j=1K [(Q T /K)*PjDC)] / Q T = ( \u03a3j=1K PjD", " get  \n 8 \n  Pae,DC = \u03a3j=1K [(Q T /K)*PjDC)] / Q T = ( \u03a3j=1K PjDC ) / K,  \n \nwhich is a simple average of proportion  of defects from \nall suppliers\u2019. Notice the index \u201cae\u201d in the Proportion \n\u201cP\u201d for this case.  \n \n3> Stage -3: Shipping from DC to Store : ", "\u201cP\u201d for this case.  \n \n3> Stage -3: Shipping from DC to Store :  \n \nOur goal is to formulate Y* \u2261 the average proportion of defects \nfor one unit of products shipped from suppliers through DC \nand to the store, which was the goal of the defect -data-\nmodel", "\nand to the store, which was the goal of the defect -data-\nmodeling studies.  \n \n(1) Unevenly -split Ordered -Quantity Q Sj for j = 1, 2, \u2026, K:  \nSimilar to the definitions of the three random variables (1) \nabove, for shipping from DC to store  we have XC", " variables (1) \nabove, for shipping from DC to store  we have XC* and XN* \n(for j = 1, 2, \u2026, K) the proportion of defective products in a \nunit-product shipment during the contingent  and typical \nsituations, respectively. The indicator function I0 is defi", "cal \nsituations, respectively. The indicator function I0 is defined \nas I0 = 1 if it is a contingent situation ; I0 = 1, otherwise. 9 \n Then, the proportion ( PR) of defects from shipping \nbetween DC and store  is \nPR = (1 \u2013 I0)*XN* + I0*XC*.     (3) \nNote", "ween DC and store  is \nPR = (1 \u2013 I0)*XN* + I0*XC*.     (3) \nNote that there are \u03a3 j=1K (QSj*PjDC) amount of defects out \nof Q T total number of products -ordere d (and shipped from \nsuppliers). Assume that there is NO INSPECTION at the \nDC for taking out d", ". Assume that there is NO INSPECTION at the \nDC for taking out defective products. There are   \nQT \u2212 \u03a3j=1K (QSj*PjDC)  \n= Q T \u2013 QT *Pau,DC = QT *(1 \u2212 Pau,DC)                  (4)            \namount of non-defective products shipped from DC to \nstore . See ", "mount of non-defective products shipped from DC to \nstore . See Eq. (2) for understanding the first equality \nabove.  \nSince the Q T *(1 \u2212 Pau,DC) amount of non-defective \nproducts shipped from DC to store will subject to further \nshipping damage (with the", "m DC to store will subject to further \nshipping damage (with the probability PR defined in \nEq.(3)), the #defects for non-defective products shipped \nfrom DC and arrived at the store is  \nQT *(1 \u2212 Pau,DC) * PR. \nNote that there are only Q T *(1 \u2212 Pau,DC) *", "(1 \u2212 Pau,DC) * PR. \nNote that there are only Q T *(1 \u2212 Pau,DC) * (1 \u2212 PR) amount \nof non -defective products arrived at the store eventually.  10 \n  \n(2) Evenly -split Ordered -Quantity Q Sj = Q T /K for j = 1, 2, \n\u2026, K:  \n \nThis option is a special case o", " Q T /K for j = 1, 2, \n\u2026, K:  \n \nThis option is a special case of (1) unevenly -split \nordered -quantity above. Applying the same ideas as \ngiven above by replacing Pau,DC with Pae,DC for this \nevenly -split case, we have  the following #defects for \nnon-d", " \nevenly -split case, we have  the following #defects for \nnon-defective products shipped from DC and arr ived at \nthe store:  \nQT *(1 \u2212 Pae,DC) * PR. \n \n4> Stage -4: Calculate total #defects occurred at all stages.  \nFrom supplier\u2019s (or logistics service ", "occurred at all stages.  \nFrom supplier\u2019s (or logistics service provider\u2019s) point of \nview, the total #defects (and its proportion) occurred at Stage \n(1) and (3)\u2019s shipping processes is important for calculating \nthe cost of product -supply. From retailer", "tant for calculating \nthe cost of product -supply. From retailer\u2019s (store manager\u2019s) \npoint of view, the #good -products arrived at the store and \nalso the proportion (#good -products arrived at the store / 11 \n #total -ordered -products) is important for ", "at the store / 11 \n #total -ordered -products) is important for supporting their \nsales (to meet customer demands).  \n \n(1) Unevenly -split Ordered -Quantity Q Sj for j = 1, 2, \u2026, \nK:  \n \nThere are \u03a3 j=1K (QSj*PjDC) amount of defects in Stage -1. \nAmong Q ", "e are \u03a3 j=1K (QSj*PjDC) amount of defects in Stage -1. \nAmong Q T *(1 \u2212 Pau,DC) good -products (see Eq.(4)) \nshipped in Stage -3, there are Q T *(1 \u2212 Pau,DC) * PR \namount of defects. Thus, the total #defects is  \n \u03a3j=1K (QSj*PjDC) + Q T *(1 \u2212 Pau,DC) * PR.", " total #defects is  \n \u03a3j=1K (QSj*PjDC) + Q T *(1 \u2212 Pau,DC) * PR. \nIf one is interested in the average -proportion of defects \nin all stages , it is then  \nY = [ \u03a3 j=1K (QSj*PjDC) + Q T *(1 \u2212 Pau,DC) * PR ] / Q T . \n \n(2) Evenly -split Ordered -Quantity Q S", "au,DC) * PR ] / Q T . \n \n(2) Evenly -split Ordered -Quantity Q Sj = Q T /K for j = 1, \n2, \u2026, K: \n \nAgain, with Q Sj = Q T /K the above results in (1) becomes  \n 12 \n Y = [ \u03a3 j=1K [(Q/K)* PjDC] + Q T *(1 \u2212 Pau,DC) * PR ] / Q T \n= (\u03a3j=1K PjDC)/K + (1 \u2212 Pae,D", " + Q T *(1 \u2212 Pau,DC) * PR ] / Q T \n= (\u03a3j=1K PjDC)/K + (1 \u2212 Pae,DC) * PR. \nSince  Pae,DC = ( \u03a3j=1K PjDC ) / K, the above formula \nbecomes  \n Y = Pae,DC + (1 \u2212 Pae,DC) * PR  \n= Pae,DC (1 \u2212 PR) + PR \n= [( \u03a3j=1K PjDC ) / K ] * (1 \u2212 PR) + PR, \nwhich is the aver", " PR \n= [( \u03a3j=1K PjDC ) / K ] * (1 \u2212 PR) + PR, \nwhich is the average of proportion of defects for all \nproducts shipped from K-suppliers to store. This is the \nneeded Y in the objective function (2.2).  \n-----------------------------------------------------", "n (2.2).  \n------------------------------------------------------------------------------------  \nStep -3: Optimizatio n-Solution Procedures  \n1) Risk Neutral:  Find Q \u2261 QT,opt = total order -quantity to \nmaximize Expected Profit . \n2) Risk Averse:  \ni) Co", "quantity to \nmaximize Expected Profit . \n2) Risk Averse:  \ni) Constrained Optimization I \u2013 Profit Constraint  \nMaximize the Expected Profit  13 \n subject to that the expected profit in the contingent \nsituation is over a certain threshold. That is,  \n \nNot", "tingent \nsituation is over a certain threshold. That is,  \n \nNotations : \n[1] G is the distribution for the random variable Y (= \naverage proportion of defects for products arrived at the \nstore). G has the mixture distribution mixing from \ndistributions i", "re). G has the mixture distribution mixing from \ndistributions in both contingent and typical situations ; \nThe expectation in the main objecti ve is taken with \nrespect to (w.r.t.) the distribution G; See File 1.2) \nExample_Supplier\u2026. for details of G.  \n", "bution G; See File 1.2) \nExample_Supplier\u2026. for details of G.  \n[2] G c is the distribution for the random variable Y in the \ncontingent situation ; The expectation in the constraint is \ntaken w.r.t. G c. \n14 \n  \nii)  Constrained Optimization II \u2013 Probabil", " w.r.t. G c. \n14 \n  \nii)  Constrained Optimization II \u2013 Probability \nConstraint  \nMaximize Expected Profit  \nsubject to that in the contingent situation the \nprobability of (profit being less than a given \namount) is less than or equal to a certain thresho", "than a given \namount) is less than or equal to a certain threshold.  \n \nRemarks:  \n[1] The expectation for the objective should be taken w.r.t. \nto G defined in (i) above.  \n15 \n [2] The probability evaluation for the constraint should be \ntaken w.r.t. to ", "bility evaluation for the constraint should be \ntaken w.r.t. to G c for the contingent situation.  \n \niii) Mean -Variance Sol ution  \n \nwhere GN is the distribution for the random variable Y \nin the typical situation ; \n \niv) Max -Min Solution  \n \n16 \n Rem", "in the typical situation ; \n \niv) Max -Min Solution  \n \n16 \n Remark s: The worse -case of the expected -profit occurs in \nthe contingent situation, where 40% of products shipped \nare defective. Thus, the optimal total order -quantity Q T,opt \nis located to", ". Thus, the optimal total order -quantity Q T,opt \nis located to maximize this worse -case expected -profit.  \n------------------------------------------------------------------------------------  \nFinal Remarks:  \nWhen a procedure is developed, one needs ", "---  \nFinal Remarks:  \nWhen a procedure is developed, one needs to explore properties \nof this procedure and compare them with respect to a few \nalternative solutions (i.e., optimiz ation models/methods). In \nexploring these properties, data models\u2019 distri", "ls/methods). In \nexploring these properties, data models\u2019 distribution parameter \nvalues  should be changed to represent various real -world \nsituations. Moreover, several constants  involved in the decision -\nmodel (e.g., unit -profit, and unit -procureme", "in the decision -\nmodel (e.g., unit -profit, and unit -procureme nt, - holding, -\nstockout costs) need to be varied for exploring different situations \npossibly occurred in real -life supply -chain practices.  \n   The original studies Kim, Lu, Kvam and Tsa", "chain practices.  \n   The original studies Kim, Lu, Kvam and Tsao (2011) have \napplied analytical methods and numerical calculations to explore \nproperties of the developed models and optimization methods. \nThe following provides an example of a brief summ", "tion methods. \nThe following provides an example of a brief summary of these \nproperties.  \n 17 \n [1] The traditional expected -value approaches for product -\nordering decisions fail to provide the retailer with s ufficient \nmeans of protection against the", "e the retailer with s ufficient \nmeans of protection against the effects of contingency.  \n[2] In the  first procedure,  by constraining the maximization \nproblem with respect to conditional expected profit , a more \nstable and  risk-averse  solution  can ", "xpected profit , a more \nstable and  risk-averse  solution  can be found.  We consider  two \ncases, where  contingency  either  increases  the mean  of the \nproportion of  damage  distribution  or increases  the variance  of \nthe distribution.  An increase", "  or increases  the variance  of \nthe distribution.  An increase  in variance  causes  a rapid  drop in \nexpected profit,  leaving  no other  alternative  to compensate for  \nthe pr ofit loss.  On the other  hand,  the more  robust  methods  \nintroduced he", "  On the other  hand,  the more  robust  methods  \nintroduced here  compensate  for a mean  shift of the profit  \ncurve, resulting  in an increased  quantity  of the order.   \nIn practice,  it is recommended that  the retailer  investigate  \nthe characteri", " is recommended that  the retailer  investigate  \nthe characteristic  of potential contingency  to see how and if it \naffects  the mean  or the variance of Y. If the model implies \nthat the contingency changes only the mean, then  the retailer  \ncan benefi", "ntingency changes only the mean, then  the retailer  \ncan benefit  from  the first constrained optimization solution.  \nHowever,  if the contingency adversely affects  the variance,  \nthe decision  maker  should  find a way to  reduce  the variance,  \nperh", "sion  maker  should  find a way to  reduce  the variance,  \nperhaps  by using  multiple  sourcing  or purchasing options  by \nwhich  the damage  distribution  can be truncated.  18 \n [3] In the second procedure, we uti lize the probability constraint  \nto ", "e second procedure, we uti lize the probability constraint  \nto restrict possible solutions. With this procedure, the \ndecision -maker has more options to include risk preferences \nin the solution; one can change either the target profit level or \nthe targ", "tion; one can change either the target profit level or \nthe target probability level to derive ri sk-averse solutions. \nThis procedure illustrates the risk-pooling effects  of integrated \nlogistics operations under certain conditions.  \nWhenever the invent", "stics operations under certain conditions.  \nWhenever the inventory holding cost, the shortage cost  \nand retail prices of products from different suppliers  are \nidentical , separated logistics  operations between the \ndistribution center and the retailer", "cs  operations between the \ndistribution center and the retailer generate solutions with \nhigher expected profits compared to those of the integrated \nlogistics operation case. But in our examples, we show that \nthe resulting expecte d profits may be highe", "ples, we show that \nthe resulting expecte d profits may be higher under the \nintegrated logistics operation strategy than the expected \nprofits under separated logistics operations when shortage \ncosts are significantly different . \n \n \n \n \n 1 \n ISyE DDA  ", "ge \ncosts are significantly different . \n \n \n \n \n 1 \n ISyE DDA  \u2013 Agenda for 0 2/09/23 Lecture (Lec. 10) \n1. New Materials for Exam -2  \ni) Decisions in an Uncertain Environment   \n Note that the decision analytics modeling tech nique is \nexplained in this", "the decision analytics modeling tech nique is \nexplained in this topic.  \n----------------------------------------------------------------------------------  \n1. Decisions in an Uncertain Environment  \nDetails:  \nThis note uses one case study posted in the", "ronment  \nDetails:  \nThis note uses one case study posted in the following directory to \nsummarize  decisions  and data and models for supporting \ndecision -making  in an uncertain situation . Because the note here \nis only a summary, for more details of t", " Because the note here \nis only a summary, for more details of the study, please see \npresentation in the following files posted on Canvas . \nDirectory:   Files> 2. 2) Subject -Focused Lecture Notes> Decision \n2. Uncertainty Models and Dynamic Optimization", " Notes> Decision \n2. Uncertainty Models and Dynamic Optimizations>   \n \nExample \u2013 Order Quantity  Decisions Considering Uncertainty \nin Supply -Chain Logistics Operations (Kim, Lu, Kvam, Tsao, \n2011)  2 \n References:  Same Directory  \ni) Summary of Data an", " \n2011)  2 \n References:  Same Directory  \ni) Summary of Data and Decision Analytics \u2013 see 1.2) \nExample_Supplier_to -DC-to-Store_Defects.docx  \nii) The origina l publication \u2013 see 1.3) \nContract_Logistics_Decision_Uncertainty_IJPE_2011.pdf  \n \nStep -0:  P", "act_Logistics_Decision_Uncertainty_IJPE_2011.pdf  \n \nStep -0:  Problem Background  - Figure 1 in Kim at el.  (2011)  \nOur goal in this study is to decide the optimal Order \nQuantities Q i (i = 1, 2, \u2026, K) for K (=eg = 3) suppliers such \nthat Retailer\u2019s pro", " 1, 2, \u2026, K) for K (=eg = 3) suppliers such \nthat Retailer\u2019s profit is maximized. These suppliers Si (i = 1, \n2, \u2026, k)  ship the same product  through a distribution center \n(\u201cDC\u201d below) to one Retail (\u201cR\u201d notation). See Figure 1 \nbelow for a graphical dis", "e Retail (\u201cR\u201d notation). See Figure 1 \nbelow for a graphical display of this logistic system. Note that \nthere are uncertainties in the shipping process. The \nuncertainties include defect occurred during the shipping \nprocess and delayed schedules for ship", "rred during the shipping \nprocess and delayed schedules for shipments. They are all \nquantified in \u201c defects \u201d from imperfect shipping in our studies \nbelow.  3 \n  \n \n \nStep -1: Decision Model   \nThe goal is to locate the optimal order -quantity by \nmaximi", "   \nThe goal is to locate the optimal order -quantity by \nmaximizing the profit. However, due to uncertainty in the \nregular or contingent situations, the optimization process \nis much more involved. See Step -3 for details.  \n \nA. Decision Variable:  Q = ", "volved. See Step -3 for details.  \n \nA. Decision Variable:  Q = order -quantity  \nTo keep the study simple, we assume that all suppliers have \nan equal order quantity Qi = Q for i = 1, 2, \u2026, K. \nB. Objective Function:  \nRetailer\u2019s Profit =  \n4 \n \u03a0(Q) = sal", ". \nB. Objective Function:  \nRetailer\u2019s Profit =  \n4 \n \u03a0(Q) = sales revenue \u2013 procurement cost \u2013 inventory cost  \n\u2013 \u201cstock -out\u201d cost  \n= r Min[ \u03be, (1 \u2013 Y)Q ] \u2013 c(1 \u2013 Y)Q \u2013 h[(1 \u2013 Y)Q \u2013 \u03be]+  \n\u2013 \u03c0[\u03be \u2212 (1 \u2013 Y)Q]+,       Eq. (2.2)  \nwhere [A]+ represents max[A", " \u03c0[\u03be \u2212 (1 \u2013 Y)Q]+,       Eq. (2.2)  \nwhere [A]+ represents max[A, 0].  \nSee file Canvas> Files> 2. 2) Subject -Focused Lecture Notes> \nDecision 2. \u2026> 1.3) Contract_Logistics_Decision_Uncertainty_IJPE_2011.pdf  \nfor details.  \n    Notations:  \n[1] r = unit ", "ty_IJPE_2011.pdf  \nfor details.  \n    Notations:  \n[1] r = unit -profit for products sold, \u03be = amount of products sold;  \n[2] Y is the average (random) proportion of defects for all \nproducts arrived at the retail store ; Thus, (1 \u2013 Y)Q = \n#products (order", "arrived at the retail store ; Thus, (1 \u2013 Y)Q = \n#products (ordered and arrived at the store) without defects;  \n[3] c = unit -procurement cost, h = unit -holding -cost, and \u03c0 = unit -\nstockout -cost, where stock -out means that no product to sell.  \nExplan", " -cost, where stock -out means that no product to sell.  \nExplanations of the Profit (2.2):  5 \n [1] The first term is \u201csales revenue\u201d, where r = unit -profit for \nproducts sold and \u03be = amount of products sold. Y is the \nproportion of defects for one unit ", " of products sold. Y is the \nproportion of defects for one unit of products shipped \nfrom suppliers through DC and to the store.  Thus,  \n(1 \u2013 Y)Q = #products -ordered without defects. Sales revenue is \nunit-profit multiplied by #products sold. But, if (1 ", "evenue is \nunit-profit multiplied by #products sold. But, if (1 \u2013 Y)Q is \nless than #products sold (\u03be) due to many shipping defects, \nunit-profit ( r) should be multiplied to (1 \u2013 Y)Q instead of \u03be.  \n \n[2] The second term is the procurement cost, where c =", "of \u03be.  \n \n[2] The second term is the procurement cost, where c = unit -\nprocurement cost counted at the store. Because store manager \nonly pay s procurement cost for products arrived at store \nwithout defects, the total procurement cost is  c (1 \u2013 Y)Q.  \nO", "\nwithout defects, the total procurement cost is  c (1 \u2013 Y)Q.  \nOne could add another cost to incur the transportation cost for \ndefective products from supplier to DC and DC to the store. \nBut, since the store m anager will not accept defective \nproducts, ", ", since the store m anager will not accept defective \nproducts, this additional transportation cost should be charged \nto the logistics company or to the supplier, but not to the \nretailer.  \n \n[3] Inventory cost will incur for the case that (1 \u2013 Y)Q = \n#p", " \n[3] Inventory cost will incur for the case that (1 \u2013 Y)Q = \n#products -ordered without def ects is larger than or equal to 6 \n amount of products sold (\u03be). If there is not enough good -\nproducts to sell, the last -term, cost of \u201cstock -out\u201d, will be \ninc", "ucts to sell, the last -term, cost of \u201cstock -out\u201d, will be \nincurred. The notations h = unit -holding -cost, and \u03c0 = unit -\nstockout -cost. \n \nStep -2: Data Models  for Y \u2013 \u201cFirst -Path Presentation\u201d  \n \nA. Defect -Data Modeling  includes the following fo", "ntation\u201d  \n \nA. Defect -Data Modeling  includes the following four stages : \n(1) #defect s occurred during shipping from a Supplier S j (j = \n1, 2, \u2026, K) to DC; \n(2) Aggregation of products at the DC;  \n(3) #defect s occurred during shipping from DC to Sto", " the DC;  \n(3) #defect s occurred during shipping from DC to Store (R);  \n(4) Total #defects occurred during (1) \u2013 (3) above. See \ndetailed discussion of this stage in Layer -2 modeling in \nfile 1.2) Details _Supplier_to -DC-to-Store\u2026..  \n \nB. \u201cContingent\u201d", "le 1.2) Details _Supplier_to -DC-to-Store\u2026..  \n \nB. \u201cContingent\u201d versus \u201cTypical\u201d Situations:  \nIn this pro blem our focus of the uncertainty  is that there are \ntwo situations for the shipping process: (i) contingent \nsituation and (ii) typical situation.", "g process: (i) contingent \nsituation and (ii) typical situation. In the contingent situation, \nthe proportion of #defects in the shipped products is large, \ne.g., 40%, but the c hance to face this situation is small, e.g., 0 7 \n \u2013 5%. On the other hand, in", "this situation is small, e.g., 0 7 \n \u2013 5%. On the other hand, in the typical situation, the \nproportion of #defects is small, e.g., 5%, but the chance for \nthis to happen is large, e.g., 95%.  \nThe following provides an example of modeling the \n#defe cts i", " \nThe following provides an example of modeling the \n#defe cts in the process of shipping products from a supplier \nSj (j = 1, 2, \u2026, K) to DC . Denoted by XjC and XjN (for j = 1, 2, \n\u2026, K) the (random)  proportion of defective products in a unit -\nproduct ", " (random)  proportion of defective products in a unit -\nproduct shipment during the contingent and typical situations, \nrespectively. Define an indicator function Ij as Ij = 1 if it is a \ncontingent situation; Ij = 1, otherwise. For a supplier Sj the \nprop", "ingent situation; Ij = 1, otherwise. For a supplier Sj the \nproportion of defects for a uni t of products is then  \nPjDC = (1 \u2212 Ij)*XjN + Ij*XjC,   j = 1, 2, \u2026, K,  (1) \nwhich is a random variable consisting of two cases with their \nown corresponding propo", "able consisting of two cases with their \nown corresponding proportions of defects. Discussion of the \ndistributions  of these three  random variables  are skipped here.  \nSee file  1.2) Example_Supplier_to -DC-to-Store\u2026.. for \ndetails.  \nRemark:   There co", "e_Supplier_to -DC-to-Store\u2026.. for \ndetails.  \nRemark:   There could be more uncertain situations than our \nexample above with two situations (one is the contingent \nsituation and the other is the typical situation). For \nexample, in our defrosting projects", "the typical situation). For \nexample, in our defrosting projects, one can see that when 8 \n the weather is \u201ctypically\u201d nice, the proportion of planes met \nthe \u201c40 -minute -rule\u201d is above 90%. On the other hand, \nwhen the weather is not that bad, but still ", "On the other hand, \nwhen the weather is not that bad, but still not the best, the \nproportion of planes met the \u201c40 -minute -rule\u201d could be \nbetween 80 to 90%. Finally, when the weather is very bad , \nthe proportion of planes met the \u201c40 -minute -rule\u201d is ", "y bad , \nthe proportion of planes met the \u201c40 -minute -rule\u201d is below \n80%. Of course, one can look into more details about the \n\u201cvery bad weather\u201d situations to classify it into more \n\u201ccontingent situations\u201d.   \n-------------------------------------------", "gent situations\u201d.   \n------------------------------------------------------------------------------------  \nThe following provide details of probability -based Y-data \nmodeling for the four stages  (discussed in pa ge 6 above ) from \nsuppliers to the retai", "ages  (discussed in pa ge 6 above ) from \nsuppliers to the retail store .  \n \n1> Stage -1: Shipping from Supplier S j (j = 1, 2, \u2026, K) to DC:  \nDenoted by XjC and XjN (for j = 1, 2, \u2026, K) the proportion of \ndefective products in a unit -product shipment du", "proportion of \ndefective products in a unit -product shipment during the \ncontingent  and typical situations , respectively. They are both \nrandom -variables with distributions GC and GN, respectively.  9 \n Define an indicator function Ij as Ij = 1 if it i", "ectively.  9 \n Define an indicator function Ij as Ij = 1 if it is a contingent \nsituation ; Ij = 0, otherwise. The distribution of Ij is a Bernoulli \nwith Pr( Ij = 1) = p and Pr( Ij = 0) = 1 \u2013 p. Assume that the three \nrandom -variables, XjC, XjN and Ij ar", " p. Assume that the three \nrandom -variables, XjC, XjN and Ij are mutually independent. For a \nsupplier Sj the proportion of defects  for a unit of products is \nthen  \nPjDC = (1 \u2212 Ij)*XjN + Ij*XjC,   j = 1, 2, \u2026, K,   (1) \nwhich is a random variable with a", "*XjC,   j = 1, 2, \u2026, K,   (1) \nwhich is a random variable with a mixture distribution of two \ncases with their own corresponding proportions of defects.  \n \n2> Stage -2: Aggregation of Products at DC  - \u201cAverage -\nAggregation\u201d:  \n \n(1) Unevenly -split Orde", "s at DC  - \u201cAverage -\nAggregation\u201d:  \n \n(1) Unevenly -split Ordered -Quantity Q Sj for j = 1, 2, \u2026, K:  \nBecause for each supplier there are Q Sj*PjDC #defects \namong Q Sj #ordered -products, the average -aggregated \nproportion of defects from all supplier", "the average -aggregated \nproportion of defects from all suppliers  is \n \n Pau,DC = \u03a3j=1K (QSj*PjDC) / Q,  where Q = \u03a3 j=1K QSj.  (2) \n 10 \n Here, the numerator is the total number of defects from \nall suppliers\u2019 products, and the denominator is the total \n", "rom \nall suppliers\u2019 products, and the denominator is the total \nnumber of ordered -products.  \n \n(2) Evenly -split Ordered -Quantity Q Sj = Q/ K for j = 1, 2, \u2026,  \nK \u2013 this is our focus.  \n \nThis option is a special case of (1) unevenly -split \nordered -qu", "his option is a special case of (1) unevenly -split \nordered -quantity above.  Apply the same formula with Q Sj \n= Q/K to get  \n \n Pae,DC = \u03a3j=1K [(Q/K)*PjDC)] / Q = ( \u03a3 j=1K PjDC ) / K,  \n \nwhich is a simple average of proportion of defects from \nall supp", "hich is a simple average of proportion of defects from \nall suppliers\u2019. Notice the index \u201cae\u201d in the Proportion \n\u201cP\u201d for this case.  \n \n3> Stage -3: Shipping from DC to Store :  \nOur goal is to formulate Y* \u2261 the average proportion of defects \nfor one unit", "o formulate Y* \u2261 the average proportion of defects \nfor one unit of products shipped from suppliers through DC 11 \n and to the store, which was the goal of the defect -data -\nmodeling studies.  \n(1) Unevenly -split Ordered -Quantity Q Sj for j = 1, 2, \u2026, K", "  \n(1) Unevenly -split Ordered -Quantity Q Sj for j = 1, 2, \u2026, K:  \nSimilar to the definitions of the three random variables (1) \nabove, for shipping from DC to store  we have XC* and XN* \n(for j = 1, 2, \u2026, K) the proportion of defective products in a \nuni", "r j = 1, 2, \u2026, K) the proportion of defective products in a \nunit-product shipment during the contingent  and typical \nsituations, respectively. The indicator function I0 is defined \nas I0 = 1 if it is a contingent situation ; I0 = 1, otherwise. \nThen, the", " if it is a contingent situation ; I0 = 1, otherwise. \nThen, the proportion ( PR) of de fects from shipping \nbetween DC and store  is \nPR = (1 \u2013 I0)*XN* + I0*XC*.     (3) \nNote that  there are \u03a3 j=1K (QSj*PjDC) amount of defects out \nof Q total number of p", " \u03a3 j=1K (QSj*PjDC) amount of defects out \nof Q total number of products -ordere d (and shipped from \nsuppliers). Assume that there is NO INSPECTION at the \nDC for taking out defective products. There are   \nQ \u2212 \u03a3j=1K (QSj*PjDC)  \n= Q \u2013 Q*Pau,DC = Q*(1 \u2212 Pa", ". There are   \nQ \u2212 \u03a3j=1K (QSj*PjDC)  \n= Q \u2013 Q*Pau,DC = Q*(1 \u2212 Pau,DC)               (4)            12 \n amount of non-defective products shipped from DC to \nstore . See Eq. (2) for understanding the first equality \nabove.  \nSince the Q*(1 \u2212 Pau,DC) amount ", "ng the first equality \nabove.  \nSince the Q*(1 \u2212 Pau,DC) amount of non-defective \nproducts shipped from DC to store will subject to further \nshipping damage (with the probability PR defined in \nEq.(3)), the #defects for non-defective products shipped \nfrom", " \nEq.(3)), the #defects for non-defective products shipped \nfrom DC and arrived at the store is  \nQ*(1 \u2212 Pau,DC) * PR. \nNote that there are only Q*(1 \u2212 Pau,DC) * (1 \u2212 PR) amount \nof non -defective products arrived at the store eventually.  \n \n(2) Evenly -s", "tive products arrived at the store eventually.  \n \n(2) Evenly -split Ordered -Quantity Q Sj = Q/ K for j = 1, 2, \n\u2026, K:  \n \nThis option is a special case of (1) unevenly -split \nordered -quantity above. Applying the same ideas as \ngiven above by replacing ", "ity above. Applying the same ideas as \ngiven above by replacing Pau,DC with Pae,DC for this \nevenly -split case, we have  the following #defects for 13 \n non-defective products shipped from DC and arrived at \nthe store:  \nQ*(1 \u2212 Pae,DC) * PR. \n \n4> Stage -", " and arrived at \nthe store:  \nQ*(1 \u2212 Pae,DC) * PR. \n \n4> Stage -4: Calculate total #defects occurred at all stages.  \nFrom supplier\u2019s (or logistics service provider\u2019s) point of \nview, the total #defects (and its proportion) occurred at Stage \n(1) and (3)\u2019s", "l #defects (and its proportion) occurred at Stage \n(1) and (3)\u2019s shipping proce sses is important for calculating \nthe cost of product -supply. From retailer\u2019s (store manager\u2019s) \npoint of view, the #good -products arrived at the store and \nalso the proport", ", the #good -products arrived at the store and \nalso the proportion (#good -products arrived at the store / \n#total -ordered -products) is important for supporting their \nsales (to meet customer demands).  \n \n(1) Unevenly -split Ordered -Quantity Q Sj for ", "er demands).  \n \n(1) Unevenly -split Ordered -Quantity Q Sj for j = 1, 2, \u2026, \nK:  \n \nThere are \u03a3 j=1K (QSj*PjDC) amount of defects in Stage -1. \nAmong Q*(1 \u2212 Pau,DC) good -products (see Eq.(4)) 14 \n shipped in Stage -3, there are Q*(1 \u2212 Pau,DC) * PR amount", ") 14 \n shipped in Stage -3, there are Q*(1 \u2212 Pau,DC) * PR amount \nof defects. Thus, the total #defects is  \n \u03a3j=1K (QSj*PjDC) + Q*(1 \u2212 Pau,DC) * PR. \nIf one is interested in the average -proportion of defects \nin all stages , it is then  \n Y = [ \u03a3j=1K (QSj", "rtion of defects \nin all stages , it is then  \n Y = [ \u03a3j=1K (QSj*PjDC) + Q*(1 \u2212 Pau,DC) * PR ] / Q.  \n \n(2) Evenly -split Ordered -Quantity Q Sj = Q/ K for j = 1, 2, \n\u2026, K: \n \nAgain, with Q Sj = Q/K the above results in (1) becomes  \n \nY = [ \u03a3 j=1K [(Q/K)*", " = Q/K the above results in (1) becomes  \n \nY = [ \u03a3 j=1K [(Q/K)* PjDC] + Q*(1 \u2212 Pau,DC) * PR ] / Q \n= (\u03a3j=1K PjDC)/K + (1 \u2212 Pae,DC) * PR. \nSince  Pae,DC = ( \u03a3j=1K PjDC ) / K, the above formula \nbecomes  \n Y = Pae,DC + (1 \u2212 Pae,DC) * PR  \n= Pae,DC (1 \u2212 PR) ", " \nbecomes  \n Y = Pae,DC + (1 \u2212 Pae,DC) * PR  \n= Pae,DC (1 \u2212 PR) + PR \n= [( \u03a3j=1K PjDC ) / K ] * (1 \u2212 PR) + PR, 15 \n which is the average of proportion of defects for all \nproducts shipped from K-suppliers to store. This is the \nneeded Y in the objective fu", " K-suppliers to store. This is the \nneeded Y in the objective function (2.2).  \n-------------------------------------------------------------------------- ----------  \nStep -3: Optimization -Solution Procedures  \n1) Risk Neutral:  F ind Qopt to maximize Ex", "olution Procedures  \n1) Risk Neutral:  F ind Qopt to maximize Expected Profit . \n2) Risk Averse:  \ni) Constrained Optimization I \u2013 Profit Constraint  \nMaximize the Expected Profit  \nsubject to that the expected profit in the contingent \nsituation is over a", " that the expected profit in the contingent \nsituation is over a certain threshold. That is,  \n \nNotations : \n16 \n [1] G is the distribution for the random variable Y (= \naverage proportion of defects for products arrived at the \nstore). G has the mixture ", " defects for products arrived at the \nstore). G has the mixture distribution mixing from \ndistributions in both contingent and typical situations ; \nThe expectation in the main objecti ve is taken with \nrespect to (w.r.t.) the distribution G; See File 1.2)", "aken with \nrespect to (w.r.t.) the distribution G; See File 1.2) \nExample_Supplier\u2026. for details of G.  \n[2] G c is the distribution for the random variable Y in the \ncontingent situation ; The expectation in the constraint is \ntaken w.r.t. G c. \n \nii)  Co", "e expectation in the constraint is \ntaken w.r.t. G c. \n \nii)  Constraine d Optimization II \u2013 Probability \nConstraint  \nMaximize Expected Profit  17 \n subject to that in the contingent situation the \nprobability of (profit being less than a given \namount) i", "n the \nprobability of (profit being less than a given \namount) is less than or equal to a certain threshold.  \n \nRemarks:  \n[1] The expectation for the objective should be taken w.r.t. \nto G defined in (i) above.  \n[2] The probability evaluation for the co", "efined in (i) above.  \n[2] The probability evaluation for the constraint should be \ntaken w.r.t. to G c for the contingent situation.  \n \niii) Mean -Variance Solution  \n18 \n  \nwhere GN is the distribution for the rand om variable Y \nin the typical situatio", "distribution for the rand om variable Y \nin the typical situation ; \n \niv) Max -Min Solution  \n \nRemark s: The worse -case of the expected -profit occurs in \nthe contingent situation, where 40% of products shipped \nare defective. Thus, the optimal order -q", "% of products shipped \nare defective. Thus, the optimal order -quantity Q opt is \nlocated to maximize this worse -case expected -profit.  \n \n"]